# Intelligent Information System for Knowledge Integration into Artificial Intelligence Models

**AdvAIT'2025: 2nd International Workshop on Advanced Applied Information Technologies**  
*December 5, 2025, Khmelnytskyi, Ukraine*

**Copyright © 2025 by its authors.**  
Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).

---

**Oleksandr Chaban**$^{1}$ [0009-0001-4710-3336], **Eduard Manziuk**$^{1}$ [0000-0002-7310-2126], **Pavlo Radiuk**$^{1,*}$ [0000-0003-3609-112X], **Elena Zaitseva**$^{2}$ [0000-0002-9087-0311], **Olena Markevych**$^{3}$ [0000-0003-2758-3288]

$^{1}$ *Khmelnytskyi National University, 11, Institutes str., Khmelnytskyi, 29016, Ukraine*  
$^{2}$ *Zilina University, Univerzitná 8215, 010 26 Žilina, Slovakia*  
$^{3}$ *Khmelnytskyi Infectious Diseases Hospital, 17, Skovorody str., Khmelnytskyi, 29008, Ukraine*

$^*$ Corresponding author: <radiukp@khmnu.edu.ua>

---

## Abstract

The rapid proliferation of artificial intelligence in medical imaging is currently hindered by a significant disconnect between high-performing research models and the rigorous demands of clinical environments. Key challenges include data interoperability issues between research formats and clinical standards, hardware dependencies that limit portability, and the opaque "black-box" nature of deep learning models which erodes clinician trust. In this work, we propose a comprehensive intelligent information system designed to bridge this gap by unifying standards-compliant data ingestion, accelerated inference, and knowledge-infused reasoning into a single auditable workflow. Our approach integrates a robust DICOM and NIfTI ingestion pipeline with built-in anonymization, a hardware-agnostic ONNX inference engine, and a novel graph-based classification module that explicitly models anatomical relationships. Evaluated on the public Automated Cardiac Diagnosis Challenge (ACDC) benchmark, the proposed system demonstrates superior performance, with the segmentation module achieving a mean Dice Similarity Coefficient of 0.939 and the knowledge-integrated classifier attaining a diagnostic accuracy of 94.0%. The significant conclusion of this study is that by systematically integrating privacy controls, hardware portability, and graph-based knowledge representation, it is possible to create a deployment-ready AI blueprint that is both scientifically reproducible and clinically trustworthy.

**Keywords:** Medical imaging, cardiac MRI, knowledge integration, graph neural networks, DICOM interoperability, ONNX runtime, information system

---

## 1. Introduction

The field of artificial intelligence (AI) for medical imaging has witnessed exponential growth in recent years, driven by the advent of deep learning architectures that often surpass human-level performance in specific diagnostic tasks. However, a substantial chasm remains between the experimental success of these models in controlled research environments and their practical utility in real-world clinical settings [1]. This discrepancy is primarily fueled by a trifecta of systemic challenges: data heterogeneity, hardware fragmentation, and the interpretability crisis. Clinical workflows heavily rely on the Digital Imaging and Communications in Medicine (DICOM) standard, a complex protocol governing the storage and transmission of medical data [2]. Conversely, the research community predominantly utilizes the Neuroimaging Informatics Technology Initiative (NIfTI) format due to its simplified handling of volumetric geometry and orientation [3]. The friction generated by converting between these formats often leads to silent geometric errors, metadata loss, and privacy breaches, thereby impeding the seamless integration of AI tools into hospital picture archiving and communication systems.

Furthermore, the deployment landscape is complicated by hardware heterogeneity. Research models are typically trained on high-end NVIDIA GPUs using frameworks like PyTorch, but clinical workstations vary widely in their computational capabilities, ranging from standard CPUs to GPUs from different vendors. This necessitates an inference strategy that is both portable and performant. The Open Neural Network Exchange (ONNX) format and its associated Runtime engine offer a solution by providing an intermediate representation that can be executed across diverse hardware backends [4, 5]. However, wrapping these technologies into a cohesive system that manages dependencies without imposing vendor lock-in remains a significant engineering hurdle.

Perhaps the most critical barrier to adoption is the "black-box" nature of modern deep neural networks. In high-stakes medical decision-making, accuracy alone is insufficient; clinicians require transparency and justification for algorithmic predictions. While purely data-driven models like the U-Net [6] and its self-configuring variant nnU-Net [7] have established strong baselines for segmentation, they often lack the ability to incorporate explicit medical knowledge or reasoning. Recent advances in transformers [8] and hybrid architectures [9, 10] push performance boundaries but often at the cost of increased opacity. To address this, human-in-the-loop approaches and explainable AI techniques are becoming essential components of trustworthy systems [11].

The problem under consideration is the absence of a unified, end-to-end framework that systematically addresses these disparate requirements, i.e., standards compliance, hardware portability, and knowledge-infused reasoning [12], within a single reproducible pipeline. Current solutions often address these issues in isolation, resulting in fragmented workflows that are difficult to audit and deploy.

In this work, we present a novel scientific contribution by architecting an intelligent information system that integrates these components from the ground up. By combining a standards-compliant ingestion module, a portable ONNX-based segmentation engine, and a graph convolutional network (GCN) for structured reasoning, we provide a holistic solution to the deployment gap.

The goal of this study is to improve knowledge integration fidelity and downstream reasoning accuracy by unifying standards-compliant ingestion, portable ONNX inference, and graph-structured classification with calibration-aware evaluation.

The objective of the study is to design, implement, and validate this integrated system. To achieve this, we present three major contributions:

1.  A complete system architecture that spans DICOM/NIfTI ingestion with built-in anonymization, accelerated ONNX inference, volumetric segmentation, and manifest-driven data export for full reproducibility.
2.  A novel graph-based classification module, KI-GCN, derived from GCNs, which aggregates structured features from segmentation masks and patient metadata to enhance diagnostic reasoning. We also specify an optional multi-teacher knowledge distillation objective for deploying compressed, efficient models.
3.  A deployment-oriented evaluation protocol that includes standard segmentation metrics, probabilistic classification metrics, and critical calibration diagnostics like reliability diagrams to ensure model trustworthiness.

**Structure of the paper**
The remainder of this paper is organized as follows. Section 2 reviews the state of the art in medical imaging interoperability, segmentation architectures, and knowledge integration methods. Section 3 details the proposed system architecture, including the formalization of the ingestion, segmentation, and graph-based classification modules. Section 4 presents the experimental results on the ACDC and M&Ms-2 datasets, providing a comparative analysis against state-of-the-art methods. Section 5 analyzes the implications of these findings, system throughput, and limitations. Finally, Section 6 summarizes the contributions and outlines future directions.

## 2. Related Works

Our research is situated at the intersection of interoperability standards, hardware acceleration, advanced deep learning architectures for segmentation, and methods for knowledge integration. This section reviews the state of the art in these domains to contextualize the proposed intelligent information system.

The foundation of any clinical AI system is its ability to handle standardized data formats. The DICOM standard serves as the global lingua franca for medical imaging, with its Part 1 (PS3.1) defining the overarching structure and semantic interoperability requirements for clinical data exchange [2]. While robust, DICOM's complexity often poses challenges for direct consumption by deep learning models. In the research domain, the NIfTI format has become the de facto standard for 3D and 4D volumetric data, primarily due to its explicit encoding of affine geometry and orientation fields, which are critical for preventing spatial misalignment during analysis [3]. A key task for our system is to seamlessly bridge these two standards, ensuring that data ingressed from clinical sources (DICOM) retains its geometric integrity when converted for model consumption (NIfTI-like tensors).

Regarding model deployment and hardware acceleration, the ONNX Runtime engine has emerged as a critical technology for ensuring portability. It abstracts the execution of model graphs through a system of pluggable Execution Providers (EPs), allowing the same model file to run efficiently on CPUs, NVIDIA GPUs via CUDA [13], and Windows-based GPUs via DirectML [14]. This flexibility is essential for clinical environments where hardware specifications cannot be guaranteed. Recent comparative analyses have highlighted the necessity of such acceleration frameworks to reduce inference latency and computational overhead in production settings [5].

In the domain of medical image segmentation, the U-Net architecture remains the cornerstone, featuring a symmetric encoder-decoder structure with skip connections that preserve spatial information [6]. Building on this, the nnU-Net framework demonstrated that automated hyperparameter optimization and rigorous preprocessing are often more critical than architectural novelty, consistently achieving state-of-the-art results on benchmarks like the Automated Cardiac Diagnosis Challenge (ACDC) [7, 8]. More recently, the field has seen a surge in transformer-based models [9], hybrid ConvNet-transformer architectures like MedNeXt [10], and specialized 3D volume processors like UNETR++ [11]. While these models offer performance gains, their integration into explainable, standards-compliant workflows remains limited.

To move beyond the "black-box" paradigm, integrating explicit knowledge is crucial. Neural networks, particularly GCNs, provide a mathematical framework for modeling anatomical structures as interconnected nodes, allowing for reasoning based on spatial and functional relationships rather than just pixel intensities [15]. Advanced variants like graph attention networks have further refined this approach by learning to weigh the importance of different anatomical connections [16]. Additionally, knowledge distillation offers a pathway to compress these complex reasoning capabilities into lightweight models suitable for deployment, transferring insights from large "teacher" ensembles to efficient "student" models [17, 18]. Recent work in our group has extended these concepts to adaptive multi-teacher distillation strategies, enhancing robustness against domain shifts [19, 20].

Finally, trust in AI systems is predicated not just on accuracy, but on calibration, i.e., the alignment between predicted confidence and actual correctness. Methods such as reliability diagrams and temperature scaling are essential for diagnosing and correcting miscalibration [21]. Emerging techniques like proximity-informed calibration continue to push the boundaries of model reliability [22].

The primary objective of this study is to synthesize these diverse technological threads into a single, cohesive system. The main tasks to fulfill this objective are: (i) to design and implement a modular software architecture for the end-to-end medical imaging workflow, (ii) to develop and integrate a graph-based reasoning module that leverages segmentation outputs for improved classification, and (iii) to validate the entire system's performance and reproducibility on public benchmark datasets.

## 3. Methods

We formalize the proposed intelligent information system as a sequence of interconnected processing modules that execute a single, manifest-driven workflow. The system is designed to transform raw medical imaging data into actionable, explainable diagnostic insights. Detailed implementation specifics and user manuals are provided in the accompanying technical report [23]. In this section, we define the mathematical formulations and algorithmic logic underpinning the core components: ingestion, segmentation, and graph-based knowledge integration.

Let a dataset be denoted by $\mathcal{D} = \{ (V_i, M_i, D_i) \}_{i=1}^N$, where for each of $N$ patients, $V_i$ represents the input medical image volume (e.g., a cardiac MRI series), $M_i$ represents the ground-truth anatomical segmentation mask, and $D_i$ represents the associated clinical diagnosis or classification label. The system architecture, illustrated in Figure 1, processes these inputs through four distinct stages: ingestion, segmentation, knowledge graph construction, and classification.

![System architecture and data flow](figs/diagram.png)
*Figure 1: System architecture and data flow. The pipeline begins with standards-compliant ingestion (DICOM/NIfTI) and anonymization, proceeds to accelerated ONNX-based segmentation (SKIF-Seg), constructs a knowledge graph for classification (KI-GCN), and concludes with comprehensive evaluation and manifest-driven export for reproducibility.*

The system processes each patient's data $i$ through a sequential pipeline formalized below.

### 3.1. Standards-Compliant Ingestion and Anonymization

The ingestion module is responsible for the secure and accurate loading of medical data. It utilizes the FO-DICOM library to parse DICOM series, ensuring that all slices are ordered correctly based on the `ImagePositionPatient` (0020,0032) tag. To adhere to privacy regulations (e.g., GDPR, HIPAA), the module implements a configurable anonymization engine compliant with the DICOM PS3.15 Basic Profile. Identifiers such as `PatientName` and `PatientID` are hashed or removed [2].

For research data in NIfTI format, the system parses the affine header to normalize voxel spacing and reorient the volume to the canonical RAS coordinate system [3]. Input volumes are then intensity-normalized to the range $[0, 1]$ to stabilize downstream numerical optimization.

### 3.2. Volumetric Segmentation (SKIF-Seg)

Synergistic Knowledge-Integrated Framework for Segmentation (SKIF-Seg) is the system's segmentation engine, designed for hardware portability via ONNX Runtime. The module accepts the preprocessed volume $V_i'$ and predicts a dense probability map $P_i$. The inference process is abstracted to support multiple backends:
*   **CPU Execution Provider:** Uses MKLDNN/OpenBLAS for optimized execution on standard processors.
*   **CUDA Execution Provider:** Leverages NVIDIA's cuDNN and TensorRT libraries for high-throughput GPU inference [13].
*   **DirectML Execution Provider:** Provides vendor-agnostic GPU acceleration on Windows, supporting AMD, Intel, and NVIDIA hardware [14].

The output $P_i \in [0, 1]^{H \times W \times D \times C}$ represents the probability of each voxel belonging to one of $C$ anatomical classes. A final segmentation mask $\hat{M}_i$ is generated via an argmax operation.

### 3.3. Graph-based Classification (KI-GCN)

To incorporate anatomical reasoning, we introduce the Knowledge Integration Graph Convolutional Network (KI-GCN). We define a graph $G=(V, E)$ where nodes $V$ correspond to segmented structures (e.g., Left Ventricle, Myocardium, Right Ventricle) and edges $E$ encode spatial adjacency and functional connectivity.

For each node $v \in V$, we compute a feature vector $\mathbf{x}_v$ derived from the segmentation mask $\hat{M}_i$, including volume, surface area, sphericity, and centroid displacement. The graph is processed using spectral graph convolution layers defined by the propagation rule shown in Equation 1:

$$
H^{(\ell+1)} = \sigma\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(\ell)} W^{(\ell)}\right),
$$

where $H^{(\ell)}$ is the feature matrix at layer $\ell$, $\tilde{A}$ is the adjacency matrix with self-loops, $\tilde{D}$ is the degree matrix, and $W^{(\ell)}$ is the learnable weight matrix [15].

This process allows the model to learn features that depend on the structural configuration of the heart, rather than treating geometry as a flat vector. The final node embeddings are pooled to form a global graph representation $\mathbf{h}_G$, which is classified into diagnostic categories.

### 3.4. Multi-Teacher Knowledge Distillation

To enable efficient deployment on edge devices, we employ a multi-teacher knowledge distillation strategy. The training objective combines the standard cross-entropy loss with a distillation term that aligns the student's logits $z^{(s)}$ with the soft targets from an ensemble of teacher models $\bar{z}^{(t)}$ as presented in Equation 2:

$$
\mathcal{L} = \alpha \mathcal{L}_{\mathrm{CE}}(y, \mathrm{softmax}(z^{(s)})) + (1-\alpha) \tau^2 \mathrm{KL}\left(\mathrm{softmax}\left(\frac{\bar{z}^{(t)}}{\tau}\right) \bigg\| \mathrm{softmax}\left(\frac{z^{(s)}}{\tau}\right)\right),
$$

where $\tau$ is the temperature parameter controlling the softness of the probability distributions, and $\alpha$ balances the two loss components [17, 18].

### 3.5. Experimental Setup and Evaluation

Our evaluation protocol is designed to be comprehensive, deployment-oriented, and fully reproducible.

For segmentation performance, let $X$ and $Y$ be the predicted and ground-truth masks, respectively. We quantify overlap using the Dice Similarity Coefficient (DSC) [24], as shown in Equation 3:

$$
\mathrm{DSC}(X,Y) = \frac{2|X \cap Y|}{|X|+|Y|}.
$$

Additionally, we calculate the Jaccard Index (IoU) [25], defined in Equation 4:

$$
\mathrm{IoU}(X,Y) = \frac{|X \cap Y|}{|X \cup Y|}.
$$

For boundary accuracy, we use the 95th percentile Hausdorff Distance (HD95) and Average Symmetric Surface Distance (ASSD), which are reviewed in detail by Taha and Hanbury [26].

For classification, let $p_i$ be the predicted probability for the positive class and $y_i \in \{0,1\}$ be the true label. We measure ranking quality with ROC-AUC and, for imbalanced classes, PR-AUC [27]. We assess calibration using the Brier score [28], which is the mean squared error of probabilistic forecasts, and visualize it with reliability diagrams, quantifying miscalibration with the Expected Calibration Error (ECE) [21].

To ensure full auditability and scientific reproducibility, every execution of the pipeline generates a JSON manifest file. This manifest records the software version, Git commit hash, timestamp, the selected ONNX Runtime EP, model opset version, and all computed evaluation metrics [23]. The system also provides an export module that saves segmentation masks as NIfTI files, qualitative overlays as PNG images, and all metrics in CSV/JSON formats. This functionality is managed through a comprehensive export module (see Appendix, Figure A.5). This practice aligns with best practices for reproducible computational science.

## 4. Results

We evaluated the system on the ACDC dataset [8] for segmentation and diagnosis, and the M&Ms-2 dataset [29] for cross-domain generalization.

### 4.1. Segmentation Performance

The SKIF-Seg module demonstrates robust performance. Table 1 presents a structure-wise comparison with a U-Net baseline. Our approach yields a significant improvement in boundary delineation, reducing the HD95 for the Left Ventricle (LV) from 7.5 mm to 5.8 mm.

*Table 1: Segmentation results on ACDC (in-domain) and M&Ms-2 (cross-domain). The proposed SKIF-Seg shows consistent improvements in DSC and HD95 over the baseline U-Net.*

| Dataset | Structure | Baseline U-Net DSC | Baseline U-Net HD95 (mm) | Proposed DSC | Proposed IoU | Proposed HD95 (mm) | Proposed ASSD (mm) |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **ACDC** | LV Cavity | $0.951 \pm 0.03$ | $7.5 \pm 2.1$ | **$0.965 \pm 0.03$** | $0.932 \pm 0.018$ | **$5.8 \pm 2.2$** | $1.28 \pm 0.40$ |
| | Myocardium | $0.895 \pm 0.05$ | $8.1 \pm 2.5$ | **$0.912 \pm 0.04$** | $0.838 \pm 0.024$ | **$6.3 \pm 2.2$** | $1.39 \pm 0.40$ |
| | RV Cavity | $0.930 \pm 0.04$ | $9.2 \pm 3.0$ | **$0.941 \pm 0.03$** | $0.889 \pm 0.018$ | **$7.7 \pm 2.2$** | $1.69 \pm 0.40$ |
| **M&Ms-2** | LV Cavity | $0.942 \pm 0.04$ | $8.9 \pm 2.8$ | **$0.953 \pm 0.03$** | $0.911 \pm 0.018$ | **$7.2 \pm 3.1$** | $1.58 \pm 0.56$ |
| | Myocardium | $0.881 \pm 0.06$ | $9.8 \pm 3.4$ | **$0.899 \pm 0.04$** | $0.817 \pm 0.024$ | **$7.9 \pm 3.1$** | $1.74 \pm 0.56$ |
| | RV Cavity | $0.915 \pm 0.05$ | $10.5 \pm 3.9$ | **$0.928 \pm 0.03$** | $0.866 \pm 0.018$ | **$8.9 \pm 3.1$** | $1.96 \pm 0.56$ |

The distribution of Dice scores is visualized in Figure 2, showing reduced variance for the proposed method. Table 2 summarizes the macro-averaged performance, highlighting a 1.67 mm reduction in HD95 on the ACDC dataset.

![Case-wise Dice distributions](figs/results_seg_boxplots.pdf)
*Figure 2: Case-wise Dice distributions for SKIF-Seg across ACDC and M&Ms-2 datasets, illustrating high median performance and low variance.*

*Table 2: Macro-averaged segmentation performance summary (LV/Myo/RV). $\Delta$ denotes the improvement of SKIF-Seg over the U-Net baseline.*

| Dataset | U-Net DSC | U-Net HD95 (mm) | SKIF-Seg DSC | SKIF-Seg HD95 (mm) | $\Delta$DSC | $\Delta$HD95 (mm) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| ACDC | 0.925 | 8.27 | **0.939** | **6.60** | +0.014 | **-1.67** |
| M&Ms-2 | 0.913 | 9.73 | **0.927** | **8.00** | +0.014 | **-1.73** |

Figure 3 visually compares the macro Dice scores, further confirming the superiority of SKIF-Seg across both datasets.

![Comparison of Macro Dice scores](figs/results_seg_macro_bars.pdf)
*Figure 3: Comparison of Macro Dice scores (LV/Myo/RV) between U-Net and SKIF-Seg on ACDC and M&Ms-2 datasets.*

### 4.2. State-of-the-Art Comparison and Robustness

We compared our system against leading methods, including nnU-Net and MedNeXt (Table 3). Our system achieves a mean Dice of 0.939, matching MedNeXt and remaining highly competitive with nnU-Net, while operating within a portable ONNX framework.

*Table 3: Comparison with state-of-the-art methods on ACDC (Mean Dice). Best results are in **bold**.*

| Method | LV Cavity | Myocardium | RV Cavity | Mean Dice |
| :--- | :---: | :---: | :---: | :---: |
| U-Net | 0.951 | 0.895 | 0.930 | 0.925 |
| nnU-Net | **0.968** | 0.909 | **0.945** | **0.941** |
| MedNeXt | 0.966 | 0.910 | 0.942 | 0.939 |
| Proposed System | 0.965 | **0.912** | 0.941 | 0.939 |

To evaluate robustness, we analyzed the domain shift from ACDC to M&Ms-2 (Figure 4). The degradation in Dice scores is minimal ($<0.013$), indicating excellent generalization capabilities across different scanner vendors.

![Domain shift analysis](figs/results_domain_shift.pdf)
*Figure 4: Domain shift analysis: The plot shows the decrease in Dice score when applying the model trained on ACDC to the M&Ms-2 dataset.*

### 4.3. Diagnostic Classification

The KI-GCN module demonstrates high diagnostic accuracy. Figure 5 displays the Macro ROC and PR curves, with an AUC of 0.964. The confusion matrix (Figure 6) shows strong discrimination between all five cardiac conditions.

![Diagnostic performance - ROC](figs/results_roc_curve.pdf)
*Figure 5(a): ROC Curve showing diagnostic performance of KI-GCN on the ACDC dataset.*

![Diagnostic performance - PR](figs/results_pr_curve.pdf)
*Figure 5(b): PR Curve showing diagnostic performance of KI-GCN on the ACDC dataset.*

*Note: The model achieves high sensitivity and precision across classes.*

![Normalized confusion matrix](figs/results_confusion_matrix.pdf)
*Figure 6: Normalized confusion matrix for the 5-class diagnosis task. Classes: Normal (NOR), Hypertrophic Cardiomyopathy (HCM), Dilated Cardiomyopathy (DCM), Myocardial Infarction (MINF), Abnormal RV (ARV).*

### 4.4. Calibration and Efficiency

Model trustworthiness was assessed via reliability diagrams (Figure 7). Post-hoc temperature scaling ($\tau=2.1$) significantly improved calibration, reducing the Expected Calibration Error (ECE) to 0.03 (Table 4).

*Table 4: Calibration metrics before and after temperature scaling. Lower values indicate better calibration.*

| Setting | Brier $\downarrow$ | ECE $\downarrow$ |
| :--- | :---: | :---: |
| Pre (no scaling) | 0.08 | 0.04 |
| Post (temp. scaling, $\tau=2.1$) | **0.07** | **0.03** |

![Reliability diagram](figs/results_reliability_pre_post.pdf)
*Figure 7: Reliability diagram showing the alignment between predicted confidence and observed accuracy. Temperature scaling brings the model closer to perfect calibration (diagonal).*

The ablation study in Table 5 confirms that the inclusion of the graph module (KI-GCN) contributes significantly to accuracy compared to a baseline MLP.

*Table 5: Ablation study on the ACDC diagnosis task.*

| Variant | Acc. (%) | Macro-F1 | Brier | ECE |
| :--- | :---: | :---: | :---: | :---: |
| Handcrafted + MLP | 89.1 | 0.881 | 0.12 | 0.08 |
| GCN (no knowledge edges) | 92.7 | 0.907 | 0.10 | 0.06 |
| KI-GCN (ours) | 94.0 | 0.930 | 0.08 | 0.04 |
| KI-GCN + Distillation | **94.5** | **0.940** | **0.07** | **0.03** |

Finally, system throughput is analyzed in Table 6 and Figure 8. The CUDA and DirectML providers offer substantial speedups over CPU, enabling real-time clinical use.

*Table 6: Inference throughput and resource usage by ONNX Execution Provider (EP).*

| EP | Median (s) | P95 (s) | Memory (GB) | Pass-rate (%) |
| :--- | :---: | :---: | :---: | :---: |
| CPU | 5.3 | 6.6 | 3.2 | 100 |
| CUDA | 0.8 | 1.1 | 4.1 | 97 |
| DirectML | 1.2 | 1.6 | 3.8 | 99 |

![Inference latency](figs/results_throughput_batch.pdf)
*Figure 8: Inference latency (seconds per volume) vs. batch size for different hardware providers.*

*Table 7: Summary of automated DICOM anonymization actions for a representative batch.*

| Action | Count |
| :--- | :---: |
| Removed (patient identifiers) | 28 |
| Replaced with hash | 16 |
| Retained (non-PHI) | 142 |
| **Total Tags Processed** | **186** |

## 5. Discussion

The results of this study underscore the critical importance of a holistic systems engineering approach to medical AI. While pure algorithmic research often prioritizes incremental gains in Dice scores, our work demonstrates that architecting for interoperability and interpretability yields substantial practical benefits without sacrificing accuracy. The SKIF-Seg module's performance, achieving a mean Dice of 0.939, is on par with state-of-the-art research models like MedNeXt [10], yet it is delivered within a containerized, hardware-agnostic framework. This portability, enabled by ONNX Runtime, addresses the vendor lock-in that frequently stifles clinical adoption.

Our key scientific finding is the efficacy of the KI-GCN module. By explicitly modeling the heart as a graph of connected structures, we achieved a 4.9% improvement in diagnostic accuracy over a feature-based MLP baseline. This validates the hypothesis that structural knowledge is a powerful inductive bias. Furthermore, the strong calibration results (ECE of 0.03) suggest that the system's probability outputs are trustworthy, a prerequisite for use in high-stakes medical decision-making.

However, the system is not without limitations. The current graph topology in KI-GCN is static, defined by a priori anatomical knowledge. This prevents the model from discovering novel, data-driven relationships that might exist in diverse pathologies. Additionally, while the M&Ms-2 generalization results are promising, true clinical robustness requires validation across a broader spectrum of imaging artifacts and patient demographics.

Future research will focus on two avenues: (i) developing dynamic graph learning techniques that can infer patient-specific topological connections, and (ii) conducting prospective multi-site clinical trials to validate the system's impact on diagnostic workflow efficiency and accuracy.

## 6. Conclusion

In this paper, we have successfully bridged the "last-mile" gap separating high-performance AI research from tangible clinical utility. By architecting a holistic intelligent information system, we resolved the tripartite challenges of data interoperability, hardware fragmentation, and model interpretability. Our solution moves beyond isolated algorithm development to provide a unified, end-to-end pipeline that seamlessly integrates standards-compliant DICOM and NIfTI ingestion, automated privacy preservation, and hardware-agnostic inference via ONNX Runtime. The empirical validation of this framework underscores its potential to transform diagnostic workflows without disrupting existing hospital infrastructure. Specifically, the proposed SKIF-Seg module demonstrated better anatomical delineation, achieving a mean Dice Similarity Coefficient of 0.939 on the ACDC benchmark, effectively matching specialized research models within a portable container. Moreover, the integration of structured domain knowledge through the novel KI-GCN classification module yielded a diagnostic accuracy of 94.0% and, critically, a low Brier score of 0.07. These metrics establish that incorporating graph-based anatomical reasoning not only enhances predictive performance but also ensures the calibration and trustworthiness essential for high-stakes medical decision-making. Consequently, this study offers a scientifically reproducible and legally auditable blueprint for deploying AI in diverse hospital environments.

Future research will focus on evolving this framework from a static deployment tool into a dynamic, continuous learning ecosystem.

---

## Declaration on Generative AI

During the preparation of this work, the authors employed generative AI tools to polish the final version of the manuscript. Specifically, Gemini 3 Pro (owned by Google LLC) and Grammarly (owned by Grammarly, Inc.) were utilized to improve grammar, spelling, and overall readability. After using these tools, the authors reviewed and edited the content as needed and take full responsibility for the publication's content.

---

## References

[1] He, J. et al. "Discrepancies between research and real-world performance in medical image analysis". In: *Nature Medicine* 31 (2025), pp. 142–155.

[2] NEMA. "Digital Imaging and Communications in Medicine (DICOM) Part 1: Introduction and Overview". NEMA PS3.1 (2023).

[3] NIfTI Data Format Working Group. "Neuroimaging Informatics Technology Initiative (NIfTI)". 2024. URL: <http://nifti.nimh.nih.gov>.

[4] ONNX Runtime Developers. "ONNX Runtime: Cross-platform, High Performance ML Inferencing". 2024. URL: <https://onnxruntime.ai>.

[5] Ratul, S. et al. "Inference acceleration strategies for medical deep learning: A comparative study". In: *Journal of Real-Time Image Processing* 22.4 (2025), p. 112.

[6] Ronneberger, O., P. Fischer, and T. Brox. "U-Net: Convolutional Networks for Biomedical Image Segmentation". In: *MICCAI 2015*. Ed. by N. Navab et al. Vol. 9351. LNCS. Springer, Cham, 2015, pp. 234–241.

[7] Isensee, F. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation". In: *Nature Methods* 18 (2021), pp. 203–211.

[8] Bernard, O. et al. "Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?" In: *IEEE Transactions on Medical Imaging* 37.11 (2018), pp. 2514–2525.

[9] Shamshad, F. et al. "Transformers in medical imaging: A survey". In: *Medical Image Analysis* 88 (2023), p. 102830.

[10] Roy, S. et al. "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation". In: *MICCAI 2023*. Ed. by H. Greenspan et al. Vol. 14220. LNCS. Springer, Cham, 2023, pp. 405–415.

[11] Shaker, A. et al. "UNETR++: Delving into Efficient 3D Medical Image Segmentation". In: *IEEE Transactions on Medical Imaging* 43.2 (2024), pp. 567–578.

[12] Radiuk, P. "Human-in-the-loop approach based on collective intelligence for medical image analysis". In: *CEUR Workshop Proceedings* 3179 (2022), pp. 1–10.

[13] Chaban, O. et al. "Enhancing Medical NLI with Knowledge Graphs". In: *Proceedings of the 3rd International Workshop on Knowledge Graph Generation and Processing*. 2024, pp. 45–56.

[14] NVIDIA Corporation. "CUDA C++ Programming Guide". 2024. URL: <https://docs.nvidia.com/cuda>.

[15] Microsoft Corporation. "DirectML documentation". 2024. URL: <https://learn.microsoft.com/en-us/windows/ai/directml>.

[16] Kipf, T. N. and M. Welling. "Semi-Supervised Classification with Graph Convolutional Networks". In: *ICLR 2017*. 2017.

[17] Alanazi, S. et al. "Graph Attention Networks for Medical Image Analysis". In: *Neurocomputing* 560 (2025), pp. 126–138.

[18] Hinton, G., O. Vinyals, and J. Dean. "Distilling the Knowledge in a Neural Network". In: *arXiv preprint arXiv:1503.02531* (2015).

[19] Moslemi, A. et al. "Knowledge Distillation in Medical Imaging: A Review". In: *Artificial Intelligence in Medicine* 148 (2024), p. 102765.

[20] Chaban, O. et al. "Method of adaptive multi-teacher knowledge distillation for medical image segmentation". In: *Radio Electronics, Computer Science, Control* 1 (2025), pp. 45–56.

[21] Chaban, O. et al. "EMTKD at the edge: Efficient Multi-Teacher Knowledge Distillation". In: *Proceedings of the 5th International Conference on Edge AI*. 2025, pp. 112–125.

[22] Niculescu-Mizil, A. and R. Caruana. "Predicting Good Probabilities With Supervised Learning". In: *ICML 2005*. 2005, pp. 625–632.

[23] Xiong, Y. et al. "Proximity-Informed Calibration for Deep Neural Networks". In: *NeurIPS 2023*. 2023.

[24] IDK Medical AI System. "Technical Report and User Manual". Khmelnytskyi National University, 2025.

[25] Dice, L. R. "Measures of the Amount of Ecologic Association Between Species". In: *Ecology* 26.3 (1945), pp. 297–302.

[26] Jaccard, P. "Distribution de la flore alpine dans le bassin des Dranses et dans quelques régions voisines". In: *Bulletin de la Société Vaudoise des Sciences Naturelles* 37 (1901), pp. 241–272.

[27] Taha, A. A. and A. Hanbury. "Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool". In: *BMC Medical Imaging* 15 (2015), p. 29.

[28] Saito, T. and M. Rehmsmeier. "The Precision-Recall Plot Is More Informative than the ROC Plot when Evaluating Binary Classifiers on Imbalanced Datasets". In: *PLoS ONE* 10.3 (2015), e0118432.

[29] Brier, G. W. "Verification of forecasts expressed in terms of probability". In: *Monthly Weather Review* 78.1 (1950), pp. 1–3.

[30] Campello, V. M. et al. "Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M&Ms Challenge". In: *IEEE Transactions on Medical Imaging* 40.12 (2021), pp. 3543–3554.

---

## Appendix A. System User Interface

This appendix provides select screenshots from the graphical user interface of the IDK Medical AI system, illustrating the key stages of the end-to-end workflow.

![Main user interface](figs/Appendix_Fig1.pdf)
*Figure A.1: The main user interface of the IDK Medical AI system, providing access to data ingestion modules (DICOM/NIfTI), analysis pipelines (Segmentation, Classification), and project management features.*

![DICOM import module](figs/Appendix_Fig2.pdf)
*Figure A.2: The DICOM import and anonymization module. The interface allows for batch loading of DICOM series and applies privacy-preserving profiles.*

![Segmentation module](figs/Appendix_Fig3.pdf)
*Figure A.3: Interface for the SKIF-Seg segmentation module. Users can select an ONNX model and monitor the segmentation progress.*

![Classification module](figs/Appendix_Fig4.pdf)
*Figure A.4: The KI-GCN classification module interface. This view enables the user to specify the graph source and initiate the graph-based diagnostic classification.*

![Export module](figs/Appendix_Fig5.pdf)
*Figure A.5: The export and reporting module, which facilitates reproducible science by allowing users to export segmentation masks (NIfTI), visual overlays, and metrics.*