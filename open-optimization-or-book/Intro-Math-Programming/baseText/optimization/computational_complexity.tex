
% Copyright 2020 by Robert Hildebrand 
% contributed by Diego Moran
%This work is licensed under a
%Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)
%See http://creativecommons.org/licenses/by-sa/4.0/

%\documentclass[../open-optimization/open-optimization.tex]{subfiles}
%
%\begin{document}
%\newcommand{\mathup}[1]{#1}
%\newcommand{\NP}{\text{NP}}
%\newcommand{\coNP}{\text{coNP}}

\chapter{Introduction to computational complexity}
\todoChapter{ Move this section to mode advanced version of the book.}

\section{Introduction}

{\bf Motivation:} We want to understand {\em what} is a problem and {\em when} a problem is {\em easy}/{\em hard}.\\

{\bf Our strategy:} An intuitive review of the basic ideas in Computational Complexity theory.\\ 

{\bf Key concepts:}
	\begin{itemize}
		\item Problem types: optimization problems, decision problems, feasibility problems.
		\item Instance (of a problem)
		\item A problem is a collection of instances.
		\item Size of an instance
		\item Algorithm
		\item Running time of an algorithm; worst-case time complexity
		\item Complexity classes: ${\mathup{P}}$ and ${\mathup{NP}}$
\end{itemize}

\section{Problem, instance, size}
\subsection{Problem, instance}
\begin{definition}{Problem}{problem}
Is a {\bf generic} question/task that needs to be answered/solved. 

A problem is a ``collection of instances'' (see below).
\end{definition}


A {\em particular} realization of a problem is define next.

\begin{definition}{Instance}{instance}
Is a specific case of a problem. In other words, we can say ``Instance$\in$Problem''.
\end{definition}

\subsection{Format and examples of problems/instances}

A problem is an abstract concept. We will write problems in the following format:
\begin{itemize}
	\item {\bf INPUT:} Generic data/instance.
	\item {\bf OUTPUT:} Question to be answered and/or task to be performed with the data.
\end{itemize}


{\bf Examples of problems/instances:}
	\begin{itemize}
	  \item Typical problems: optimization problems, decision problems, feasibility problems.
		\item LP and IP feasibility, TSP, IP minimization, Maximum cardinality independent set.
	\end{itemize}
	
	\subsection{Size of an instance}
	
The size of an instance is the {\em amount of information} required to represent the instance (in the computer).	
	
\begin{definition}{Binary size/length}{size}
Is the number of bits that are needed in order to give the problem to a computer.
\end{definition}	
	
{\bf Examples of sizes:}
	\begin{itemize}
		\item Size of an integer/rational number.
		\item Size of a rational matrix.
		\item Size of a graph (node-egde matrix represetation).
	\end{itemize}

\section{Algorithms, running time, Big-O notation}
\subsection{Basics}
\begin{definition}{Algorithm}{algorithm}
List of instructions to solve a problem.
\end{definition}

	
\begin{definition}{Running time of an algorithm}{running-time}
Is the number of steps (as a function of the size) that the algorithm takes in order to solve an instance. 
\end{definition}


	
	

\subsection{Worst-time complexity}	

Given an algorithm $\AA$ to solve a problem $P$, the {\em running time of $\AA$}, as a function of the size $\sigma\in\Z_+$ will be defined as follows:
\begin{itemize}
	\item The (generic) running time will be a function $f:\Z_+\rightarrow\Z_+$.
   \item Given $\sigma$, the function $f$ is defined as follows:
		$$f(\sigma)=\max\{\textup{running time of $\AA$ for instance $z$, where $\size(z)\leq \sigma$}\}.$$
\end{itemize}
	
{\bf Remark:} This is a very conservative/pessimistic measure of running time.	
\subsection{Big-O notation}

A function 	$f:\Z_+\rightarrow\Z_+$ belongs to the class of functions $\textup{O}(g(n))$ (that is, $f\in\textup{O}(g(n))$) if there exists $c>0$, $n_0\in\Z_+$ such that
$$f(n)\leq c g(n),\quad \textup{for all}\ n\geq n_0.$$

We usually say ``$f$ is $\textup{O}(g(n))$'' or ``$f$ is order $\textup{O}(g(n))$''.
	\subsection{Examples} 
\begin{itemize}
  \item Basic examples of Big-O notation: $\textup{O}(1)$, $\textup{O}(n^k)$, $\textup{O}(c^n)$, $\textup{O}(\log(n))$, etc.
	\item An illustration of the fact that the running time depends on the size of the instance: the algorithm for the binary knapsack problem that is $O(nb)$ is not polynomial, since the size of the instance is $\log(b)$.
\end{itemize}	
 




\section{Basics}

\begin{definition}{Polynomial time algorithm}{polytime}
An algorithm is said to be a {\em polynomial time algorithm} if its running time is $\textup{O}(n^k)$ for some $k\geq 1$ (where $n$ representes the size of a generic instance).
\end{definition}

{\bf Remark:} {\em Polynomial time algorithms} are also known as  {\em Polytime algorithms}.

\begin{definition}{Decision problem}{decision-problem} 
A decision problem  is  any problem whose only acceptable answers are either YES or NO (but not both at the same time).
\end{definition}



{\bf Some examples:} feasibility problems, decision version of optimization problems, etc.

\section{Complexity classes}

We will introduced 3 complexity classes (For see at least 495 more classes, please see \url{http://complexityzoo.uwaterloo.ca/Complexity_Zoo}).

\subsection{Polynomial time problems} 
\begin{definition}{The class $\PP$}{PP} 
Is the set of all decision problems for which a YES or NO answer for a  
particular instance can be {\bf obtained} in polytime.
\end{definition}

{\bf Remark:} For a particular problem $P$, there are 3 possibilities: (1) $P\in\PP$, (2) $P\notin\PP$, and $P\ \text{?}\ \PP$ (i.e., we don't know). 

{\bf Examples:}

\begin{multicols}{2}
\begin{itemize}
	\item Shortest path
	\item Max flow
	\item Min cut
	\item Matroid optimization
	\item Matchings
	\item Linear programming
\end{itemize}
\end{multicols}

	\subsection{Non-deterministic polynomial time problems}
	
	\begin{definition}{The class $\NP$}{NP2}
Is the set of all decision problems for which a YES answer for a  
particular instance can be {\bf verified} in polytime.
\end{definition}
	
	{\bf Examples:}

\begin{multicols}{2}
\begin{itemize}
\item All problems in $\PP$
\item Integer programming
\item TSP
\item Binary knapsack
\item Maximum independent set
\item Subset sum
\item Partition
\item SAT, $k$-SAT
\item Clique
\end{itemize}
\end{multicols}
	
	\subsection{Complements of problems in $\NP$}
	\begin{definition}{The class $\NP$}{NP} 
Is the set of all decision problems for which a NO answer for a  
particular instance can be {\bf verified} in polytime.
\end{definition}

	{\bf Examples:}

\begin{multicols}{2}
\begin{itemize}
\item All problems in $\PP$
\item Every ``complement'' of an $\NP$ problem
\item PRIMES
\end{itemize}
\end{multicols}

{\bf Remark}: Actually, $\textup{PRIMES}\in\NP$ (see {\em Pratt's certificates}), even better, it was recently proven that $\textup{PRIMES}\in\PP$ (by Manindra Agrawal, Neeraj Kayal, Nitin Saxena in 2004).

\section{Relationship between the classes}
\subsection{A basic result}
 
\begin{theorem}{}{} The following relationship holds:
 $$\PP\subseteq \NP\cap\coNP.$$
\end{theorem}

\subsection{An \$1,000,000 open question}
 The question ``Is $\PP=\NP$?'' is one of the most important problems in mathematics and computer science. A correct answer is worth 1 Million dollars! Most people believe that $\PP\neq \NP$.

 \section{Comparing problems, Polynomial time reductions}

{\bf Motivation:} We would like to solve problem $P_1$ by efficiently {\em reducing} it to another problem $P_2$ (why? Perhaps we know how to solve $P_2$!!!).

	\begin{definition}{Polynomial time reductions}{reduction}
Let $P_1,P_2$ be decision problems. We say that $P_1$ is {\em polynomially reducible to $P_2$} (denoted $P_1\leq_{\PP}P_2$) if there exists a function
$$f:P_1\rightarrow P_2$$
such that 
\begin{enumerate}
	\item For all $w\in P_1$ the answer to $w$ is YES if and only if the answer to $f(w)$ is YES.
	\item For all $w\in P_1$ $f(w)$ can be computed in polynomial time w.r.t to $\size(w)$. In particular, we must have that $\size(f(w))$ is polynomially bounded by $\size(w)$.
\end{enumerate}
\end{definition}

{\bf Remarks:} \begin{enumerate}
	\item In the above definition ``$f$ efficiently transforms an instance of $P_1$ into an instance of $P_2$''. In particular, if we know how to solve problem $P_2$, then we can solve problem $P_1$.
	\item Therefore, the notation $P_1\leq_{\PP}P_2$ makes sense: we are saying that $P_1$ is ``easier'' to solve than $P_2$, as any algorithm for $P_2$ would work for $P_1$. 
\end{enumerate} 



\section{Comparing problems, Polynomial time reductions}
\subsection{Definition}
{\bf Motivation:} We would like to solve problem $P_1$ by efficiently {\em reducing} it to another problem $P_2$ (why? Perhaps we know how to solve $P_2$!!!).

	\begin{definition}{Polynomial time reductions}{reducible}
Let $P_1,P_2$ be decision problems. We say that $P_1$ is {\em polynomially reducible to $P_2$} (denoted $P_1\leq_{\PP}P_2$) if there exists a function
$$f:P_1\rightarrow P_2$$
such that 
\begin{enumerate}
	\item For all $w\in P_1$ the answer to $w$ is YES if and only if the answer to $f(w)$ is YES.
	\item For all $w\in P_1$ $f(w)$ can be computed in polynomial time w.r.t to $\size(w)$. In particular, we must have that $\size(f(w))$ is polynomially bounded by $\size(w)$.
\end{enumerate}
\end{definition}

{\bf Remarks:} \begin{enumerate}
	\item In the above definition ``$f$ efficiently transforms an instance of $P_1$ into an instance of $P_2$''. In particular, if we know how to solve problem $P_2$, then we can solve problem $P_1$.
	\item Therefore, the notation $P_1\leq_{\PP}P_2$ makes sense: we are saying that $P_1$ is ``easier'' to solve than $P_2$, as any algorithm for $P_2$ would work for $P_1$. 
\end{enumerate} 
\subsection{Basic properties}

\begin{proposition}{}{} Let $P_1,P_2$ be two problems such that $P_1\leq_{\PP}P_2$ and assume that $P_2\in \PP$. Then $P_1\in\PP$.
\end{proposition}

\begin{proposition}{}{} Let $P_1,P_2$ be two problems such that $P_1\leq_{\PP}P_2$ and assume that $P_2\in \NP$. Then $P_1\in\NP$.
\end{proposition}

\begin{proposition}{}{} Let $P_1,P_2,P_3$ be three problems assume that $P_1\leq_{\PP}P_2$ and $P_2\leq_{\PP}P_3$. Then $P_1\leq_{\PP}P_3$.
\end{proposition}

\section{$\NP$-Completeness}
\subsection{The basics}
\begin{definition}{$\NP$-Completeness}{NP-complete}
A decision problem $P$ is said to be $\NP$-complete if:
\begin{enumerate}
	\item $P\in \NP$
	\item $Q\leq_{\PP}P$ for all $Q\in\NP$ (that is, every problem $Q$ in $\NP$ can be polynomially reduced to $P$). 
\end{enumerate}
\end{definition}

\begin{proposition}{}{} If $P$ is $\NP$-complete and $P\in\PP$ then $\PP=\NP$.
\end{proposition}
\subsection{Do $\NP$-complete problems  exist?}
\begin{theorem}{S. Cook, 1971}{sat-complete}
SAT is $\NP$-complete.  
\end{theorem}
\section{$\NP$-Hardness}
\begin{definition}{$\NP$-Completeness}{NPcomplete}
A problem $P$ is said to be $\NP$-hard if there exists a $\NP$-complete decision problem that can be reduced to it. 
\end{definition}

{\bf Remarks:}
\begin{itemize}
	\item $\NP$-complete problems are $\NP$-hard.
	\item Problems in $\NP$-hard not need to be decision problems.
	\item Optimization versions of $\NP$-complete decision problems are $\NP$-hard.
	\item If $P$ is $\NP$-hard and $P\in\PP$ then $\PP=\NP$.
\end{itemize}

\section{Exercises}

\begin{enumerate}
\item Let $P,Q$ be decision problems such that every instance of $Q$ is an instance of $P$ {\color{black}(that is $\{\text{instances in $Q$}\}\subseteq \{\text{instances in $P$}\}$)}.
\begin{enumerate}
	\item Give an example of $P,Q$ such that $Q\in \PP$ and $P\in \NP-\text{complete}$. 
		\item Give an example of $P,Q$ such that $Q,P\in \NP-\text{complete}$. 
\end{enumerate} 

{\bf Note:} You must prove that your problem belongs to the corresponding class unless we have proved or sketched the proof of that fact in class.\\ 

{\bf \Large Solution:}\\

\begin{enumerate}
	\item \begin{itemize}
		\item Let $P$ be the {\em Knapsack problem}. Then $P$ is $\NP$-complete (see Problem 5).
		\item Let $Q$ be the special case of the {\em Knapsack problem} where all weights are 1, that is, $a_1,\dots,a_n=1$. The following algorithm decides this special case:
		
			{\tt ALGORITHM:}
			
			\begin{itemize}
				\item[1.] List the objects $1,\dots,n$ in decreasing order according to $c_1,\dots,c_n$.
				\item[2.] Select the first $b$ objects from that list. Call this set $S$.
				\item[3.] If $\sum_{i\in S}c_i\leq k$, then  the output of the algorithm is YES. Else, the output is NO. 
			\end{itemize}
			
			Clearly, this algorithm is correct and runs in polynomial time w.r.t. to the instance. Hence, $Q\in\PP$.
			
	\end{itemize}
	\item \begin{itemize}
		\item Let $P$ be {\em SAT}.
		\item Let $Q$ be {\em 3-SAT}.
	\end{itemize}
	
	We showed in class that both $P$ and $Q$ are  $\NP$-complete problems.
	
\end{enumerate}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item A {\em Hamiltonian cycle} in a graph $G = (V,E)$ is a simple cycle that contains all the
vertices. A {\em Hamiltonian $s-t$ path} in a graph is a simple path from $s$ to $t$ that
contains all of the vertices. The associated decision problems are:
\begin{itemize}
	\item {\em Hamiltonian Cycle} {\bf Input:} $G=(V,E)$. {\bf Question:} Does there exist a hamiltonian cycle in $G$?
	\item  {\em Hamiltonian Path} {\bf Input:} $G=(V,E)$, $s,t\in V, s\neq t$. {\bf Question:} Does there exist a hamiltonian $s$-$t$ path in $G$?
\end{itemize}
\begin{enumerate}
	\item  Given that {\em Hamiltonian Cycle} is $\NP$-complete, prove that {\em Hamiltonian Path} is $\NP$-complete.
	\item Given that {\em Hamiltonian Cycle} is $\NP$-complete, prove that the optimization version of the TSP problem is $\NP$-hard. 
\end{enumerate}

{\bf \Large Solution:}\\



\begin{enumerate}
	\item {\bf  Step 1: {\em Hamiltonian Path} is in $\NP$.} 
	
	It is clear that {\em Hamiltonian Path} is in $\NP$, the certificate to a YES answer is the path itself. Given a Hamiltonian path from $s$ to $t$. We only need to travel along it to check that in fact it visits every vertex once and that starts in $s$ and ends in $t$. This takes $O(|E|)$ time. 
	
 {\bf Step 2: $\text{{\em Hamiltonian Cycle}}\leq_P\text{{\em Hamiltonian Path}}$.} 
	
	Given an instance $G=(V,E)$ of {\em Hamiltonian Cycle}, we construct an instance of {\em Hamiltonian Path} as follows:
	\begin{itemize}
		\item Let $v\in V$, the we construct the graph $G'=(V',E')$, where:
		\begin{itemize}
			\item $V'=V\setminus\{v\}\cup\{v_1,v_2\}$ (this takes $O(1)$). 
			\item $E'=\left(E\setminus\{\{v,u\}\tq \{v,u\}\in E\}\right)\cup \{\{v_1,u\}\tq \{v,u\}\in E\}\cup \{\{v_2,u\}\tq \{v,u\}\in E\}$ (this takes $O(|V|)$).
		\end{itemize}
		\item The instance is: $G'=(V',E'),\ s=v_1,\ t=v_2$. 
	\end{itemize}
	
	Notice the construction takes polynomial time w.r.t. the size of the instance.
	
	Finally, the fact that a YES to an instance of {\em Hamiltonian Cycle} is equivalent to a YES to the associated {\em Hamiltonian Path} instance follows by noticing that there exists a Hamiltonian cycle of the form
	$$vu_1u_2\dots u_{n-1}v$$
	in $G$ if and only if there exists and Hamiltonian $v_1$-$v_2$ path in $G'$ of the form
	$$v_1u_1u_2\dots u_{n-1}v_2$$	
	in $G'$.
	
	{\bf Note:} we are denoting $n=|V|$ and the notation $u_0u_1\dots u_k$ represents the path/cycle that uses the edges $\{u_0,u_1\}\{u_1,u_2\}\dots \{u_{k-1},u_k\}$ (in that order).
	
{\bf Conclusion:}	{\em Hamiltonian Path} is $\NP$-complete.
	
	\item 	Given an instance $G=(V,E)$ of {\em Hamiltonian Cycle}, the following algorithm decides whether the answer to this instance is yes or no:\\
	
	{\tt ALGORITHM:}
	\begin{itemize}
	  \item[1.] Given $V=\{v_1,\dots,v_n\}$, consider the cities $\{1,\dots,n\}$.
		\item[2.] Construct the objective function $c$ given by:
		$$c_{ij}=\begin{cases}0,\ & \{v_i,v_j\}\in E\\ 1,\ & \text{else.}\end{cases}$$
		\item[3.] Solve the TSP instance given above. Let $\alpha$ be the cost of the optimal tour.
		\item[4.] If $\alpha=0$, then the output of the algorithm is YES. Else, the output is NO.
	\end{itemize}
	
	The algorithm is correct since the definition of the objective function implies that the optimal tour has cost equals to zero if and only if the tour only travels between pairs of cities associated to edges in $E$. 
	
	Notice that the algorithm only need to solve the TSP problem once and that every other step takes polynomial time. Therefore, this is a valid polynomial time reduction since if we were able to solve the  optimization version of the TSP in polynomial time, we would also be able to decide {\em Hamiltonian Cycle} in polynomial time.

{\bf Conclusion:}	the optimization version of the TSP problem is $\NP$-hard.
	
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Given that the {\em node packing problem} is $\NP-\text{complete}$, show that the following problems are also $\NP-\text{complete}$:
\begin{enumerate}
	\item {\em Node cover}: {\bf Input:} $G=(V,E)$, $k\in \Z_+$. {\bf Question:}  Does there exist a set $S\subseteq V$ of size at most $k$ such that every edge of $G$ is incident to a node of $S$?
	\item {\em Uncapacitated facility location}. {\bf Input:} sets $M,N$ and integers k, $c_{ij}$, $f_j$ for $i\in M$, $j\in N$. {\bf Question:} Is there a set $S\subseteq N$ such that $\sum_{i\in M}\min_{j\in S} c_{ij} + \sum_{j\in S}f_j \leq k$? 
\end{enumerate}

Recall that {\em Node packing problem} is: {\bf Input:} $G=(V,E)$, $k\in \Z_+$. {\bf Question:} Does there exist an independent set of size at least $k$ in $G$?\\

{\bf \Large Solution:}\\

\begin{enumerate}
	\item {\bf Step 1: {\em Node cover}  is in $\NP$.} 
	
	It is clear that {\em Node cover} is in $\NP$, the certificate is the node cover itself. Verifying that the set of nodes is a cover can be done by checking that every edge is connected to a node in the given set. This takes $O(|E||V|)$ time. 
	
 {\bf Step 2: $\text{{\em Node packing}}\leq_P\text{{\em Node cover}}$.} 
	
	Given an instance $G=(V,E)$, $l\in\Z_+$ of {\em Node Packing}, we construct an instance of {\em Node cover} as follows:
	\begin{itemize}
		\item We construct the graph $G'=(V',E')$, where:
		\begin{itemize}
			\item $V'=V$ (this takes $O(1)$). 
			\item $E'=E$ (this takes $O(1)$).
		\end{itemize}
		\item We take $k=|V|-l$ (this takes $O(1)$).
		\item The instance is: $G'=(V',E'), k\in\Z_+$. 
	\end{itemize}
	
	Notice the construction takes polynomial time w.r.t. the size of the instance.
	
	Finally, the fact that a YES to an instance of {\em Node packing} is equivalent to a YES to the associated {\em Node cover} instance follows by noticing that a set $U\subseteq V$ is a node packing in $G$ if and only if no edge in $E$ has both end points in $U$, which is equivalent to say that every edge in $E$ has at least one end point in $V\setminus U$. Equivalently, this is saying that the set $V\setminus U$ is a node cover in $G'$.
		
{\bf Conclusion:}	{\em Node cover} is $\NP$-complete.

\item {\bf {\em Step 1: {\em Uncapacitated facility location}} is in $\NP$.} 
	
	It is clear that {\em Uncapacitated facility location} is in $\NP$, because given $S\subseteq N$, we can verify in $O(|M||N|+|N|)$ if
	$$\sum_{i\in M}\min_{j\in S} c_{ij} + \sum_{j\in S}f_j \leq k$$
	
 {\bf Step 2: $\text{{\em Node packing}}\leq_P\text{{\em Uncapacitated facility location}}$.} 
	
	Given an instance $G=(V,E)$, $l\in\Z_+$ of {\em Node Packing}, we construct an instance of {\em Uncapacitated facility location} as follows:
	\begin{itemize}
		\item $M=E$, $N=V$ (this takes $O(|E|)$).
		\item The objective
		$$c_{ij}=\begin{cases}|V|+1,\ & \text{if $j=uv$, where $u,v\neq i$}\\ 0,\ & \text{otherwise.}\end{cases}.$$
	  (This takes $O(|E|^2)$.) 	
		\item $k=|V|-l$ (this takes $O(1)$).
		\item $f_j=1$, for all $j\in N$ (this takes $O(|V|)$).
	\end{itemize}
	
	Notice the construction takes polynomial time w.r.t. the size of the instance.
	
\begin{itemize}
	\item {\bf YES to {\em Node Packing} $\Rightarrow$ YES to {\em Uncapacitated facility location}:}
	
	If $U$ is a node packing, with $|U|\geq l$, then $S=V\setminus U$ is a vertex cover, hence for all $i\in M$:
	$$\min\{c_{ij}\tq j\in S\}=0.$$
	
	And
	$$\sum_{j\in S}f_j=|S|=|V|-|U|\leq |V|-l\leq k.$$
	
	This implies $$\sum_{i\in M}\min_{j\in S} c_{ij} + \sum_{j\in S}f_j \leq k.$$
	
	Thus, the set $S\subseteq N$ gives a YES answer to {\em Uncapacitated facility location}. 
	
	\item {\bf YES to {\em Uncapacitated facility location} $\Rightarrow$ YES to  {\em Node Packing}:}



\end{itemize}
		


There exists $S\subseteq N$ such that
$$\sum_{i\in M}\min_{j\in S} c_{ij} + \sum_{j\in S}f_j \leq k.$$
By definition of the reduction from node packing, we have
\begin{itemize}
	\item[(i)] For all $i\in M$, $\min\{c_{ij}\tq j\in S\}\leq |V|$, which implies $\min\{c_{ij}\tq j\in S\}=0$.
	\item[(ii)] Let $U=V\setminus S$. By (i), $\sum_{j\in S}f_j=|S|=|V|-|U|$.
	\item[(iii)] By (i), if $u,v\in U$, then we must have $\{u,v\}\notin E$.
	\item[(iv)] By (ii), we have $|U|\geq l$. 
\end{itemize}

This implies that the set $U\subseteq V$ is a node packing with $|U|\geq l$, which gives a YES answer to  {\em Node Packing}.

{\bf Conclusion:}	{\em Uncapacitated facility location} is $\NP$-complete.
\end{enumerate}
\end{enumerate}




%
%
%\end{document}
