### 3.4. Experimental Framework and Evaluation Setup

Для всебічного оцінювання ефективності запропонованого підходу та його порівняння з класичною методикою побудови матриць переходу [4], було розроблено комплексний фреймворк експериментальних досліджень. Експериментальна база складається з двох взаємодоповнюючих етапів: контрольованого чисельного експерименту на синтетичних даних, де геометрична структура є повністю прозорою, та перевірки на реальному наборі даних MNIST, що дозволяє оцінити масштабованість методу для задач комп'ютерного зору.

Основна мета експериментів полягає у перевірці гіпотези про те, що введення обмежень еквіваріантності (симетрії) у процедуру побудови матриці переходу дозволяє суттєво зменшити структурну похибку пояснень та підвищити їх стійкість до трансформацій вхідних даних, зберігаючи при цьому прийнятний рівень точності реконструкції (fidelity).

#### 3.4.1. Протокол дослідження на синтетичних даних

Синтетичний тест був розроблений для верифікації математичного апарату в ідеалізованих умовах, що дозволяє ізолювати вплив симетрій від шумів, притаманних реальним даним.

Характеристика даних. У якості базового набору даних використовується вибірка з $m = 15$ зразків, що імітує структуру даних у задачі класифікації з трьома класами (по 5 зразків на клас).

* Формальна модель (FM): представлена матрицею $A \in \mathbb{R}^{15 \times 5}$ (App. 1.1), яка моделює простір глибоких ознак розмірності $k=5$.
* Ментальна модель (MM): представлена матрицею $B \in \mathbb{R}^{15 \times 4}$ (App. 1.1), що відповідає простору інтерпретованих ознак розмірності $l=4$.

Оскільки синтетичні матриці $A$ та $B$ задані явно як набір векторів і не мають прив'язки до реальних фізичних об'єктів (зображень чи сигналів), виникає методологічна проблема визначення дії групи симетрії на цих даних. Для коректного обчислення генераторів $J$ необхідно визначити, що означає «поворот» для абстрактного вектора з $A$.

Геометричне заземлення та візуалізація. Щоб надати даним геометричного змісту, ми вкладаємо кожну матрицю в двовимірний простір $\mathbb{R}^2$ за допомогою методу багатовимірного шкалювання (Multidimensional Scaling, MDS). Вибір MDS зумовлений його здатністю зберігати глобальні відстані між об'єктами, що є критичним для коректного відображення структури класів. Отримане 2D-вкладення інтерпретується як «візуальний простір об’єктів», на якому дія групи $SO(2)$ (групи поворотів на площині) є природною та інтуїтивно зрозумілою.

Алгоритм 2. Отримання генератора $J$ через 2D-поворот

Для знаходження матриць інфінітезимальних генераторів $J^A$ та $J^B$ у відповідних просторах ознак, коли пряма дія групи на вхідні дані відсутня, ми пропонуємо наступний алгоритм, що використовує простір візуалізації як проміжну ланку (proxy):

1. Редукція розмірності (Embedding): Вихідна матриця ознак (наприклад, $A \in \mathbb{R}^{15 \times 5}$) відображається у простір меншої розмірності $A_{2D} \in \mathbb{R}^{15 \times 2}$ за допомогою алгоритму MDS (Metric MDS). Це створює координатну систему, де можна застосувати оператор повороту.
2. Побудова зворотного відображення (Inverse Mapping): Оскільки MDS не має аналітичної зворотної функції, ми апроксимуємо її, навчаючи лінійний декодер (регресію) $D: \mathbb{R}^2 \rightarrow \mathbb{R}^5$. Модель навчається відображати координати точок $(x, y)$ з $A_{2D}$ назад у вектори $(a_1, \dots, a_5)$ з $A$. Лінійність декодера є свідомим спрощенням для збереження гладкості перетворень.
3. Імітація збурення (Perturbation): У 2D-просторі виконується поворот усіх точок хмари $A_{2D}$ на малий кут $\epsilon = 0.01$ рад навколо початку координат. Вибір малого $\epsilon$ є принциповим, оскільки генератори алгебри Лі описують поведінку системи саме в інфінітезимальному околі одиничного елемента групи. Отримуємо збурену матрицю $A_{2D, rot}$.
4. Реконструкція збурених ознак (Back-projection): Отримана матриця $A_{2D, rot}$ пропускається через навчений декодер $D$, що дає матрицю $A_{rot} \in \mathbb{R}^{15 \times 5}$ — прогноз того, як виглядали б глибокі ознаки, якби вихідні дані були повернуті.
5. Оцінка генератора (Estimation): Генератор $J^A$ обчислюється як розв'язок системи лінійних рівнянь відносно скінченних різниць:
    $$ \Delta A = \frac{A_{rot} - A}{\epsilon} \approx A (J^A)^\top. $$
    Розв'язок знаходиться методом найменших квадратів через псевдообернену матрицю $A$. Програмна реалізація даного підходу мовою Python наведена в App. 1.2.

Аналогічна процедура застосовується до матриці $B$ для отримання генератора $J^B \in \mathbb{R}^{4 \times 4}$. У результаті ми отримуємо пару матриць $J^A$ та $J^B$ (App. 1.3), які кодують дію однієї й тієї ж групи симетрії $SO(2)$ у різних просторах ознак. Це дозволяє сформулювати рівняння переплітання $T J^A - J^B T = 0$ та використати його як жорстке або м'яке обмеження при пошуку матриці переходу.

Для даного експерименту обрано $r=1$ генератор, що відповідає одновимірній групі поворотів площини. Таке спрощення дозволяє уникнути неоднозначностей при інтерпретації результатів та робить візуалізацію матриць системи $M$ більш наочною.

#### 3.4.2. Протокол дослідження на наборі даних MNIST

Для перевірки методу в умовах реальних високовимірних даних використовується еталонний датасет MNIST.

Опис даних. MNIST містить 70 000 зображень рукописних цифр у градаціях сірого розміром $28 \times 28$ пікселів. Використовується стандартне розбиття: 60 000 зображень для навчання та побудови матриці переходу, 10 000 — для тестування.

Архітектура моделей:

* Формальна модель (FM): Згорткова нейронна мережа (CNN), навчена на задачу класифікації цифр. Глибокі ознаки $a(x)$ витягуються з передостаннього повнозв'язного шару мережі ("pre-softmax"), що дає простір ознак розмірності $k = 490$. Цей шар містить високоабстраговану семантичну інформацію про об'єкт.
* Ментальна модель (MM): У якості зрозумілого для людини представлення використовується саме зображення у піксельному просторі. Зображення розгортається у вектор $b(x)$ розмірності $l = 784$ ($28 \times 28$). Таким чином, матриця переходу $T$ у цьому налаштуванні виконує роль лінійного декодера, що реконструює зображення цифри безпосередньо з її латентного коду.

Обчислення генераторів для MNIST. На відміну від синтетичного тесту, тут ми маємо доступ до прямої дії групи на вхідні дані. Генератори обертання обчислюються методом центральних скінченних різниць безпосередньо у просторі ознак:

1. До кожного вхідного зображення $x$ застосовуються малі повороти на кути $\pm \epsilon$ ($\epsilon = 0.1$ рад).
2. Обчислюються відгуки шару CNN $a(R(\epsilon)x)$ та $a(R(-\epsilon)x)$.
3. Апроксимація дії генератора $J^A$ на вектор $a(x)$ знаходиться як $\frac{a(R(\epsilon)x) - a(R(-\epsilon)x)}{2\epsilon}$.
4. Матриця $J^A$ знаходиться шляхом розв'язання задачі лінійної регресії на всьому навчальному наборі.
Аналогічно знаходиться $J^B$ для піксельного простору (хоча для пікселів дію повороту можна також задати аналітично, ми використовуємо чисельний підхід для узгодженості).

При побудові матриці переходу використовується параметр регуляризації $\lambda = 0.5$. Емпіричний аналіз (див. Розділ 4) показав, що це значення забезпечує сильне зменшення дефекту симетрії при збереженні візуальної якості реконструкції. Розв'язок системи $M \cdot u = Y$ для MNIST вимагає роботи з великими розрідженими матрицями, тому використовуються ітераційні методи (LSQR) або усічений SVD.

#### 3.4.3. Методика проведення експерименту та сценарії

Експериментальне дослідження структуроване за трьома сценаріями, що дозволяють послідовно оцінити переваги нового методу.

Сценарій 1: Базовий рівень (Baseline / Старий підхід)
У цьому сценарії відтворюється методика, описана в роботі [4]. Обчислюється статична матриця переходу $T_{old}$ шляхом мінімізації виключно функціонала похибки реконструкції (MSE Fidelity):
$$ T_{old} = \arg \min_T \| B - A T^\top \|_F^2. $$
Отримана матриця (App. 1.1 для синтетичних даних) використовується для прогнозування параметрів ментальної моделі $B_{old}^* = A T_{old}^\top$. Цей сценарій слугує точкою відліку ("lower bound" для якості апроксимації та "upper bound" для похибки симетрії).

Сценарій 2: Еквіваріантний підхід (Proposed Method / Новий підхід)
Застосовується Алгоритм 1 (див. Розділ 3.3). Будується розширена матриця системи $M$, що включає блоки $A \otimes I$ (fidelity) та $\lambda K$ (symmetry).
Для синтетичних даних із ваговим коефіцієнтом $\lambda = 0.5$ обчислюється матриця $T_{new}$. Прогнози отримуються як $B_{new}^* = A T_{new}^\top$ (App. 1.4). Основна увага приділяється аналізу того, як введення обмеження комутації впливає на структуру самої матриці $T$ (візуалізація теплових карт матриць) та на метрики якості.
Також проводиться дослідження чутливості методу до параметра $\lambda$ (ablation study), змінюючи його в діапазоні від 0 до 10, щоб продемонструвати керований компроміс між точністю та симетрією.

Сценарій 3: Тестування стійкості до трансформацій (Robustness Test)
Це критичний етап валідації, що перевіряє поведінку пояснювальної моделі при виході даних за межі навчальної вибірки шляхом геометричних трансформацій.

Для синтетичних даних, оскільки прямий зв'язок із вхідними образами відсутній, тест на стійкість реалізується через розширення Алгоритму 2:

1. У 2D-просторі візуалізації для кожного зразка генерується серія повернутих копій на кути $\alpha \in [-\pi/2; \pi/2]$ (що відповідає діапазону $\pm 90^\circ$).
2. Використовуючи навчений «зворотний місток» (декодер), ці точки відображаються у 5-вимірний простір, формуючи тестовий набір $A_{test}(\alpha)$.
3. Для кожного кута $\alpha$ обчислюються прогнози $B^*$ за допомогою $T_{old}$ та $T_{new}$.
4. Стійкість оцінюється шляхом порівняння траєкторії прогнозів із теоретично ідеальною траєкторією повороту ментальної моделі.

Для даних MNIST процедура є прямою: тестові зображення фізично повертаються на кути від $-90^\circ$ до $+90^\circ$, після чого обчислюються їхні глибокі ознаки. Ми порівнюємо якість реконструкції повернутих цифр (SSIM, PSNR) для матриць $T_{old}$ та $T_{new}$. Гіпотеза полягає в тому, що $T_{new}$ забезпечить більш стабільну якість зображення та менші артефакти при великих кутах повороту, оскільки вона "знає" про структуру обертання.

#### 3.4.4. Критерії оцінювання та метрики

Для кількісного порівняння результатів використовуються три групи метрик.

1. Метрики точності апроксимації (Fidelity Metrics).
Оцінюють, наскільки точно матриця переходу відтворює статичні ознаки.

* Mean Squared Error (MSE):* $\text{MSE}_{\text{fid}} = \frac{1}{m \cdot l} \| B - A T^\top \|_F^2$. Основна метрика для синтетичних даних.
* *Structural Similarity Index (SSIM):* Для MNIST, оскільки MSE погано корелює з людським сприйняттям якості зображення. Оцінює збереження структурної інформації цифри.
* *Peak Signal-to-Noise Ratio (PSNR):* Логарифмічна метрика якості відновлення сигналу для зображень.

2. Метрики симетрії (Symmetry/Equivariance Metrics).
Оцінюють ступінь порушення комутативної діаграми перетворень.

* *Symmetry Error (SymErr):* Норма Фробеніуса різниці комутаторів $\| T J^A - J^B T \|_F$. Ця величина (дефект симетрії) показує, наскільки сильно матриця переходу відхиляється від оператора сплітання (intertwining operator). Нульове значення означає ідеальну еквіваріантність.
* *Commutator Norm per Sample:* Для детального аналізу розподілу помилки по класах або зразках.

3. Метрики стійкості (Robustness Metrics).
Оцінюють стабільність прогнозів при варіації вхідних даних.

* *Drop in Performance:* Різниця між метрикою якості (SSIM/MSE) на оригінальних даних та на даних, повернутих на максимальний кут (наприклад, $90^\circ$).
* *Consistency Plot:* Графічна залежність метрики помилки від кута повороту $\alpha$. Більш полога крива свідчить про вищу стійкість моделі.

Очікується, що використання еквіваріантної матриці переходу (ЕМП) призведе до зменшення дефекту симетрії на кілька порядків порівняно з базовим методом. При цьому можливе незначне зростання MSE на навчальній вибірці (через введення додаткових обмежень в задачу оптимізації), проте на тестовій вибірці, особливо при наявності поворотів, $T_{new}$ повинна демонструвати кращу генералізацію та меншу варіативність помилки. Всі результати обчислень та візуалізації наведені у Розділі 4, а вихідні дані та програмний код для відтворення експериментів — у відповідних Додатках (App. 1).
