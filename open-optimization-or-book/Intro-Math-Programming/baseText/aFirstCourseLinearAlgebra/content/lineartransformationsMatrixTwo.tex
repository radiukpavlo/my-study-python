\section{The Matrix of a Linear Transformation II}

%Requires Linear Transformations. 

\begin{outcome}

\begin{enumerate}

\item[A.] Find the matrix of a linear transformation with respect to general bases. 

\end{enumerate}
\end{outcome}

We begin this section with an important lemma. 

\begin{lemma}{Mapping of a Basis}{mappingbasis}
Let $T: \mathbb{R}^n \mapsto \mathbb{R}^n$ be an isomorphism.  Then $T$ maps any basis of
$\mathbb{R}^n$ to another basis for $\mathbb{R}^n$. 

Conversely, if $T:
\mathbb{R}^n \mapsto \mathbb{R}^n$ is a linear transformation which
maps a basis of $\mathbb{R}^n$ to another basis of $\mathbb{R}^n$,
then it is an isomorphism.
\end{lemma}

\begin{proof}
First, suppose $T:\mathbb{R}^n \mapsto \mathbb{R}^n$ is a linear
transformation which is one to one and onto. Let $\left\{
\vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $ be a basis for
$\mathbb{R}^n$. We wish to show that $\left\{ T(\vect{v}_{1}),\cdots ,
T(\vect{v}_{n})\right\} $ is also a basis for $\mathbb{R}^n$. 

First consider why it is linearly independent. Suppose
$\sum_{k=1}^{n}a_{k}T(\vect{v}_{k})=\vect{0}$. Then by linearity we have $T\left(
\sum_{k=1}^{n}a_{k}\vect{v}_{k}\right) =\vect{0}$ and since $T$ is one
to one, it follows that $\sum_{k=1}^{n}a_{k}\vect{v}_{k}=\vect{0}$.
This requires that  each $a_{k}=0$ because $\left\{ \vect{v}_{1},\cdots,
\vect{v}_{n}\right\} $ is independent, and it follows that $\left\{
T(\vect{v}_{1}),\cdots , T(\vect{v}_{n})\right\} $ is linearly
independent. 


Next take $\vect{w}\in \mathbb{R}^n.$ Since $T$ is onto,
there exists $\vect{v}\in \mathbb{R}^n$ such that
$T(\vect{v})=\vect{w}$. Since $ \left\{ \vect{v}_{1},\cdots
,\vect{v}_{n}\right\} $ is a basis, in particular it is a spanning set
and there are scalars $b_{k}$ such that $T\left(
\sum_{k=1}^{n}b_{k}\vect{v} _{k}\right) =T\left( \vect{v}\right)
=\vect{w}$. Therefore $\vect{w} =\sum_{k=1}^{n}b_{k}T(\vect{v}_{k})$
which is in the $\func{span}\left\{ T(\vect{v}_{1}),\cdots ,
T(\vect{v}_{n})\right\} .$ Therefore, $\left\{ T(\vect{v}_{1}),\cdots
,T(\vect{v}_{n}) \right\} $ is a basis as claimed.

Suppose now that $T: \mathbb{R}^n \mapsto \mathbb{R}^n$ is a linear
transformation such that $T(\vect{v}_{i})=\vect{w}_{i}$ where
$\left\{\vect{v} _{1},\cdots ,\vect{v}_{n}\right\} $ and $\left\{
\vect{w}_{1},\cdots , \vect{w}_{n}\right\} $ are two bases for
$\mathbb{R}^n$. 

To show that $T$ is one to one, let $T\left(
\sum_{k=1}^{n}c_{k}\vect{v}_{k}\right) =\vect{0}$. Then
$\sum_{k=1}^{n}c_{k}T(\vect{v}_{k})=\sum_{k=1}^{n}c_{k}\vect{w}_{k}=\vect{
0}$. It follows that each $c_{k} = 0$ because it is given that
$\left\{ \vect{w} _{1},\cdots ,\vect{w}_{n}\right\} $ is linearly
independent. Hence $T\left( \sum_{k=1}^{n}c_{k}\vect{v}_{k}\right)
=\vect{0}$ implies that $\sum_{k=1}^{n}c_{k}\vect{v}_{k}=\vect{0}$ and
so $T$ is one to one.  

To show that $T$ is onto, let $\vect{w}$ be an arbitrary vector in
$\mathbb{R}^n$. This vector can be written as $\vect{w} =
\sum_{k=1}^{n}d_k\vect{w}_k =
\sum_{k=1}^{n}d_{k}T(\vect{v}_{k})=T\left( \sum_{k=1}^{n}d_{k}
\vect{v}_{k}\right) .$  Therefore, $T$ is also onto. 
\end{proof}

Consider now an important definition.

\index{vector!coordinate vector} \index{coordinate vector}
\begin{definition}{Coordinate Vector}{coordinatevector}
Let $B = \left\{ \vect{v}_1, \vect{v}_2, \cdots, \vect{v}_n \right\}$
be a basis for $\mathbb{R}^n$ and let $\vect{x}$ be an arbitrary
vector in $\mathbb{R}^n$. Then $\vect{x}$ is uniquely represented as
$\vect{x} = a_1\vect{v}_1 +
a_2\vect{v}_2 + \cdots + a_n\vect{v}_n$ for scalars $a_1, \cdots,
a_n$. 

The  \textbf{coordinate vector} of $\vect{x}$ with respect to the
basis $B$, written $C_B(\vect{x})$ or  $[\vect{x}]_B$,  is given by \index{coordinate vector}
\[
C_B(\vect{x}) =  C_B \left( a_1\vect{v}_1 + a_2\vect{v}_2 + \cdots + a_n\vect{v}_n \right) = \leftB
\begin{array}{c}
a_1 \\
a_2 \\
\vdots \\
a_n
\end{array} \rightB
\] 
\end{definition}

Consider the following example.

\begin{example}{Coordinate Vector}{coordinatevector}
Let $B = \left\{ \leftB \begin{array}{r}
1 \\
0 
\end{array} \rightB, \leftB \begin{array}{r}
-1 \\
1
\end{array} \rightB \right\}$ be a basis of $\mathbb{R}^2$ and let $\vect{x} = \leftB
\begin{array}{r}
3 \\
-1
\end{array}
\rightB$ be a vector in $\mathbb{R}^2$. Find $C_B(\vect{x})$. 
\end{example}

\begin{solution}
First, note the order of the basis is important so label the vectors in the basis $B$ as 
\[
B = \left\{ \leftB \begin{array}{r}
1 \\
0 
\end{array} \rightB, \leftB \begin{array}{r}
-1 \\
1
\end{array} \rightB \right\} = \left\{ \vect{v}_1, \vect{v}_2 \right\} \]
Now we need to find $a_1, a_2$ such that $\vect{x} = a_1 \vect{v}_1 + a_2 \vect{v}_2$, that is:
\[
\leftB
\begin{array}{r}
3 \\
-1
\end{array}
\rightB
=
a_1 
\leftB \begin{array}{r}
1 \\
0 
\end{array} \rightB
+ a_2
\leftB \begin{array}{r}
-1 \\
1 
\end{array} \rightB\]
Solving this system gives $a_1 = 2, a_2 = -1$. Therefore the coordinate vector of $\vect{x}$ with respect to the basis $B$ is 
\[
C_B(\vect{x})
=
\leftB \begin{array}{r}
a_1 \\
a_2 
\end{array}\rightB
= \leftB \begin{array}{r}
2 \\
-1 
\end{array} \rightB
\]
\end{solution}

Given any basis $B$, one can easily verify that the coordinate function is actually an isomorphism. 

\begin{theorem}{$C_B$ is a Linear Transformation}{coordlintransf}
For any basis $B$ of $\mathbb{R}^n$, the coordinate function
\[ C_B: \mathbb{R}^n  \rightarrow \mathbb{R}^n  \]
is a linear transformation, and moreover an isomorphism. 
\end{theorem}

We now discuss the main  result  of this section, that is how
to represent a linear transformation with respect to different
bases.

\begin{theorem}{The Matrix of a Linear Transformation}{matrixlintransfbases}
Let $T: \mathbb{R}^n \mapsto \mathbb{R}^m$ be a linear transformation,
and let $B_1$ and $B_2$ be bases of $\mathbb{R}^{n}$ and
$\mathbb{R}^{m}$ respectively.

Then the following holds
\begin{equation}
C_{B_2} T = M_{B_{2} B_{1}} C_{B_1}   \label{matrixequation}
\end{equation}
where $M_{B_{2} B_{1}}$  is a unique  $m \times n$  matrix.

If the basis $B_1$ is given by $B_1=\{ \vect{v}_1, \cdots, \vec{v}_n \}$ in this order, then 

\[  M_{B_{2} B_{1}} = \leftB C_{B_2}(T(\vec{v}_1)) \; C_{B_2}(T(\vec{v}_2)) \; \cdots C_{B_2}(T(\vec{v}_n)) \rightB \]
\end{theorem}

\begin{proof}
The above equation \ref{matrixequation} can be represented by the following diagram.
\begin{equation*}
\begin{array}{rrcll}
&  & T &  &  \\
& \mathbb{R}^n & \rightarrow  & \mathbb{R}^m & \\
& C_{B_{1} }\downarrow  & \circ  & \downarrow C_{B_{2} } &  \\
& \mathbb{R}^{n} & \rightarrow  & \mathbb{R}^{m} &  \\
&  & M_{B_{2} B_{1} } &  &
\end{array}
\end{equation*}

Since $C_{B_1}$ is an isomorphism, then the matrix we are looking for is the matrix of the linear transformation 
\[   C_{B_2} T C^{-1}_{B_1} : \mathbb{R}^n \mapsto \mathbb{R}^m. \]
By Theorem \ref{thm:matrixoflineartransformation}, the columns are
given by the image of the standard basis $\left\{ \vect{e}_1,
\vect{e}_2, \cdots, \vect{e}_n \right\}$. But since $C^{-1}_{B_1}( \vec{e}_i) = \vec{v}_i$, we readily obtain that 

\[ \begin{array}{ll} 
M_{B_{2} B_{1}} 
& = \leftB C_{B_2}T C^{-1}_{B_1} (\vec{e}_1) \;\; C_{B_2}T C^{-1}_{B_1} (\vec{2}_2) \;\; \cdots \;\; C_{B_2}T C^{-1}_{B_1} (\vec{e}_n) \rightB \\
& = \leftB C_{B_2}(T(\vec{v}_1)) \;\; C_{B_2}(T(\vec{v}_2)) \;\; \cdots \;\; C_{B_2}(T(\vec{v}_n)) \rightB 
\end{array}\]
and this completes the proof. 
\end{proof}

Consider the following example.

\begin{example}{Matrix of a Linear Transformation}{matrixlintransf}
Let $T: \mathbb{R}^2 \mapsto \mathbb{R}^2$ be a linear transformation defined by $T \left( \leftB \begin{array}{r}
a \\
b
\end{array} \rightB \right) = \leftB \begin{array}{r}
b \\
a 
\end{array} \rightB$. 

Consider the two bases
\[
B_1 = \left\{ \vect{v}_{1}, \vect{v}_{2} \right\} = \left\{ \leftB \begin{array}{r}
1 \\
0
\end{array}\rightB, \leftB \begin{array}{r}
-1 \\
1
\end{array}
\rightB
\right\}
\]
 and 
\[
B_2 = \left\{ \leftB \begin{array}{r}
1 \\
1
\end{array}
\rightB, \leftB \begin{array}{r}
1 \\
-1
\end{array}
\rightB
\right\}
\]

Find the matrix $M_{B_2,B_1}$ of $T$ with respect to the bases $B_1$ and $B_2$. 
\end{example}

\begin{solution}
By Theorem \ref{thm:matrixlintransfbases}, the columns of $M_{B_{2} B_{1}}$ are the
coordinate vectors of $T(\vect{v}_{1}), T(\vect{v}_{2})$ with respect
to $B_2$.

Since \[
T \left( 
\leftB \begin{array}{r}
1 \\
0
\end{array}\rightB \right)
= \leftB \begin{array}{r}
0 \\
1
\end{array}\rightB ,\]
a standard calculation yields 
\[
 \leftB \begin{array}{r}
0 \\
1
\end{array}\rightB 
 =  
\left(\frac{1}{2} \right)\leftB \begin{array}{r}
1 \\
1
\end{array} 
\rightB
+
\left(-\frac{1}{2} \right)
\leftB 
\begin{array}{r}
1 \\
-1
\end{array} \rightB,
\]
the first column of $M_{B_{2} B_{1}}$ is $\leftB \begin{array}{r}
\vspace{0.05in}\frac{1}{2}\\
\vspace{0.05in}-\frac{1}{2}
\end{array}\rightB$. 

The second column is found in a similar way. We have 
\[
T \left( 
\leftB \begin{array}{r}
-1 \\
1
\end{array}
\rightB \right)
= \leftB \begin{array}{r}
1 \\
-1
\end{array}\rightB , \]
and with respect to $B_2$ calculate:
\[ 
\leftB \begin{array}{r}
1 \\
-1
\end{array}\rightB
=
0 \leftB \begin{array}{r}
1 \\
1
\end{array} 
\rightB
+
1
\leftB 
\begin{array}{r}
1 \\
-1
\end{array} \rightB
\]
Hence the second column of $M_{B_{2} B_{1}}$ is given by $\leftB \begin{array}{r}
0 \\
1
\end{array} \rightB$. We thus obtain 
\[
M_{B_{2} B_{1}} = \leftB
\begin{array}{rr}
\vspace{0.05in}\frac{1}{2} & 0 \\
\vspace{0.05in}-\frac{1}{2} & 1 
\end{array}
\rightB \]

We can verify that this is the correct matrix $M_{B_{2} B_{1}}$ on the specific example
\[
\vect{v} = \leftB 
\begin{array}{r}
3 \\
-1 
\end{array}
\rightB \]
First applying $T$ gives
\[
T( \vect{v} ) =
T \left( 
\leftB 
\begin{array}{r}
3 \\
-1 
\end{array}
\rightB \right) = \leftB 
\begin{array}{r}
-1\\
3
\end{array}
\rightB
\]
and one can compute that  
\[ C_{B_2} 
 \left( 
\leftB 
\begin{array}{r}
-1 \\
3 
\end{array}
\rightB \right) = \leftB 
\begin{array}{r}
1\\
-2
\end{array}
\rightB .\]

On the other hand, one compute $C_{B_1}( \vect{v})$ as 
\[ C_{B_1} 
 \left( 
\leftB 
\begin{array}{r}
3 \\
-1 
\end{array}
\rightB \right) = \leftB 
\begin{array}{r}
2\\
-1
\end{array}
\rightB ,\]
and finally applying $M_{B_1 B_2}$ gives

\[\leftB
\begin{array}{rr}
\vspace{0.05in}\frac{1}{2} & 0 \\
\vspace{0.05in}-\frac{1}{2} & 1 
\end{array}
\rightB 
\leftB \begin{array}{r}
2 \\
-1
\end{array}\rightB 
= \leftB \begin{array}{r}
1 \\
-2
\end{array}
\rightB \]
as above. 

We see that the same vector results from either method, as suggested by Theorem \ref{thm:matrixlintransfbases}.
\end{solution}

If the bases $B_1$ and $B_2$ are equal, say $B$, then we write $M_{B}$ instead of  $M_{B B}$. 
The following example illustrates how to compute  such a matrix. Note that this is what we did earlier when we considered only
$B_1=B_2$ to be the standard basis. 

\begin{example}{Matrix of a Linear Transformation with respect to an Arbitrary   Basis}{arbitrarybases}

Consider the basis $B$ of $\mathbb{R}^3$ given by 
\begin{equation*}
B = \{\vect{v}_1 , \vect{v}_2,  \vect{v}_3  \} =
\left\{
\leftB
\begin{array}{r}
1 \\
0 \\
1
\end{array}
\rightB ,\leftB
\begin{array}{r}
1 \\
1 \\
1
\end{array}
\rightB ,\leftB
\begin{array}{r}
-1 \\
1 \\
0
\end{array}
\rightB \right\}
\]

And let $T :\mathbb{R}^{3}\mapsto \mathbb{R}^{3}$ be the linear transformation 
defined on $B$ as:
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
0 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
1 \\
-1 \\
1
\end{array}
\rightB ,T \leftB
\begin{array}{c}
1 \\
1 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
1 \\
2 \\
-1
\end{array}
\rightB ,T\leftB
\begin{array}{r}
-1 \\
1 \\
0
\end{array}
\rightB =\leftB
\begin{array}{r}
0 \\
1 \\
1
\end{array}
\rightB
\end{equation*}

\begin{enumerate}
\item Find the matrix  $M_{B}$ of $T$ relative to the basis $B$.
\item Then find the usual matrix of $T$ with respect to the standard basis of $\mathbb{R}^{3}$.
\end{enumerate}

\end{example}

\begin{solution}

Equation  \ref{matrixequation}  gives $ C_BT=M_{B}C_B$, and thus 
$M_{B} = C_BTC^{-1}_B$. 

Now $C_B(\vec{v}_i) = \vec{e}_i$, so the matrix of $C_B^{-1}$ (with respect to the standard basis) is given by
\[ \leftB  C_B^{-1}(\vec{e}_1) \;\; C_B^{-1}(\vec{e}_2) \;\; C_B^{-1}(\vec{e}_2) \rightB =  
\leftB 
\begin{array}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{array}
\rightB
\]
Moreover the matrix of  $T C_B^{-1}$ is given by 
\[ \leftB  TC_B^{-1}(\vec{e}_1) \;\; TC_B^{-1}(\vec{e}_2) \;\; TC_B^{-1}(\vec{e}_2) \rightB =  
\leftB
\begin{array}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{array}
\rightB
\]
Thus 
\[ \begin{array}{ll}
M_{B} & =  C_BTC^{-1}_B =  [C^{-1}_B]^{-1} [TC^{-1}_B] \\
	& = 
\leftB
\begin{array}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{array}
\rightB ^{-1}\leftB 
\begin{array}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{array}
\rightB \\
&=\leftB 
\begin{array}{rrr}
2 & -5 & 1 \\ 
-1 & 4 & 0 \\ 
0 & -2 & 1
\end{array}
\rightB
\end{array}
\]


Consider how this works. Let $\vect{b} = \leftB
\begin{array}{r}
b_1 \\
b_2 \\
b_3
\end{array}
\rightB$ be an arbitrary vector in $\mathbb{R}^3$. 

Apply $C^{-1}_{B}$ to $\vect{b}$ to get 
\begin{equation*}
b_1\leftB 
\begin{array}{r}
1 \\
0 \\
1
\end{array}
\rightB + b_2\leftB 
\begin{array}{r}
1 \\
1 \\
1
\end{array}
\rightB + b_3\leftB 
\begin{array}{r}
-1 \\
1 \\
0
\end{array}
\rightB 
\end{equation*}
Apply $T$ to this linear combination to obtain 
\begin{equation*}
b_1\leftB 
\begin{array}{r}
1 \\ 
-1 \\ 
1
\end{array}
\rightB + b_2\leftB 
\begin{array}{r}
1 \\ 
2 \\ 
-1
\end{array}
\rightB + b_3\leftB 
\begin{array}{r}
0 \\ 
1 \\ 
1
\end{array}
\rightB =\leftB 
\begin{array}{c}
b_1+b_2 \\ 
-b_1 + 2b_2+ b_3 \\ 
b_1-b_2+b_3
\end{array}
\rightB
\end{equation*}
Now take the matrix $M_{B}$ of the transformation (as found above) and multiply it by $\vect{b}$. 
\begin{equation*}
\leftB 
\begin{array}{rrr}
2 & -5 & 1 \\ 
-1 & 4 & 0 \\ 
0 & -2 & 1
\end{array}
\rightB \leftB 
\begin{array}{c}
b_1 \\ 
b_2 \\ 
b_3
\end{array}
\rightB =\leftB 
\begin{array}{c}
2b_1-5b_2+b_3 \\ 
-b_1 + 4b_2 \\ 
-2b_2 + b_3
\end{array}
\rightB
\end{equation*}
Is this the coordinate vector of the above relative to the given basis? We check as follows. 
\begin{equation*}
\left( 2b_1-5b_2+b_3\right) \leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1
\end{array}
\rightB +\left( -b_1 + 4b_2\right) \leftB 
\begin{array}{c}
1 \\ 
1 \\ 
1
\end{array}
\rightB +\left( -2b_2+b_3\right) \leftB 
\begin{array}{c}
-1 \\ 
1 \\ 
0
\end{array}
\rightB
\end{equation*}
\begin{equation*}
= \leftB 
\begin{array}{c}
b_1+b_2 \\ 
-b_1 + 2b_2+b_3 \\ 
b_1-b_2+b_3
\end{array}
\rightB
\end{equation*}
You see it is the same thing.

Now lets find the matrix of $T$ with respect to the standard basis. Let $A$ be
this matrix. That is, multiplication by $A$ is the same as doing $T$. Thus 
\begin{equation*}
A\leftB 
\begin{array}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{array}
\rightB =\leftB 
\begin{array}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{array}
\rightB
\end{equation*}
Hence 
\begin{equation*}
A=\leftB 
\begin{array}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{array}
\rightB \leftB 
\begin{array}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{array}
\rightB ^{-1}=\leftB 
\begin{array}{rrr}
0 & 0 & 1 \\ 
2 & 3 & -3 \\ 
-3 & -2 & 4
\end{array}
\rightB
\end{equation*}
Of course this is a very different matrix than the matrix of the linear
transformation with respect to the non standard basis.
\end{solution}
