\section{Linear Independence}

\begin{outcome}
\begin{enumerate}
\item[A.] Determine if a set is linearly independent.
\end{enumerate}
\end{outcome}

In this section, we will again explore concepts introduced earlier in terms of $\mathbb{R}^n$ and extend them to apply to abstract vector spaces. 

\begin{definition}{Linear Independence}{linearindependencevectorspace}
Let $V$ be a vector space. If $\{\vect{v}_{1},\cdots ,\vect{v}_{n}\} \subseteq V,$ then it is linearly independent
\index{linearly independent} if
\begin{equation*}
\sum_{i=1}^{n}a_{i}\vect{v}_{i}=\vect{0} \;\mbox{implies}\;
a_{1}=\cdots =a_{n}=0
\end{equation*}
where the $a_i$ are real numbers. 
\end{definition}

The
set of vectors is called linearly dependent if it is not linearly independent.
\index{linearly dependent}

\begin{example}{Linear Independence}{linearindependencepoly}
Let $S \subseteq \mathbb{P}_2$ be a set of polynomials given by
\[
S = \left\{ x^2 + 2x - 1, 2x^2 - x + 3 \right\}
\]
Determine if $S$ is linearly independent. 
\end{example}

\begin{solution}
To determine if this set $S$ is linearly independent, we write
\[
a ( x^2 + 2x -1 ) + b(2x^2 - x + 3) = 0x^2 + 0x + 0
\]
If it is linearly independent, then $a=b=0$ will be the only solution. We proceed as follows. 
\begin{eqnarray*}
a ( x^2 + 2x -1 ) + b(2x^2 - x + 3) &=& 0x^2 + 0x + 0 \\
ax^2 + 2ax - a + 2bx^2 - bx + 3b &=& 0x^2 + 0x + 0 \\
(a+2b)x^2 + (2a -b)x  - a + 3b &=&  0x^2 + 0x + 0
\end{eqnarray*}

It follows that
\begin{eqnarray*}
a + 2b &=& 0 \\
2a - b &=& 0 \\
-a + 3b &=& 0
\end{eqnarray*}

The augmented matrix and resulting \rref \;are given by
\[
\leftB \begin{array}{rr|r}
1 & 2 & 0 \\
2 & -1 & 0 \\
-1 & 3 & 0 
\end{array} \rightB 
\rightarrow \cdots \rightarrow
\leftB \begin{array}{rr|r}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0 
\end{array} \rightB 
\]

Hence the solution is $a=b=0$ and the set is linearly independent. 
\end{solution}

The next example shows us what it means for a set to be dependent.

\begin{example}{Dependent Set}{dependent}
Determine if the set $S$ given below is independent. 
\[
S=\left\{
\leftB\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\rightB,
\leftB\begin{array}{c} 1 \\ 1 \\ 1 \end{array}\rightB,
\leftB\begin{array}{c} 1 \\ 3 \\ 5 \end{array}\rightB \right\}
\]
\end{example}

\begin{solution}
To determine if $S$ is linearly independent, we look for solutions to
\[ 
a\leftB\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\rightB
+b\leftB\begin{array}{c} 1 \\ 1 \\ 1 \end{array}\rightB
+c\leftB\begin{array}{c} 1 \\ 3 \\ 5 \end{array}\rightB
=\leftB\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\rightB
\]
Notice that this equation has nontrivial solutions, 
for example $a=2$, $b=3$ and $c=-1$. Therefore $S$ is dependent. 
\end{solution}

The following is an important result regarding dependent sets.

\begin{lemma}{Dependent Sets}{dependent}
Let $V$ be a vector space and suppose $W = \left\{ \vect{v}_1, \vect{v}_2, \cdots, \vect{v}_k \right\}$ is a subset of $V$. Then $W$ is dependent if and only if $\vect{v}_i$ can be written as a linear combination of $\left\{ \vect{v}_1, \vect{v}_2, \cdots, \vect{v}_{i-1}, \vect{v}_{i+1}, \cdots,  \vect{v}_k \right\}$ for some $i \leq k$. 
\end{lemma}

Revisit Example \ref{exa:dependent} with this in mind. Notice that we can write one of the three vectors as a combination of the others.
\[
\leftB\begin{array}{c} 1 \\ 3 \\ 5 \end{array}\rightB
=
2\leftB\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\rightB
+3\leftB\begin{array}{c} 1 \\ 1 \\ 1 \end{array}\rightB
\]

By Lemma \ref{lem:dependent} this set is dependent. 

If we know that one particular set is linearly independent, we can use this information to determine if a related set is linearly independent. Consider the following example.

\begin{example}{Related Independent Sets}{relatedindependent}
Let $V$ be a vector space and suppose $S \subseteq V$ is a set of linearly independent vectors given by $S = \left\{ \vect{u}, \vect{v}, \vect{w} \right\}$. Let $R \subseteq V$ be given by $R = \left\{ 2\vect{u} - \vect{w}, \vect{w} + \vect{v}, 3\vect{v} + \frac{1}{2} \vect{u} \right\}$. Show that $R$ is also linearly independent. 
\end{example}

\begin{solution}
To determine if $R$ is linearly independent, we write 
\[
a(2\vect{u} - \vect{w}) + b(\vect{w} + \vect{v}) + c( 3\vect{v} + \vspace{0.05in}\frac{1}{2}\vect{u}) = \vect{0} \]
If the set is linearly independent, the only solution will be $a=b=c=0$. We proceed as follows.  
\begin{eqnarray*}
a(2\vect{u} - \vect{w}) + b(\vect{w} + \vect{v}) + c( 3\vect{v} + \vspace{0.05in}\frac{1}{2} \vect{u}) &=& \vect{0} \\
2a\vect{u} - a\vect{w} + b\vect{w} + b\vect{v}  + 3c\vect{v} + \vspace{0.05in}\frac{1}{2}c\vect{u} &=& \vect{0}\\
(2a + \vspace{0.05in}\frac{1}{2}c) \vect{u} + (b+3c)\vect{v} + (-a + b) \vect{w} &=& \vect{0}
\end{eqnarray*}

We know that the set $S = \left\{ \vect{u}, \vect{v}, \vect{w} \right\}$ is linearly independent, which implies that the coefficients in the last line of this equation must all equal $0$. 
In other words:
\begin{eqnarray*}
2a + \vspace{0.05in}\frac{1}{2} c &=& 0 \\
b + 3c &=& 0 \\
-a + b &=& 0 
\end{eqnarray*}

The augmented matrix and resulting \rref \;are given by:
\[
\leftB \begin{array}{rrr|r}
2 & 0 & \vspace{0.05in}\frac{1}{2} & 0 \\
0 & 1 & 3 & 0 \\
-1 & 1 & 0 & 0 
\end{array}\rightB
\rightarrow \cdots \rightarrow
\leftB \begin{array}{rrr|r}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 
\end{array}\rightB
\]
Hence the solution is $a=b=c=0$ and the set is linearly independent. 
\end{solution}

The following theorem was discussed in terms in $\mathbb{R}^n$. We consider it here in the general case.

\begin{theorem}{Unique Representation}{uniquerepresentation}
Let $V$ be a vector space and let $U = \left\{ \vect{v}_1, \cdots, \vect{v}_k \right\} \subseteq V$ be an independent set. If $\vect{v} \in \func{span} \;U$, then $\vect{v}$ can be written uniquely as a linear combination of the vectors in $U$. 
\end{theorem}

Consider the span of a linearly independent set of vectors. Suppose we take a vector which is not in this span and add it to the set. The following lemma claims that the resulting set is still linearly independent. 

\begin{lemma}{Adding to a Linearly Independent Set}{addinglinearlyindependent}
Suppose $\vect{v}\notin \func{span}\left\{ \vect{u}_{1},\cdots ,\vect{u}_{k}\right\} $ and $\left\{ \vect{u}_{1},\cdots ,
\vect{u}_{k}\right\} $ is linearly independent. Then the set
\begin{equation*}
\left\{ \vect{u}_{1},\cdots ,\vect{u}_{k},\vect{v} \right\}
\end{equation*}
is also linearly independent.
\end{lemma}

\begin{proof}
Suppose $\sum_{i=1}^{k}c_{i}\vect{u}_{i}+d\vect{v}=
\vect{0}.$ It is required to verify that each $c_{i}=0$ and that $d=0.$
But if $d\neq 0,$ then you can solve for $\vect{v}$ as a linear
combination of the vectors, $\left\{ \vect{u}_{1},\cdots ,\vect{u}
_{k}\right\} $, 
\begin{equation*}
\vect{v}=-\sum_{i=1}^{k}\left( \frac{c_{i}}{d}\right) \vect{u}_{i}
\end{equation*}
contrary to the assumption that $\vect{v}$ is not in the span of the $\vect{u}_{i}$. Therefore, $d=0.$ But then $\sum_{i=1}^{k}c_{i}
\vect{u}_{i}=\vect{0}$ and the linear independence of $\left\{ \vect{u}
_{1},\cdots ,\vect{u}_{k}\right\} $ implies each $c_{i}=0$ also. 
\end{proof}

Consider the following example.

\begin{example}{Adding to a Linearly Independent Set}{addinglinind}
Let $S \subseteq M_{22}$ be a linearly independent set given by 
\[
S  = \left\{ \leftB \begin{array}{rr}
1 & 0 \\
0 & 0 
\end{array} \rightB, \leftB \begin{array}{rr}
0 & 1 \\
0 & 0 
\end{array} \rightB \right\}
\]
Show that the set $R \subseteq M_{22}$ given by 
\[
R = \left\{ \leftB \begin{array}{rr}
1 & 0 \\
0 & 0 
\end{array} \rightB, \leftB \begin{array}{rr}
0 & 1 \\
0 & 0 
\end{array} \rightB, \leftB \begin{array}{rr}
0 & 0 \\
1 & 0 
\end{array} \rightB \right\}
\]
is also linearly independent.
\end{example}

\begin{solution}
Instead of writing a linear combination of the matrices which equals
$0$ and showing that the coefficients must equal $0$, we can instead
use Lemma \ref{lem:addinglinearlyindependent}.

To do so, we show that 
\[
\leftB \begin{array}{rr}
0 & 0 \\
1 & 0 
\end{array} \rightB
\notin
\func{span}\left\{ \leftB \begin{array}{rr}
1 & 0 \\
0 & 0 
\end{array} \rightB, \leftB \begin{array}{rr}
0 & 1 \\
0 & 0 
\end{array} \rightB \right\}
\]

Write 
\begin{eqnarray*}
\leftB \begin{array}{rr}
0 & 0 \\
1 & 0 
\end{array} \rightB
&=&  a\leftB \begin{array}{rr}
1 & 0 \\
0 & 0 
\end{array} \rightB +  b\leftB \begin{array}{rr}
0 & 1 \\
0 & 0 
\end{array} \rightB \\
&=&
\leftB \begin{array}{rr}
a & 0 \\
0 & 0 
\end{array} \rightB +  \leftB \begin{array}{rr}
0 & b \\
0 & 0 
\end{array} \rightB \\
&=& \leftB \begin{array}{rr}
a & b \\
0 & 0 
\end{array} \rightB
\end{eqnarray*}

Clearly there are no possible $a,b$ to make this equation true. Hence the new matrix does not lie in the span of the matrices in $S$. By Lemma \ref{lem:addinglinearlyindependent}, $R$ is also linearly independent.
\end{solution}