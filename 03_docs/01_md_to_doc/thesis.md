# Методи та засоби інтеграції знань в моделі штучного інтелекту медичних діагностичних комплексів

---

# Розділ 1. Аналіз сучасних методів та підходів до інтеграції знань діагностичних моделей в системи штучного інтелекту медичних діагностичних комплексів

## 1.1. Актуальність застосування діагностичних моделей в системах штучного інтелекту медичних діагностичних комплексів

Сучасний етап розвитку медичної науки та клінічної практики характеризується експоненціальним зростанням обсягів діагностичних даних, що вимагає впровадження новітніх інформаційних технологій для їх обробки, аналізу та інтерпретації. Протягом останніх десятиліть спостерігається фундаментальний прогрес у галузі комп'ютерної детекції та діагностики (Computer-Aided Detection/Diagnosis, CAD), особливо у сферах медичної візуалізації та радіології. Цей технологічний стрибок значною мірою зумовлений розвитком методів глибокого навчання (Deep Learning, DL), які продемонстрували здатність апроксимувати складні нелінійні залежності у багатовимірних просторах ознак [1], [2]. У роботах [3], [4] зазначається, що цей вплив поширюється не лише на стаціонарні системи, але й на мобільні та бездротові мережі передачі медичних даних.

Досягнувши безпрецедентних успіхів у класичних задачах комп'ютерного зору, різноманітні архітектури DL-моделей, переважно глибокі згорткові нейронні мережі (Convolutional Neural Networks, CNN), були успішно адаптовані до специфіки медичних зображень. Спектр застосувань охоплює критично важливі напрямки, включаючи раннє виявлення раку молочної залози на мамограмах, де значний внесок зробили дослідження [5], [6]. Окремої уваги заслуговують методи ідентифікації легеневих вузликів на КТ, представлені у працях [7], [8], а також підходи до діагностики глаукоми за зображеннями очного дна [9] та дерматоскопічний аналіз новоутворень шкіри [10], [11].

![Концептуальна схема інтелектуальної системи CAD: трансформація вхідних сенсорних даних у простір клінічних рішень з урахуванням доменних знань.](figs/figure_ch1_cad_concept.pdf)
*Рисунок 1.1: Концептуальна схема інтелектуальної системи CAD: трансформація вхідних сенсорних даних у простір клінічних рішень з урахуванням доменних знань.*

У найбільш загальному вигляді інтелектуальну систему CAD, побудовану на основі методів глибокого навчання, можна формалізувати як параметричну функцію відображення $f_{CAD}$, що трансформує вхідний простір сенсорних даних у простір клінічних рішень (Рисунок 1.1). Нехай $I \in \mathbb{R}^{H \times W \times C}$ — вхідне медичне зображення (або тензор мультимодальних даних), $\theta \in \mathbb{R}^d$ — вектор параметрів моделі, що навчаються, а $\mathcal{K}_{domain}$ — структуроване представлення апріорних знань предметної області. Тоді процес діагностики описується рівнянням:

$$
D = f_{CAD}(I; \theta, \mathcal{K}_{domain}),
$$

де $D$ позначає вихідний діагностичний результат, який може набувати форми вектора ймовірностей класів (класифікація), маски сегментації (локалізація) або координат обмежувальних рамок (виявлення).

Важливість інтеграції компоненти $\mathcal{K}_{domain}$ для підвищення надійності систем підтверджується у систематичних оглядах [12], [13].

Критичним аспектом, що відрізняє медичні системи ШІ від систем загального призначення, є необхідність інтеграції знань для подолання обмежень "чистих" даних. У класичному глибокому навчанні модель намагається вивести всі необхідні закономірності виключно з навчальної вибірки даних (data-driven approach). Однак, як зауважують автори [14], [15], у медицині існує величезний пласт верифікованих знань — анатомічних, фізіологічних, патологічних та процедурних, — ігнорування яких призводить до створення моделей, що є нестійкими, погано інтерпретованими та схильними до помилок у нестандартних клінічних ситуаціях. Це створює низку системних проблем при впровадженні ШІ в діагностику, які деталізовано в Таблиці 1.1.

**Таблиця 1.1.** Системні проблеми та бар'єри, що виникають при використанні штучного інтелекту в діагностичних сферах медицини [16].

| Фактор впровадження ШІ | Проблема |
| :--- | :--- |
| Приватність та кібербезпека | Необхідний надійний захист від зовнішнього втручання в технологічну систему діагностичних центрів для збереження всіх даних пацієнтів. Уникнення можливості помилок діагностичних систем ШІ (підробка, зміна даних). |
| Надійність | Проблеми з технологією можуть вплинути на кінцевий результат і діагноз. Якісне формулювання процесів і завдань ШІ, своєчасний аналіз та контроль рівня результатів безпосередньо впливають на правильне виконання завдань. |
| Технологія та відповідальність | Постійно виникають питання про технічні, етичні та управлінські компоненти технологій на базі ШІ. Хто нестиме відповідальність за діагностичні помилки? |
| Автономія та система підтримки | Громадськість має доступ до сучасних додатків, що використовуються в медицині. Коли виникає потреба, людина може змінити результати, що вплине на кінцевий продукт. |
| Етнічні групи населення | Не всі країни та не всі медичні діагностичні заклади здатні мати відповідну матеріально-технічну базу для технологій ШІ. Недостатнє фінансування охорони здоров'я. |
| Технологічна база | Розробкою технологій ШІ здебільшого займаються люди без медичної освіти, тому можуть виникати питання щодо медичних помилок. Вони не можуть бути виправлені медичним персоналом, що призведе до неякісного результату. |

Практична реалізація підходу інтеграції знань стикається з фундаментальною проблемою дефіциту даних. Невеликий розмір верифікованих медичних наборів даних створює суттєвий бар'єр для отримання задовільних DL-моделей, оскільки, згідно з дослідженнями [17], здатність моделі до узагальнення корелює з обсягом навчальної вибірки. У традиційних задачах комп'ютерного зору існують еталонні набори даних, такі як ImageNet (понад 14 мільйонів анотованих зображень). На відміну від цього, загальнодоступні медичні набори даних є на порядки меншими, що вимагає специфічних методів адаптації, таких як навчання з малою кількістю прикладів або адаптація без доступу до вихідного домену [18]. Цей дисбаланс призводить до того, що емпіричний ризик $R_{emp}(f_{CAD}; S_{med})$ перестає бути надійною оцінкою істинного ризику $R_{true}(f_{CAD})$, що спричиняє явище перенавчання (overfitting).

![Порівняльна характеристика обсягів даних у загальних наборах комп'ютерного зору та спеціалізованих медичних наборах.](figs/figure_ch1_data_distribution.pdf)
*Рисунок 1.2: Порівняльна характеристика обсягів даних у загальних наборах комп'ютерного зору (ImageNet) та спеціалізованих медичних наборах (ACDC та M&Ms), що ілюструє проблему дефіциту даних.*

Ілюстрацією цієї проблеми є статистика доступних наборів даних, візуалізована на рисунку 1.2. Серед множини існуючих ресурсів лише окремі містять понад 100 000 зображень. До таких належать ChestX-ray14 [19] та CheXpert [20]. Також варто виділити набори PadChest [21] та DeepLesion [22], які забезпечують значний обсяг даних для навчання. Для аналізу звітів радіологів важливим є ресурс MIMIC-CXR [23], що поєднує зображення та текстові описи. У галузі МРТ серця значними є ініціативи CMRxMotion [24] та CMRxRecon [25], що надають дані для задач реконструкції та аналізу руху. Детальний розподіл та характеристики найбільш релевантних медичних наборів даних наведено в Таблиці 1.2.

**Таблиця 1.2.** Аналіз наборів даних, що використовуються для вирішення різних завдань обробки медичних зображень.

| Назва набору даних | Завдання | Медичний фокус | Тип даних | Кількість |
| :--- | :--- | :--- | :---: | :--- |
| Cardiac MRI [26] | Класифікація, Сегментація | Серцево-судинна | МРТ | 7980 зображень з 33 сканів |
| ABIDE [27] | Класифікація | Мозок | МРТ | 539 пацієнтів та 573 скани |
| ADNI [28] | Класифікація | Мозок | Різні | 1921 пацієнт |
| ChestX-ray14 [19] | Виявлення | Грудна клітка | Рентген | 112 120 зображень |
| CheXpert [20] | Класифікація | Грудна клітка | Рентген | 224 316 зображень |
| LDCT-IQ [29] | Оцінка якості | Торакальна/Абдомінальна | КТ | Різні дози |
| MIMIC-CXR [23] | Генерація звітів | Грудна клітка | Рентген/Текст | 377 110 зображень |
| BraTS2021 [30] | Сегментація | Мозок | МРТ | 542 зображення |
| DeepLesion [22] | Класифікація, Виявлення | Різні | КТ | 32 735 зображень |

Проблема дефіциту даних у медичній сфері має системний характер і проявляється у трьох взаємопов'язаних аспектах. По-перше, абсолютна кількість зображень є обмеженою через високу вартість та складність процедур збору даних (КТ, МРТ, ПЕТ). По-друге, існує критична нестача якісних анотацій, що вимагають експертних знань. По-третє, спостерігається значний дисбаланс класів, особливо для рідкісних патологій. Це питання детально розглядається в контексті "довгого хвоста" розподілу даних у роботах [31], [32].

Прямим наслідком цих обмежень є схильність глибоких моделей до перенавчання [33]. Математично перенавчання визначається як значна розбіжність між значенням функції втрат на навчальній та тестовій вибірках. Нехай $\mathcal{L}(y, \hat{y})$ — функція втрат, наприклад, перехресна ентропія або відстань Хаусдорфа, яка є специфічною для задач сегментації [34]. Умова перенавчання записується як:

$$
\mathbb{E}_{(x,y) \sim S_{train}} [\mathcal{L}(y, f_{CAD}(x; \theta))] \ll \mathbb{E}_{(x,y) \sim S_{test}} [\mathcal{L}(y, f_{CAD}(x; \theta))].
$$

Для боротьби з цим явищем у комп'ютерному зорі розроблено низку методів регуляризації. Серед них — методи оптимізації, такі як Adam [35], зменшення ємності мережі (pruning), та стохастична регуляризація. Важливу роль відіграє аугментація даних, яка може бути реалізована за допомогою генеративних змагальних мереж (GAN) [36] або методів доменно-змагального навчання [37].

Однак, зазначені методи є суто статистичними інструментами. В умовах критичного дефіциту даних більш перспективним підходом є інтеграція зовнішніх знань, що дозволяє компенсувати нестачу навчальних прикладів. Попри наявні перешкоди, інтеграція діагностичних моделей демонструє потенціал для значного підвищення ефективності, що підтверджується ключовими результатами останніх досліджень (Таблиця 1.3).

**Таблиця 1.3.** Ключові показники результативності інтегрованих діагностичних моделей ШІ, що демонструють потенціал гібридних підходів [16].

| Метрика | Значення |
| :--- | :--- |
| Чутливість (Sensitivity) | 94.5% |
| Специфічність (Specificity) | 92.3% |
| Загальна класифікація | 93.8% |
| Інтерпретованість | Покращене розуміння процесу прийняття рішень системою ШІ |

Ідея використання зовнішньої інформації реалізується через різні механізми. Найпоширенішим є трансферне навчання (transfer learning) [38], [39], де модель попередньо навчається на масивному наборі даних. Отримані параметри слугують початковою точкою для навчання на цільовому медичному наборі. Цей підхід довів свою ефективність у задачах класифікації раку простати [40] та виявленні патологій на трансректальному ультразвуці [41]. Для ефективної адаптації часто використовують дистиляцію знань, огляд методів якої наведено у [42].

Окрім трансферного навчання, важливим джерелом є знання предметної області, які можна класифікувати за рівнем абстракції. Високорівневі знання включають діагностичні протоколи та таксономії захворювань [43], [44]. Низькорівневі знання охоплюють інформацію про анатомічну локалізацію та морфологічні ознаки [45]. Для завдань сегментації критично важливими є апріорні знання про форму та взаємне розташування органів [46], [47].

![Категоризація знань та методів для діагностики захворювань: ієрархія завдань та джерел додаткової інформації.](figs/figure_ch1_knowledge_integration.pdf)
*Рисунок 1.3: Категоризація знань та методів для діагностики захворювань: ієрархія завдань та джерел додаткової інформації [12].*

Сучасні методи інтеграції знань включають гібридні архітектури, що поєднують глибокі нейронні мережі з традиційними методами (handcrafted features) [48]. Якщо позначити $h_{DL}$ як вектор ознак з DL-моделі, а $h_{HC}$ як вектор, розрахований на основі експертних правил (наприклад, форми або текстури [49], [50]), то об'єднаний дескриптор використовується для прийняття рішення. Більш складні підходи використовують механізми уваги для імітації патернів візуального пошуку радіолога [51], [52]. Карта уваги модулює просторові ознаки, посилюючи сигнал від релевантних зон. Також застосовуються багатозадачне навчання [14] та мета-навчання [53].

Попри наявність оглядових праць з медичного глибокого навчання, існує потреба у систематизації методів саме в контексті інтеграції експертних знань. Рисунок 1.3 ілюструє концептуальну таксономію підходів до цієї проблеми. На верхньому рівні цієї схеми дослідження класифікуються за клінічними завданнями: 1) діагностика (класифікація) захворювань; 2) виявлення анатомічних структур та аномалій; 3) сегментація органів та уражень.

## 1.2. Огляд сучасних підходів систем штучного інтелекту до діагностики захворювань

Задача діагностики захворювань засобами штучного інтелекту формалізується як проблема класифікації вхідного зображення $I$ до одного з класів множини $\mathcal{C} = \{c_1, c_2, \dots, c_K\}$, що представляють можливі патологічні стани або норму.

### 1.2.1. Моделі глибокого навчання для діагностики захворювань

Протягом останнього десятиліття домінуючим підходом у цій галузі стали згорткові нейронні мережі (CNN), принципи яких були закладені у фундаментальних роботах [54]. Архітектура CNN базується на біологічно натхненних принципах організації зорової кори, зокрема на наявності рецептивних полів та ієрархічній обробці інформації.

Математично згортковий шар $l$ виконує перетворення вхідного тензора ознак $F^{(l-1)}$ у вихідний тензор $F^{(l)}$ за допомогою операції згортки з набором ядер (фільтрів) $W^{(l)}$ та додавання зміщення $b^{(l)}$, з подальшим застосуванням нелінійної функції активації $\sigma$:

$$
F_k^{(l)}(i,j) = \sigma \left( \sum_{c} \sum_{u,v} W_{k,c}^{(l)}(u,v) \cdot F_c^{(l-1)}(i-u, j-v) + b_k^{(l)} \right),
$$

де $k$ — індекс вихідної карти ознак, $c$ — індекс вхідного каналу, $(u,v)$ — просторові координати ядра.

Функція активації $\sigma(\cdot)$ забезпечує нелінійність моделі, що є критичним для вивчення складних залежностей. Для зменшення розмірності даних використовуються шари субдискретизації (pooling):

$$
P_k^{(l)}(i,j) = \max_{(u,v) \in \Omega(i,j)} F_k^{(l)}(u,v).
$$

Глибока архітектура формується шляхом каскадного з'єднання блоків «згортка-пулінг». Останній шар зазвичай використовує функцію Softmax для генерації розподілу ймовірностей $\hat{y}$ над класами діагнозів:

$$
\hat{y}_k = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)},
$$

де $z_k$ — логіт для класу $k$.

Еволюція архітектур CNN, починаючи від VGGNet [55] до більш сучасних ResNet [56] та DenseNet [57], дозволила значно підвищити точність діагностики. Зокрема, введення залишкових зв'язків у ResNet дозволило ефективно навчати надглибокі мережі. У медичних застосуваннях ці архітектури є базовими. Наприклад, вони успішно застосовуються для діагностики виразкового кератиту [58] та виявлення легеневих вузликів [59], [7].

Для завдань сегментації, які вимагають піксельної точності, використовуються спеціалізовані архітектури, такі як U-Net та її модифікації. Прикладами є R2U-Net [60], яка поєднує рекурентні та залишкові блоки, та методи для сегментації пухлин мозку [61], [62]. У роботах [63], [64] продемонстровано ефективність глибоких мереж для сегментації гіперінтенсивності білої речовини та неонатального мозку відповідно. Важливим напрямком є також використання умовних випадкових полів (CRF) у поєднанні з нейронними мережами для уточнення меж об'єктів [65]. Для задач кардіології розробляються методи семантичного маркування зрізів КТ [66].

У сучасній цифровій патології виділяють кілька категорій методів, що використовуються для обробки зображень та інтеграції знань. Їх класифікація наведена в Таблиці 1.4.

**Таблиця 1.4.** Категорії методів цифрової патології, що використовуються для аналізу медичних зображень [16].

| Категорія методу | Опис |
| :--- | :--- |
| Статичні | Традиційні методи аналізу нерухомих зображень. |
| Динамічні | Методи, що враховують часові зміни або рух. |
| Роботизовані | Автоматизовані системи збору та обробки зразків. |
| Повнослайдові (Whole Slide Imaging) | Сканування та аналіз цілих гістологічних препаратів з високою роздільною здатністю. |
| Гібридні | Поєднання кількох підходів для підвищення точності. |

Однак, стандартні CNN, навчені "з нуля" або адаптовані без урахування специфіки домену, часто ігнорують багатий контекст медичних знань. Це обмежує їхню ефективність в умовах малих вибірок та знижує інтерпретованість рішень.

![Ілюстрація проблеми зсуву домену (Domain Shift) у медичній діагностиці.](figs/figure_ch1_domain_shift.pdf)
*Рисунок 1.4: Ілюстрація проблеми зсуву домену (Domain Shift) у медичній діагностиці: відмінності у розподілі даних між різними сканерами та клінічними центрами, що призводять до деградації точності моделей.*

Проблема, візуалізована на рисунку 1.4, демонструє необхідність розробки методів, стійких до варіативності обладнання, що є одним із ключових завдань даної роботи.

### 1.2.2. Аналіз підходів до інтеграції знань з медичних наборів даних у моделі глибокого навчання

Інтеграція знань через використання додаткових наборів даних є однією з найбільш розроблених стратегій. Згідно з [67], існують дві основні стратегії використання попередньо навчених моделей (рис. 1.5).

![Дві стратегії використання попередньо навчених DL-моделей для аналізу медичних зображень.](figs/figure_ch1_transfer_strategies.pdf)
*Рисунок 1.5: Дві стратегії використання попередньо навчених DL-моделей для аналізу медичних зображень: (a) як фіксований екстрактор ознак та (b) як ініціалізація для доналаштування на цільовому наборі даних [67].*

Перша стратегія (рис. 1.5a) використовує мережу $M_{pre}$ як фіксований екстрактор ознак. Вихідний вектор використовується для навчання класифікатора $C$. Цей підхід є ефективним і зменшує ризик перенавчання на малих наборах даних, що підтверджено у дослідженнях [5], [68].

Друга стратегія (рис. 1.5b) передбачає доналаштування (fine-tuning) всієї мережі або її частини. Параметри ініціалізуються значеннями $\theta_{source}^*$, а потім оновлюються на цільових даних. Цей метод дозволяє адаптувати високорівневі ознаки до специфіки медичних зображень і є стандартом для багатьох задач, включаючи дерматоскопію [10] та рентгенографію [6].

Окрім трансферного навчання, важливим механізмом є дистиляція знань. Це дозволяє передавати інформацію від складних ансамблів до компактних моделей або між різними модальностями [69]. Сучасні методи дистиляції включають використання мета-знань [70] та адаптацію до нових доменів [71]. Для підвищення робастності сегментації розробляються методи дистиляції форми та інтенсивності [72], а також методи навчання на основі точкових анотацій [73]. У роботі [74] запропоновано підхід до рекомбінації ознак для трансформерів у задачах МРТ.

Важливим напрямком є також розв'язання проблеми "чорної скриньки" при адаптації домену [75] та забезпечення пояснюваності дистильованих моделей [76]. Багатозадачне навчання (Multi-task Learning) є розширенням цієї ідеї, де модель одночасно навчається вирішувати декілька пов'язаних завдань. Спільне представлення ознак дозволяє обмінюватися інформацією між завданнями. Дослідження [77], [78] демонструють ефективність цього підходу для класифікації гліом та пухлин молочної залози. У роботі [79] показано переваги використання кореляцій між різними станами при діагностиці хвороби Альцгеймера.

## 1.3. Характеристики та формалізація знань предметної області для розробки систем штучного інтелекту

Процес медичної діагностики не є лінійним перетворенням вхідного сигналу у вихідний діагноз. Він базується на складній системі знань та евристик. Згідно з класифікацією, наведеною в роботах [12] та інших джерелах, виділимо такі категорії знань: навчальні патерни, процедурні діагностичні патерни, просторові пріоритети, семантичні ознаки, мультимодальний контекст.

### 1.3.1. Навчальний патерн медичних працівників та Curriculum Learning

Навчання лікаря відбувається за принципово іншою схемою, ніж стандартне навчання нейронної мережі. Студенти-медики опановують матеріал поступово. Ця стратегія може бути формалізована в рамках парадигми навчання за програмою (Curriculum Learning) [44]. Навчальна програма визначається як послідовність вагових функцій, що еволюціонують, включаючи спочатку лише "легкі" приклади.

У роботі [43] для аналізу МРТ молочної залози використано стратегію, де модель спочатку вчиться виявляти наявність ураження, а потім класифікувати його. Подібні підходи ефективні для класифікації переломів [80] та діагностики глаукоми [81]. Для вирішення проблем дисбалансу даних застосовуються методи адаптивної вибірки [82] та підходи, засновані на псевдо-мітках з анти-навчальним планом [83].

### 1.3.2. Загальні діагностичні патерни та архітектурні пріори

Досвідчені радіологи використовують специфічні стратегії візуального пошуку, які включають глобальний огляд та детальне сканування. Цей процедурний патерн можна імплементувати через багатопотокову обробку [14]. Така структура (рис. 1.6) дозволяє моделі враховувати як контекст, так і деталі текстури.

![Ілюстрація архітектури, що імітує діагностичний патерн радіолога.](figs/figure_ch1_diagnostic_pattern.pdf)
*Рисунок 1.6: Ілюстрація архітектури, що імітує діагностичний патерн радіолога: глобальна та локальна гілки обробки з подальшим злиттям ознак [14].*

Іншим прикладом є використання симетрії. При аналізі мамограм лікарі порівнюють молочні залози для виявлення асиметрії. Архітектури, такі як MommiNet [84] та методи, описані у [85], [86], явно кодують цю стратегію, використовуючи сіамські мережі для виявлення відмінностей. Аналогічний підхід застосовується для відстеження змін у часі при скринінгу меланоми [87]. Для аналізу легеневих вузликів ефективними є мережі з подвійним шляхом та мульти-видові архітектури [88], [89]. У роботі [90] також досліджувалося використання глибоких мереж для виявлення патологій грудної клітки з урахуванням специфічних діагностичних патернів.

### 1.3.3. Області інтересу та механізми уваги

Медичні фахівці фокусуються на клінічно значущих зонах. Інтеграція знань про ці зони реалізується через механізми уваги, огляд яких представлено у [52]. Нехай $A_{exp}$ — карта уваги, отримана на основі записів руху очей експерта. Задача полягає в мінімізації розбіжності між генерованою картою уваги та експертною.

У моделі AG-CNN [9] для діагностики глаукоми (рис. 1.7) цей підхід дозволив значно підвищити чутливість моделі. Подібні механізми інтегровані в моделі для класифікації медичних зображень [91] та прогнозування ускладнень, таких як нориці [92].

![Приклад використання карт уваги офтальмолога для навчання моделі AG-CNN.](figs/figure_ch1_attention_maps.pdf)
*Рисунок 1.7: Приклад використання карт уваги офтальмолога для навчання моделі AG-CNN. Порівняння карт фіксації погляду та карт активації мережі демонструє ефективність керованого навчання [9].*

Альтернативним підходом є "жорстка" увага, де зображення маскується на основі сегментації органу перед подачею в класифікатор, як це реалізовано для зображень оптичної когерентної томографії [93]. Для катаракти розроблено методи, що керуються увагою до судин [94].

### 1.3.4. Візуальні ознаки та семантичні дескриптори

Медична діагностика спирається на стандартизовані системи опису патологій, такі як BI-RADS [95]. Інтеграція "вручну створених ознак" з абстрактними ознаками CNN може відбуватися на рівні рішень або ознак. У дослідженнях [11], [96] показано переваги злиття результатів роботи CNN та класифікаторів, навчених на традиційних ознаках.

Злиття на рівні ознак дозволяє знаходити нелінійні кореляції. Це продемонстровано для класифікації вузлів у легенях [48], раку молочної залози [97], [98] та дерматології. Важливими є також ознаки форми [49] та текстурні переходи [50]. Окремим напрямком є використання радіомних ознак для прогнозування інвазивності пухлин [99]. Також досліджено методи введення інформації про краї та межі у процес навчання [100].

Особливо цікавим є підхід використання семантичних ознак як цільових міток у багатозадачному навчанні. Це змушує CNN формувати внутрішні представлення, що корелюють з клінічно значущими поняттями [33], [101]. У роботі [102] запропоновано інтерпретовану мережу MDNet для медичної діагностики. Включення анатомічних знань також дозволяє покращити результати сегментації, як показано у [103], [47]. Окремо слід згадати методи, що використовують локальні бінарні патерни або інші перетворення на рівні входу [104].

### 1.3.5. Інтеграція текстових та мультимодальних знань

Медичне зображення ніколи не інтерпретується у вакуумі. Клінічний контекст, що міститься у радіологічних звітах, є критично важливим. Для обробки тексту використовуються сучасні мовні моделі, такі як BERT [105] та його біомедична адаптація BioBERT [106].

Для інтеграції текстових звітів використовуються гібридні архітектури CNN-RNN. Наприклад, мережа TieNet [107] використовує спільний простір вбудовування для зображень та тексту. Дослідження [108], [109] фокусуються на генерації клінічно релевантних описів. Також розробляються методи класифікації медичних текстів [110], [111] та розділення синтаксичної і семантичної інформації [112].

Важливим аспектом є логічне висновування на природній мові (NLI). У роботах [113], [114] пропонуються методи покращення NLI шляхом інтеграції зовнішніх знань та аналізу тональності. Водночас існують проблеми, пов'язані з артефактами у наборах даних NLI, які досліджуються у [115]. Для покращення розуміння семантики використовуються вдосконалені методи LSTM [116] та аналіз векторних представлень [117].

Графи знань (Knowledge Graphs, KG) дозволяють інтегрувати структуровану інформацію. Огляд методів побудови пацієнт-орієнтованих графів наведено у [118]. Використання графових нейронних мереж, таких як GAT [119], дозволяє ефективно обробляти такі структури. У дослідженнях [120], [121] вектори з графів знань використовуються для покращення діагностики та генерації звітів. Також активно розвиваються методи вбудовування графів [122] та ієрархічного навчання представлень [123]. Для класифікації графів використовуються архітектури DGCNN [124], а для пояснення рішень — методи GNNExplainer [125]. Окремої уваги заслуговують методи напівконтрольованого навчання на графах [126] та використання апріорних знань для класифікації [127].

## 1.4. Огляд підходів до інтеграції медичних знань в системах обробки медичних даних

Методологія інтеграції знань виходить за межі класифікації і є актуальною для задач реконструкції, пошуку та генерації описів.

### 1.4.1. Реконструкція медичних зображень

У задачах реконструкції знання виступають як апріорні обмеження. Використання генеративно-змагальних мереж (GAN), таких як DAGAN [128], дозволяє відновити деталі МРТ. Також досліджуються методи синтезу зображень для мультимодальних даних [129], [130]. Новітнім напрямком є використання дифузійних ймовірнісних моделей для генерації 3D зображень [131]. Для оптичної томографії розроблено методи на основі нечітких функцій втрат [132].

### 1.4.2. Пошук медичних зображень (CBIR)

Системи пошуку за вмістом (CBIR) допомагають лікарям знайти схожі історичні випадки. Інтеграція знань тут відбувається через семантичне збагачення вектора ознак [133]. Використання бінарних текстур [134] та метаданих пацієнтів, таких як вік і стать [135], дозволяє покращити релевантність пошуку. У роботі [136] запропоновано метод послідовного звуження простору пошуку з використанням глибоких ознак.

### 1.4.3. Генерація медичних звітів

Автоматична генерація описів вимагає перетворення візуальних ознак у послідовність слів. Інтеграція знань тут критична для забезпечення фактологічної точності. Використання механізмів пошуку та перефразування [137], а також гібридних агентів з навчанням з підкріпленням [138], дозволяє генерувати звіти, що відповідають професійному стилю. У роботі [139] запропоновано мережу MVP-Net для виявлення уражень, яка також може бути частиною пайплайну генерації звітів.

## 1.5. Актуальні проблеми та виклики інтеграції знань

Попри значний прогрес, інтеграція знань у медичний ШІ залишається відкритою науковою проблемою, що характеризується низкою викликів.

### 1.5.1. Проблеми ідентифікації та формалізації знань

Експертні знання часто є неявними, а лікарі діють інтуїтивно. Автоматичне вилучення знань з текстів є перспективним, але стикається з проблемою неоднозначності. Інструменти, такі як MetaMap [140] та спеціалізовані бібліотеки NLP [141], допомагають структурувати інформацію. Важливу роль відіграє Уніфікована система медичної мови (UMLS), яка надає онтологічну базу для досліджень [142].

### 1.5.2. Труднощі представлення та методів включення

Існує "семантичний розрив" між символьним представленням знань та субсимвольним представленням у нейронних мережах. Розробка диференційовних механізмів, що дозволяють транслювати логічні обмеження у градієнти помилок, є нетривіальною задачею. Прикладами спроб подолання цього розриву є використання знань про структуру при діагностиці целіакії [143] та застосування класифікаторів для діагностики раку молочної залози [48].

### 1.5.3. Проблема зсуву домену та дистиляція знань

Медичні дані є вкрай гетерогенними. Зображення, отримані на різних сканерах, мають різні статистичні розподіли, що призводить до зсуву домену. Методи адаптації домену [75] та дистиляції знань є ключовими для вирішення цієї проблеми. Це дає змогу зберегти знання при переході між модальностями або при роботі з обмеженими даними [71]. Актуальними є дослідження узгодженості семантики при адаптації, наприклад, для класифікації вузлів щитоподібної залози [144], [109] та аналізу ретинальних зображень [145].

## 1.6. Постановка завдання дисертаційної роботи

На основі проведеного аналізу встановлено, що існуючі методи інтеграції знань є фрагментарними і часто не забезпечують системного підходу. Існує протиріччя між необхідністю підвищення надійності діагностичних систем і обмеженими можливостями суто статистичних методів навчання на малих вибірках. Спираючись на попередні дослідження автора [146], [16], метою роботи визначено вдосконалення процесу прийняття рішень під час медичної діагностики.

Для досягнення мети сформульовано наступні завдання:

*   Провести системний аналіз методів глибокого навчання та способів формалізації медичних знань.
*   Розробити метод інтеграції знань на основі дистиляції від ансамблю вчителів для адаптації до нових доменів.
*   Розробити метод покращення текстового висновування (NLI) шляхом інтеграції онтологічних знань UMLS та аналізу тональності, розвиваючи ідеї, викладені у [113].
*   Розробити архітектуру для сегментації зображень, що інтегрує експертні анотації та топологічні обмеження.
*   Експериментально підтвердити ефективність розроблених методів на реальних клінічних даних.

## 1.7. Висновки до Розділу 1

У даному розділі здійснено комплексний аналіз проблеми інтеграції знань у системи медичного штучного інтелекту. Показано, що "чисті" підходи, засновані на даних, досягли межі своєї ефективності в умовах дефіциту анотованих даних. Встановлено, що найбільш перспективним вектором розвитку є створення гібридних систем, які поєднують потужність глибокого навчання з надійністю експертних знань.

Систематизовано типи медичних знань та методи їх інтеграції, такі як трансферне навчання, багатозадачність та механізми уваги. Формалізовано математичні апарати цих методів. Визначено ключові виклики, пов'язані зі зсувом домену та семантичним розривом, які будуть вирішуватися у наступних розділах дисертації.

---

# Розділ 2. Моделі та методи передачі експертних знань до системи штучного інтелекту медичного діагностичного комплексу

Сучасна парадигма розвитку медичних інформаційних систем характеризується стрімким переходом від класичних алгоритмічних підходів до використання адаптивних моделей штучного інтелекту, здатних опрацьовувати надвеликі масиви гетерогенних даних. Процес класифікації медичних зображень, який лежить в основі автоматизованої діагностики, передбачає складну процедуру категоризації візуальної інформації на основі виявлення латентних ознак, що корелюють з патологічними станами біологічних тканин або наявністю специфічних анатомічних аномалій. У контексті аналізу зображень різної модальності, таких як магнітно-резонансна томографія, комп'ютерна томографія або цифрова рентгенографія, вхідні дані розглядаються як багатовимірні тензори інтенсивності, тоді як діагностичний висновок, що визначає тип патології або відхилення від фізіологічної норми, виступає у ролі цільової змінної або семантичної анотації. Відповідно, фундаментальна задача побудови інтелектуального діагностичного комплексу зводиться до синтезу та навчання моделі глибокого навчання, здатної апроксимувати складну нелінійну функцію відображення простору візуальних ознак у простір клінічних рішень.

Досягнення моделлю необхідного рівня узагальнення шляхом ітеративного стохастичного навчання дозволяє отримати систему, яка демонструє високу точність класифікації на нових даних, за умови стаціонарності статистичного розподілу вхідних сигналів. Проте у реальній клінічній практиці ця умова часто порушується, що призводить до явища, відомого як зсув домену. Це явище характеризується суттєвою деградацією метрик якості розпізнавання при спробі застосування моделі, навченої на даних одного медичного закладу, до даних, отриманих в інших умовах, на іншому обладнанні або на іншій популяції пацієнтів. Зсув домену є критичною перешкодою для масштабування та впровадження систем штучного інтелекту, оскільки він підриває надійність діагностичних висновків у неконтрольованому середовищі. Окрім проблеми гетерогенності даних, суттєвим обмежувальним фактором є дефіцит верифікованих анотованих наборів даних. Процес створення розмічених медичних вибірок вимагає залучення висококваліфікованих експертів і є надзвичайно ресурсомістким, що створює дисбаланс між величезними обсягами накопичених сирих даних та мізерною кількістю даних, придатних для навчання з учителем.

У відповідь на зазначені виклики, даний розділ дисертаційного дослідження присвячено розробці нових методів інтеграції знань, які дозволяють компенсувати нестачу розмічених даних та подолати бар'єр зсуву домену. Перша частина розділу фокусується на методі дистиляції знань від ансамблю моделей-вчителів до єдиної моделі-учня, що дозволяє агрегувати досвід, отриманий з різнорідних джерел, та адаптувати його до цільового домену. Друга частина розділу розкриває методологію покращення автоматизованого аналізу клінічних текстів шляхом інтеграції онтологічних знань та аналізу тональності, що дозволяє системі глибше розуміти семантику медичних записів та підвищувати точність прийняття рішень на основі текстових даних. Обидва підходи спрямовані на створення надійних, адаптивних та точних компонентів інтелектуальних діагностичних комплексів.

## 2.1. Метод дистиляції знань від множини моделей-вчителів до єдиної моделі-учня

Розглянемо задачу класифікації медичних зображень у загальній постановці, яка полягає у виявленні та ідентифікації візуальних маркерів патологічних змін на зображеннях, отриманих з джерел з різними статистичними характеристиками. Така задача є класичним прикладом проблеми адаптації домену, де модель, що оптимізована на одному розподілі даних (початковий домен), повинна відповідно точно функціонувати на іншому, хоча й семантично пов'язаному розподілі (цільовий домен). Для вирішення цієї проблеми у даній роботі пропонується застосування та розвиток методу дистиляції знань, який дозволяє здійснити трансфер узагальненої інформації від колективу моделей-вчителів, кожна з яких спеціалізується на конкретному початковому домені, до компактної моделі-учня, що адаптується до специфіки цільового домену.

Науковий внесок даного підрозділу полягає у розробці нового методу ансамблевої дистиляції знань, який включає використання спеціалізованої моделі-вчителя для змагальної адаптації домену та механізму селективної фільтрації знань. Запропонований підхід забезпечує точне накопичення знань з децентралізованих джерел, представлених окремими моделями, та їх передачу моделі-учню, що підвищує стійкість системи до варіативності вхідних даних та покращує точність діагностики в умовах обмеженої розмітки.

Основні переваги та відмінності запропонованого методу можна сформулювати наступним чином:

*   Метод дозволяє інтегрувати знання з гетерогенних джерел, таких як різні клініки або типи діагностичного обладнання, без необхідності фізичного об'єднання сирих даних, що є критично важливим для дотримання вимог конфіденційності та захисту персональних даних пацієнтів.
*   На відміну від класичних схем дистиляції, що використовують одного вчителя, запропонований підхід базується на використанні динамічного ансамблю, до складу якого входить модель, навчена виділяти доменно-інваріантні ознаки, що дозволяє моделі-учню засвоювати найбільш універсальні патерни патологій.
*   Впровадження механізму фільтрації знань на основі верифікації на малій вибірці цільового домену дозволяє відсіювати помилкові передбачення вчителів, запобігаючи поширенню неправдивих знань (negative transfer) та підвищуючи надійність навчання моделі-учня.
*   Результатом роботи методу є компактна модель-учень, яка, маючи меншу обчислювальну складність, демонструє продуктивність, порівнянну з великими ансамблями, що дозволяє використовувати її в умовах обмежених апаратних ресурсів, наприклад, у мобільних діагностичних комплексах.

Для кращого розуміння контексту дистиляції, розглянемо порівняння існуючих підходів у Таблиці 2.1, що демонструє переваги запропонованого методу EMTKD.

**Таблиця 2.1.** Порівняння підходів до дистиляції знань у медичній візуалізації [147].

| Метод | Основний принцип | Недоліки |
| :--- | :--- | :--- |
| Звичайна дистиляція (KD) | Передача знань від одного вчителя до учня через згладжені мітки. | Не враховує різноманітність даних з різних доменів; вразлива до помилок вчителя. |
| Багатовчителева дистиляція (MTKD) | Усереднення прогнозів від кількох вчителів. | Конфлікт знань при доменних зсувах; неадаптивне зважування. |
| Адаптивна дистиляція (AEKD) | Динамічне зважування вчителів на основі впевненості. | Не використовує доменну адаптацію для вирівнювання ознак. |
| Запропонований EMTKD | Поєднання адаптивного зважування, доменної адаптації та SSL. | Підвищена обчислювальна складність на етапі навчання. |

Для побудови математичної моделі процесу дистиляції введемо формальний опис просторів даних. Припустимо наявність множини початкових доменів, кожен з яких представлений відповідним набором даних для навчання окремої моделі-вчителя. Формалізуємо $n$ наборів даних медичних зображень наступним чином:

$$
D_j^t = \{(x_i^j, y_i^j)\}_{i=1}^{N_j}, \quad j=1,\dots,n,
$$

де $x_i^j$ належить до простору ознак $\mathcal{X}_j$ і представляє $i$-те вхідне зображення з $j$-го набору даних, $y_i^j$ належить до простору міток $\mathcal{Y}_j$ і є відповідною діагностичною міткою, $N_j$ позначає кількість зразків у вибірці $j$, а $n$ визначає загальну кількість доступних моделей-вчителів.

Кожен набір даних $D_j^t$ характеризується власним маргінальним розподілом ймовірностей $P_j(X)$, що відображає специфіку конкретного джерела даних.

Цільовий домен, для якого розробляється модель-учень $f_\theta$, представлений набором даних $D_S$, який структурно поділяється на дві неперетинні підмножини:

$$
D_S = \{D_S', D_S''\},
$$

де $D_S'$ — це невелика за обсягом анотована частина вибірки, яка використовується для налаштування та валідації, а $D_S''$ — масивна неанотована частина, що використовується для навчання без учителя та дистиляції знань.

Анотована підмножина визначається як:

$$
D_S' = \{(x_i', y_i')\}_{i=1}^{N'}, \quad x_i' \in \mathcal{X}_S, y_i' \in \mathcal{Y}_S,
$$

де $x_i'$ та $y_i'$ — це відповідно зображення та мітка, що належать до просторів ознак та міток цільового домену.

Неанотована підмножина визначається як:

$$
D_S'' = \{x_i''\}_{i=1}^{N''}, \quad x_i'' \in \mathcal{X}_S,
$$

де $N'$ та $N''$ — потужності відповідних вибірок, причому виконується умова $N' \ll N''$, що є типовим для медичних задач, де експертна розмітка є вузьким місцем.

Загальна архітектура запропонованого методу базується на ієрархічній схемі передачі інформації. Схематичне зображення підходу представлено на рисунку 2.1, де показано потоки даних від початкових доменів до ансамблю вчителів, а згодом — через механізм агрегації — до моделі-учня.

![Схематичний огляд запропонованого методу розширеної багато-вчителевої дистиляції знань (EMTKD).](figs/figure_ch2_emtkd_scheme.pdf)
*Рисунок 2.1: Схематичний огляд запропонованого методу розширеної багато-вчителевої дистиляції знань (EMTKD). Блок 1 включає навчання моделей-вчителів з адаптацією домену. Блок 2 виконує адаптивну дистиляцію. Блок 3 тренує учня з використанням SSL.*

Методологія реалізується через послідовність трьох ключових етапів: навчання спеціалізованих моделей-вчителів, агрегація та дистиляція знань, і, нарешті, навчання та адаптація моделі-учня.

На першому етапі відбувається незалежне навчання кожної моделі-вчителя $T_j$ на відповідному наборі даних $D_j^t$. Метою навчання є знаходження оптимальних параметрів $\theta_j$, що мінімізують емпіричний ризик, виражений через функцію втрат перехресної ентропії $\mathcal{L}_{CE}$:

$$
\theta_j^* = \arg\min_{\theta_j} \sum_{(x_i^j, y_i^j) \in D_j^t} \mathcal{L}_{CE}(T_j(x_i^j; \theta_j), y_i^j).
$$

Окрім набору доменно-специфічних вчителів, формується додаткова модель $T_{DA}$, призначена для адаптації домену. Ця модель навчається на об'єднаній вибірці всіх вхідних даних з використанням методів змагального навчання (adversarial learning), таких як DANN (Domain-Adversarial Neural Network). Метою $T_{DA}$ є формування простору ознак, в якому мінімізується розбіжність між розподілами різних доменів, що дозволяє виділяти універсальні діагностичні патерни, інваріантні до технічних умов отримання зображень. Процес навчання вчителів з адаптацією домену показано на рисунку 2.2.

![Схема Блоку 1: Навчання моделей-вчителів з інтегрованою адаптацією домену.](figs/figure_ch2_teacher_da.pdf)
*Рисунок 2.2: Схема Блоку 1: Навчання моделей-вчителів з інтегрованою адаптацією домену. Кожен учитель $T_i$ навчається на своєму джерелі даних $D_i$, одночасно змагаючись з дискримінатором домену $D_l$ для вивчення інваріантних ознак.*

На другому етапі реалізується механізм дистиляції знань. Навчені моделі-вчителі розглядаються як генератори ознак (feature extractors) з фіксованими параметрами. Для кожного вхідного зразка $z_i$ з цільового домену $D_S$ кожна модель $T_j$ формує вектор глибоких ознак (embedding) $e_{ij}$:

$$
T_j: z_i \rightarrow e_{ij}, \quad \text{де } z_i \in D_S, \quad i \in \{1, \dots, N' + N''\}, \quad j=1,\dots,n.
$$

Деталізована покрокова схема процесу дистиляції та навчання моделі-учня наведена на рисунку 2.3.

![Покрокова алгоритмічна схема методу дистиляції знань.](figs/figure_ch2_step_by_step.pdf)
*Рисунок 2.3: Покрокова алгоритмічна схема методу дистиляції знань, що ілюструє потік даних від вхідних моделей-вчителів через блоки вилучення ознак, їх зважування та агрегації до фінального оновлення параметрів моделі-учня.*

Процес агрегації знань адаптується залежно від наявності розмітки для вхідного зразка. Якщо вхідний зразок $z_i$ належить до неанотованої множини $D_S''$, то формується розширений вектор ознак шляхом простої конкатенації виходів усіх вчителів та моделі адаптації домену:

$$
E_i = \text{concat}(e_{i1}, e_{i2}, \dots, e_{in}, e_{i,DA}).
$$

У випадку, коли зразок $z_i$ належить до анотованої множини $D_S'$, застосовується процедура інтелектуальної фільтрації. Вводиться індикаторна функція $m_{ij}$, яка оцінює коректність передбачення $j$-го вчителя відносно істинної мітки $y_i'$:

$$
m_{ij} = \mathbb{I}(\text{argmax } T_j(z_i; \theta_j^*) = y_i'), \quad \text{для } z_i = (x_i', y_i') \in D_S'.
$$

Ця функція дозволяє виключити вплив тих моделей-вчителів, які помиляються на конкретних прикладах цільового домену, запобігаючи таким чином трансферу некоректних знань. Агрегований вектор для анотованих даних формується з урахуванням маски:

$$
E_i' = \text{concat}(m_{i1}e_{i1}, \dots, m_{in}e_{in}, e_{i,DA}).
$$

Сформовані вектори $E_i$ та $E_i'$ подаються на вхід агрегаційної нейронної мережі $g_\phi$, яка виконує нелінійне перетворення та злиття різнорідних ознак у єдиний компактний вектор знань $e_i^{KD}$. Агрегаційна мережа зазвичай реалізується як багатошаровий перцептрон (MLP):

$$
g_\phi:
\begin{cases}
    E_i \rightarrow e_i^{KD}, & \text{якщо } z_i \in D_S'', \\
    E_i' \rightarrow e_i^{KD}, & \text{якщо } z_i \in D_S',
\end{cases}
$$

де вихідний вектор обчислюється через послідовність лінійних шарів та функцій активації ReLU:

$$
e_i^{KD} = \text{ReLU}(\mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 \cdot E_{input} + b_1) + b_2).
$$

Детальна архітектура блоку адаптивної дистиляції, що включає механізми уваги та пулінгу, представлена на рисунку 2.4.

![Детальна схема Блоку 2: Адаптивна дистиляція знань.](figs/figure_ch2_adaptive_block.pdf)
*Рисунок 2.4: Детальна схема Блоку 2: Адаптивна дистиляція знань. Показано процес конкатенації векторів ознак, проходження через мережу агрегації, застосування механізму уваги та формування дистильованого вектора.*

На третьому етапі відбувається навчання моделі-учня $f_\theta$, яка повинна відтворити отриманий узагальнений вектор знань. Модель-учень генерує власний вектор ознак $e_i^{ST}$:

$$
f_\theta: z_i \rightarrow e_i^{ST}, \quad z_i \in D_S.
$$

Процес навчання базується на мінімізації функції втрат дистиляції, яка визначається як метрика відстані (наприклад, середньоквадратична помилка) між вектором знань вчителя та вектором моделі-учня:

$$
\mathcal{L}_i^{\text{Dist}} = \| e_i^{KD} - e_i^{ST} \|_2^2 = \| g_\phi(\text{AggFeatures}(z_i, \{T_j\}, F)) - f_\theta(z_i) \|_2^2.
$$

Для забезпечення стабільності градієнтного спуску оптимізація проводиться пакетним методом (mini-batch), де функція втрат усереднюється по пакету розміром $B$:

$$
\mathcal{L}_B^{\text{Dist}} = \frac{1}{B} \sum_{k=1}^B \mathcal{L}_{z_k}^{\text{Dist}}(e_{z_k}^{KD}, e_{z_k}^{ST}).
$$

Оновлення параметрів моделі-учня $\theta$ здійснюється за допомогою адаптивного алгоритму оптимізації Adam, який враховує моменти градієнтів першого та другого порядку для прискорення збіжності:

$$
\theta_{t+1} = \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon_{Adam}} \nabla_\theta \mathcal{L}_B^{\text{Dist}}(\theta_t),
$$

де $\eta$ — швидкість навчання, $\hat{m}_t$ та $\hat{v}_t$ — експоненційні ковзні середні градієнта та його квадрата.

Схема навчання студента з використанням псевдо-міток та збереженням приватності зображена на рисунку 2.5.

![Схема Блоку 3: Навчання моделі-учня з інтеграцією SSL та механізмів збереження приватності.](figs/figure_ch2_student_privacy.pdf)
*Рисунок 2.5: Схема Блоку 3: Навчання моделі-учня з інтеграцією SSL та механізмів збереження приватності. Використовуються псевдо-мітки для неанотованих даних та диференційна приватність при оновленні градієнтів.*

Особливістю запропонованого методу є врахування обчислювальної складності, що дозволяє використовувати його в обмежених ресурсах. У Таблиці 2.2 наведено порівняння параметрів моделей та часу їх навчання.

**Таблиця 2.2.** Час навчання та складність моделей для різних методів адаптації домену [147].

| Модель | Час навчання (годин) | Параметри (Мільйони) |
| :--- | :---: | :---: |
| STM (baseline) | 5 | **25** |
| MTKD [116] | 7 | 60 |
| DANN [37] | 6 | 30 |
| MTMS [70] | 9 | 65 |
| EMTKD (запропонований) | 12 | 70 |

Паралельно з дистиляцією, на кожній епосі відбувається донавчання класифікатора $f_c$ та коригування агрегатора $g_\phi$ на доступних анотованих даних $D_S'$ з використанням функції втрат перехресної ентропії:

$$
\mathcal{L}_{CE}(y', \hat{y}') = -\frac{1}{N'} \sum_{i=1}^{N'} (y_i' \cdot \log(\hat{y}_i'(x_i')) + (1-y_i') \cdot \log(1-\hat{y}_i'(x_i'))),
$$

де $\hat{y}_i'$ — ймовірність приналежності до позитивного класу, отримана після застосування сигмоїдної активації до виходу класифікатора.

Це дозволяє спрямувати процес формування ознак у бік максимальної дискримінативності для конкретної діагностичної задачі. Оновлення всіх параметрів системи на цьому етапі відбувається спільно:

$$
(\phi, \theta, \theta_c) \leftarrow \text{Adam}(\mathcal{L}_{CE}(y', \hat{y}'), (\phi, \theta, \theta_c)).
$$

Завершальним етапом є тонке налаштування (fine-tuning) моделі-учня, яке виконується з меншою швидкістю навчання для досягнення локального мінімуму функції втрат на цільовому домені:

$$
(\theta', \theta_c') \leftarrow \text{Adam}(\mathcal{L}_{CE}(y', \hat{y}'), (\theta, \theta_c)).
$$

У Таблиці 2.3 наведено приклад конфігурації гіперпараметрів та розмірностей шарів, що можуть бути використані при реалізації запропонованого методу.

**Таблиця 2.3.** Рекомендована конфігурація параметрів та розмірностей для реалізації методу дистиляції знань.

| Параметр | Значення / Опис |
| :--- | :--- |
| Кількість моделей-вчителів ($n+1$) | 4 (3 доменно-специфічні + 1 $T_{DA}$) |
| Архітектура вчителів $T_j, T_{DA}$ | ResNet-50 (попередньо навчена на ImageNet) |
| Розмірність ознак вчителів ($d_j, d_{DA}$) | 2048 |
| Архітектура агрегатора $g_\phi$ | MLP: вхід $4 \times 2048 \rightarrow 1024 \rightarrow 2048$ |
| Розмірність $e_i^{KD}$ ($d_{KD}$) | 2048 |
| Архітектура моделі-учня $f_\theta$ | ResNet-18 (компактна модель) |
| Розмірність ознак моделі-учня ($d_{ST}$) | 2048 |
| Розмір пакету $B$ (дистиляція) | 64 |
| Розмір пакету $B_{CE}$ (оновлення) | 32 (з $D_S'$) |
| Кількість епох дистиляції | 50 |
| Кількість епох доналаштування | 10 |
| Оптимізатор | Adam ($\beta_1=0.9, \beta_2=0.999$) |
| Швидкість навчання (дистиляція) | $1 \times 10^{-4}$ |
| Швидкість навчання (доналаштування) | $1 \times 10^{-6}$ |

Продуктивність інференсу також є критичним фактором. У Таблиці 2.4 показано результати тестування пропускної здатності моделі-учня при використанні різних провайдерів виконання ONNX.

**Таблиця 2.4.** Пропускна здатність інференсу та використання ресурсів провайдерами виконання ONNX [148].

| Провайдер (EP) | Медіана (с) | P95 (с) | Пам'ять (ГБ) |
| :--- | :---: | :---: | :---: |
| CPU | 5.3 | 6.6 | 3.2 |
| CUDA | 0.8 | 1.1 | 4.1 |
| DirectML | 1.2 | 1.6 | 3.8 |

Реалізація запропонованого методу дозволяє створити надійну систему діагностики, яка поєднує в собі переваги використання великих обсягів різнорідних даних для навчання та адаптивність до специфічних умов експлуатації. Метод забезпечує подолання проблеми зсуву домену, покращує використання обчислювальних ресурсів та гарантує конфіденційність даних пацієнтів, що робить його перспективним інструментом для побудови сучасних медичних діагностичних комплексів.

## 2.2. Покращення медичного висновування природною мовою шляхом інтеграції знань предметної області та аналізу тональності

Сфера обробки природної мови (Natural Language Processing, NLP) у медицині стикається з унікальними викликами, пов'язаними з високою щільністю спеціалізованої термінології, складністю синтаксичних конструкцій та критичною важливістю контексту для правильної інтерпретації. Недавні досягнення в галузі контекстуальних векторних представлень слів, такі як BioELMo [149], дозволили суттєво підвищити якість аналізу текстів. Проте задача медичного висновування природною мовою (Natural Language Inference, NLI), яка полягає у визначенні логічного зв'язку між двома твердженнями — засновком (Premise) та гіпотезою (Hypothesis), залишається складною для вирішення суто статистичними методами. Необхідність інтеграції структурованих знань предметної області та точного аналізу тональності (зокрема, заперечень) є ключовою для подальшого прогресу в цій галузі [115]. У даному розділі описується розроблений метод, що поєднує нейромережеві підходи з онтологічними знаннями та аналізом сентименту для підвищення точності NLI.

### 2.2.1. Передумови та аналіз проблематики

Поява трансформерних моделей та контекстуальних ембедінгів, таких як BERT та ELMo, революціонізувала NLP. У біомедичному домені моделі BioBERT [106] та BioELMo [117], донавчені на масивах наукових публікацій PubMed, демонструють здатність фіксувати специфічні нюанси медичної мови. Зокрема, BioELMo генерує глибокі контекстуалізовані представлення, враховуючи як лівий, так і правий контекст кожного токена.

Попри це, суто текстові моделі часто не здатні коректно обробляти ситуації, що вимагають знань, які не містяться явно в тексті, але є частиною медичної онтології (наприклад, знання про те, що певний препарат належить до конкретної фармакологічної групи). Уніфікована система медичних мов (UMLS) [142] надає багату базу таких знань, об'єднуючи тезауруси та семантичні мережі. Інтеграція цих знань у нейронні мережі є активним напрямком досліджень. Методи, такі як ExBERT [114], намагаються поєднати BERT із зовнішніми базами знань. Крім того, критичним аспектом є обробка заперечень та модальності тверджень, оскільки в медицині наявність або відсутність симптому ("немає кашлю" проти "є кашель") радикально змінює зміст. Останні дослідження показали перспективність врахування тональності, проте повна синергія між контекстом, онтологією та тональністю залишається відкритою науковою проблемою.

Основні наукові внески цього підрозділу полягають у наступному:

*   **Новий підхід до інтеграції знань:** Розроблено архітектуру, яка вбудовує специфічні знання з UMLS у модель BioELMo, використовуючи векторні представлення концептів, отримані за допомогою моделі MultE [122]. Ця модель точно кодує складні багатозначні відношення в графах знань, що дозволяє системі "розуміти" семантичні зв'язки, які виходять за межі текстового корпусу.
*   **Покращена техніка інтеграції тональності:** Запропоновано метод явного кодування інформації про тональність та заперечення, отриманої за допомогою інструменту MetaMap [140], у вигляді спеціалізованих векторів, які інтегруються з лексичними та онтологічними ембедінгами через механізм уваги.

### 2.2.2. Архітектура запропонованого методу

Задача NLI формулюється як класифікація пари речень (засновок, гіпотеза) на три класи: Entailment (слідування), Contradiction (суперечність) та Neutral (нейтральність). Загальна схема методу базується на архітектурі ESIM (Enhanced Sequential Inference Model) [116], яка доповнюється модулями обробки знань. Схема підходу представлена на рисунку 2.6.

![Загальна схема класифікації пар засновок-гіпотеза.](figs/figure_ch2_nli_scheme.pdf)
*Рисунок 2.6: Загальна схема класифікації пар засновок-гіпотеза, що включає етапи підготовки даних (токенізація, MetaMap), генерації мультимодальних векторних представлень, їх інтеграції та глибокого навчання для прийняття рішення.*

Компоненти запропонованої архітектури та їх функції узагальнено в Таблиці 2.5.

**Таблиця 2.5.** Компоненти запропонованої архітектури NLI для аналізу медичних текстів [113].

| Компонент | Функціональне призначення |
| :--- | :--- |
| BioELMo | Генерація контекстуальних векторів слів на основі корпусу PubMed. |
| MetaMap | Вилучення медичних концептів UMLS та ідентифікація заперечень. |
| MultE | Формування векторів вбудовування для концептів з графа знань. |
| Sentiment Vector | Бінарне кодування тональності (0 - позитивна/нейтральна, 1 - негативна/заперечення). |
| Attention Mechanism | Динамічне зважування важливості кожного типу вбудовування. |
| BiLSTM | Кодування послідовностей засновку та гіпотези з урахуванням контексту. |

Процес обробки даних складається з наступних етапів.

**Етап 1: Підготовка та токенізація.** Вхідні речення токенізуються за допомогою інструментарію CLTK [141], адаптованого для медичних текстів. Паралельно текст обробляється системою MetaMap для ідентифікації медичних концептів UMLS та виявлення заперечень.

**Етап 2: Генерація векторних представлень.** Для кожного токена $w$ формується композитний вектор, що складається з трьох компонентів:

*   **Контекстуальний вектор BioELMo ($e_{\text{BioELMo}}^w$).** Генерується попередньо навченою моделлю BioELMo, що забезпечує врахування лінгвістичного контексту. Розмірність вектора $d_{BioELMo} = 1024$.
*   **Вектор знань MultE ($e_{\text{MultE}}^w$).** Генерується моделлю вбудовування графів знань MultE. Ця модель навчається на підграфі UMLS, релевантному для вхідних даних. Функція оцінки правдоподібності трійки $(h, r, t)$ у MultE визначається як:

$$
\phi(h, r, t) = \text{ReLU}(\mathbf{W}_r \mathbf{r} + b_r) \odot \text{ReLU}(\mathbf{W}_h \mathbf{h} + b_h) \cdot \text{ReLU}(\mathbf{W}_t \mathbf{t} + b_t),
$$

де $\mathbf{h}, \mathbf{t}, \mathbf{r}$ — вектори сутностей та відношень, $\mathbf{W}$ та $b$ — параметри проекцій, $\odot$ — поелементне множення. Це дозволяє моделювати нелінійні взаємодії між концептами.
*   **Вектор тональності ($s^w$).** Бінарний вектор або скаляр, що вказує на наявність заперечення для даного токена (наприклад, $s^w=1$, якщо токен є частиною запереченого симптому).

**Етап 3: Інтеграція векторів.** Різнорідні вектори об'єднуються за допомогою механізму уваги (Attention mechanism), який дозволяє моделі динамічно визначати важливість кожного компонента. Результуючий вектор $\mathbf{e}^{ww}$ обчислюється як:

$$
\mathbf{e}^{ww} = \sum_{k=1}^{3} a_k \mathbf{v}_k,
$$

де $\mathbf{v}_k$ — проектовані вектори компонентів, а $a_k$ — ваги уваги, що розраховуються через Softmax функцію від оцінок важливості:

$$
a_k = \frac{\exp(f_{att}(\mathbf{v}_k))}{\sum_{j=1}^{3} \exp(f_{att}(\mathbf{v}_j))}.
$$

Ілюстрація процесу об'єднання наведена на рисунку 2.7.

![Схема формування композитного векторного представлення токена.](figs/figure_ch2_embedding_combination.pdf)
*Рисунок 2.7: Схема формування композитного векторного представлення токена шляхом злиття контекстуальних (BioELMo), онтологічних (MultE) та тональних ознак (Sentiment Vector) через механізм вирівнювання.*

На рисунку 2.8 показано деталізовану архітектуру рекурентної мережі, що використовується для обробки отриманих ембедінгів.

![Архітектура BiLSTM для медичного NLI.](figs/figure_ch2_bilstm_arch.pdf)
*Рисунок 2.8: Архітектура BiLSTM для медичного NLI: два потоки кодування (засновок/гіпотеза), механізм перехресної уваги та шар класифікації.*

**Етап 4: Глибоке навчання та класифікація.** Збагачені вектори подаються на вхід архітектури ESIM. Вона включає шари BiLSTM для кодування послідовностей, механізм перехресної уваги для вирівнювання засновку та гіпотези (Local Inference Modeling), та шар композиції, який формує вектори різниці та поелементного добутку для виявлення суперечностей. Матриця уваги $A_{ij}$ між прихованими станами засновку $\bar{p}_i$ та гіпотези $\bar{h}_j$ обчислюється як:

$$
A_{ij} = \bar{p}_i^T \bar{h}_j.
$$

![Деталізація механізму уваги в моделі ESIM.](figs/figure_ch2_attention_esim.pdf)
*Рисунок 2.9: Деталізація механізму уваги в моделі ESIM, який обчислює матрицю схожості між словами засновку та гіпотези для визначення локальних висновків.*

Фінальна класифікація здійснюється через повнозв'язний шар з функцією активації Softmax:

$$
\hat{y} = \text{Softmax}(\mathbf{W}_{mlp} v_{final} + b_{mlp}),
$$

де $v_{final}$ — агрегований вектор представлення пари речень.

![Фрагмент графа знань UMLS.](figs/figure_ch2_umls_fragment.pdf)
*Рисунок 2.10: Фрагмент графа знань UMLS, що демонструє семантичні типи та відношення між медичними поняттями, які використовуються для навчання моделі MultE.*

Для кращого розуміння джерела знань, на рисунку 2.10 наведено приклад структури UMLS, що використовується для генерації векторів MultE. Ця структурована інформація дозволяє моделі розуміти зв'язки типу "є симптомом" або "лікує", які часто опускаються в тексті.

![Логіка формування вектора тональності на основі виводу MetaMap.](figs/figure_ch2_sentiment_logic.pdf)
*Рисунок 2.11: Логіка формування вектора тональності на основі виводу MetaMap: виявлення заперечень (Negation) та їх кодування у бінарний вектор.*

Нарешті, рисунок 2.11 ілюструє процес вилучення тональності, що є критичним для розрізнення тверджень про наявність та відсутність симптомів.

---

# Розділ 3. Методи, моделі та засоби інтеграції знань діагностичних моделей в архітектури глибокого навчання медичних систем

## 3.1. Теоретико-методологічні засади інтеграції апріорних знань у стохастичні моделі навчання

Сучасна парадигма побудови систем підтримки прийняття лікарських рішень у медичних діагностичних комплексах переживає фундаментальну трансформацію, зумовлену переходом від детермінованих експертних систем до імовірнісних моделей глибокого навчання (Deep Learning, DL). Незважаючи на безпрецедентні успіхи згорткових нейронних мереж (CNN) та трансформерних архітектур у задачах розпізнавання образів, їхнє практичне впровадження у клінічну практику стримується низкою критичних факторів, серед яких ключовими є проблема інтерпретованості (ефект "чорної скриньки"), низька стійкість до збурень (adversarial robustness) та висока залежність від обсягу анотованих даних, які у медичній галузі є дефіцитним ресурсом.

Загальна наукова гіпотеза даного розділу дисертаційної роботи базується на твердженні, що подолання зазначених обмежень можливе лише шляхом переходу від чистої парадигми навчання на основі даних (data-driven) до гібридної парадигми навчання, інформованого знаннями (knowledge-informed learning). У цьому контексті ми розглядаємо інтеграцію знань не як евристичне доповнення, а як математично обґрунтовану модифікацію простору пошуку рішень моделі.

Формалізуємо задачу навчання нейронної мережі як пошук оптимального набору параметрів $\theta^* \in \mathbb{R}^d$, що мінімізує функціонал емпіричного ризику $\mathcal{R}_{emp}(\theta)$ на навчальній вибірці $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N$:

$$
\theta^* = \arg\min_{\theta \in \Theta} \frac{1}{N} \sum_{i=1}^N \mathcal{L}(f(x_i; \theta), y_i),
$$

де $\mathcal{L}$ — функція втрат (наприклад, перехресна ентропія), а $f$ — функція, що апроксимується мережею. У медичних задачах, де розмірність простору ознак $x_i$ значно перевищує кількість зразків $N$ (прокляття розмірності), простір розв'язків $\Theta$ містить велику кількість локальних мінімумів, які забезпечують нульову помилку на навчальній вибірці, але не гарантують узагальнення на генеральній сукупності, що призводить до перенавчання.

Запропонований у цьому розділі підхід полягає у звуженні простору допустимих рішень шляхом введення індуктивного зміщення (inductive bias), що базується на верифікованих медичних знаннях $\mathcal{K}$. Ми розглядаємо знання $\mathcal{K}$ як набір обмежень або регуляризаторів, що трансформують задачу безумовної оптимізації у задачу умовної оптимізації або Байєсівського виведення з апріорним розподілом $P(\theta|\mathcal{K})$. Тоді цільова функція модифікується наступним чином:

$$
\theta^*_{informed} = \arg\min_{\theta \in \Theta} \left( \mathcal{L}_{data}(\theta; \mathcal{D}) + \lambda \mathcal{R}_{knowledge}(\theta; \mathcal{K}) \right),
$$

де $\mathcal{R}_{knowledge}$ — функціонал, що оцінює ступінь узгодженості моделі з базою знань, а $\lambda$ — коефіцієнт Лагранжа, що регулює вплив знань.

У рамках цього розділу розроблено, теоретично обґрунтовано та реалізовано два нових методи, що втілюють цю концепцію на різних рівнях абстракції:

*   На рівні піксельної обробки зображень: розроблено метод SKIF-Seg (Synergistic Knowledge Integration Framework for Segmentation), що інтегрує просторові експертні знання та топологічні обмеження в процес сегментації.
*   На рівні семантичного аналізу об'єктів: розроблено метод KI-GCN (Knowledge-Informed Graph Convolutional Network), що інтегрує реляційні діагностичні знання в процес класифікації патологій.

Обидва методи спрямовані на досягненення центрольної мети дисертації — підвищення точності та клінічної достовірності автоматизованої діагностики через використання накопиченого медичного досвіду, формалізованого математичними методами. Нижче наведено детальний опис кожного з розроблених методів, їхню математичну формалізацію, алгоритмічну реалізацію та аналіз результатів.

## 3.2. Метод синергетичної структури інтеграції знань для сегментації серцевих МРТ-зображень (SKIF-Seg)

Сегментація анатомічних структур серця на зображеннях магнітно-резонансної томографії (МРТ) є критично важливим етапом у ланцюжку кардіологічної діагностики. Точне виділення контурів лівого шлуночка (ЛШ), правого шлуночка (ПШ) та міокарда (Міо) дозволяє розрахувати такі життєво важливі параметри, як фракція викиду, ударний об'єм та маса міокарда [26]. Незважаючи на успіхи архітектур типу U-Net [150], стандартні підходи страждають від ігнорування глобальної топології об'єктів. Нейронні мережі, що оптимізують піксельні метрики (Dice, Cross-Entropy), часто генерують анатомічно неможливі структури: розриви в кільці міокарда, появу "острівців" тканин у порожнинах або перетин областей, що мають бути розділеними [83].

### 3.2.1. Науковий внесок 1: Визначення, новизна та ціннісна пропозиція

**Науковий внесок:** Розроблено метод SKIF-Seg (Synergistic Knowledge Integration Framework for Segmentation), який є глибокою згортковою нейронною мережею з модифікованою архітектурою та функцією втрат. Метод базується на синергетичному поєднанні двох компонентів:

*   **Механізму Експертно-Керованої Уваги (Expert-Guided Attention, EGA):** Модуль, що інтегрує явні просторові пріори (карти уваги, згенеровані на основі знань експертів про типові зони помилок) у процес вилучення ознак.
*   **Топологічно-Обізнаних Анатомічних Обмежень (Topologically-Aware Anatomical Constraint, TAAC):** Спеціалізована функція втрат, що базується на диференційовних перетвореннях відстані та морфологічних операціях для штрафування за порушення топології.

![Загальна схема запропонованого двоступеневого конвеєра.](figs/figure_ch3_pipeline_skifseg.png)
*Рисунок 3.1: Загальна схема запропонованого двоступеневого конвеєра: Стадія 1 — анатомічно обмежена сегментація (SKIF-Seg), Стадія 2 — графова класифікація (KI-GCN).*

На рисунку 3.1 представлено загальну архітектуру системи, що демонструє взаємодію між модулями сегментації та класифікації.

**Наукова новизна:**

*   Вперше запропоновано механізм EGA, який на відміну від класичних механізмів уваги (self-attention або gating attention [151]), використовує зовнішній сигнал — карту експертних пріорів $E$, що дозволяє мережі фокусуватися на клінічно складних зонах (наприклад, місцях кріплення папілярних м'язів) ще до формування високорівневих ознак.
*   Розроблено математичне формулювання функції втрат TAAC, яка, на відміну від існуючих методів регуляризації форми (shape priors), явно кодує відношення вкладеності та суміжності між кількома класами одночасно через використання функцій знакової відстані (Signed Distance Functions, SDF) у диференційованому вигляді.
*   Обґрунтовано синергетичний ефект поєднання EGA та TAAC: EGA покращує локальну розрізнювальну здатність у складних зонах, що полегшує оптимізацію глобальної топології за допомогою TAAC, запобігаючи застряганню в локальних мінімумах.

**Ціннісна пропозиція та переваги:**

*   Метод забезпечує отримання анатомічно валідних масок сегментації без необхідності ручної корекції.
*   Підвищується стійкість до артефактів зображення за рахунок використання апріорних знань.
*   Забезпечується вища точність розрахунку клінічних метрик (об'ємів, маси), що критично важливо для діагностики кардіоміопатій.

Проблема інтеграції знань у сегментацію активно досліджується. Існуючі підходи можна класифікувати наступним чином:

*   Статистичні моделі форми (ASM/AAM): Використовують PCA для моделювання варіацій форми. Недолік: лінійність моделей не дозволяє охопити всі патологічні деформації.
*   Атласні методи: Базуються на реєстрації зображень до атласу. Недолік: висока обчислювальна складність та чутливість до помилок реєстрації.
*   Пост-обробка (CRF, Morphological cleaning): Застосовуються до виходу нейромережі. Недолік: не впливають на ваги мережі, не навчаються end-to-end [65].
*   Втрати на основі топології (Persistent Homology): Використовують діаграми стійкості для відстеження топологічних ознак. Недолік: надзвичайна обчислювальна складність ($O(N^3)$) та складність диференціювання [34].

На відміну від вищезазначених методів, SKIF-Seg пропонує обчислювально ефективний ($O(N)$) та повністю диференційовний підхід, що дозволяє інтегрувати як локальні (через увагу), так і глобальні (через топологічні втрати) знання в єдиному циклі навчання.

### 3.2.2. Постановка науково-прикладної задачі та формалізація обмежень

Розглянемо вхідне зображення $I: \Omega \to \mathbb{R}$, де $\Omega \subset \mathbb{R}^2$ — область визначення зображення (піксельна решітка). Задачею сегментації є відображення кожного пікселя $x \in \Omega$ у клас $c \in \mathcal{C} = \{0, \dots, K-1\}$, де $K$ — кількість класів (для серця $K=4$: фон, ЛШ, Міо, ПШ).

Основною проблемою, яку вирішує цей науковий внесок, є невідповідність між статистичною природою навчання CNN та детермінованою природою анатомічної топології. Стандартна функція втрат розглядає ймовірність приналежності пікселя до класу $P(y|x)$ як незалежну від сусідів, що призводить до порушення топологічних інваріантів.

![Приклади типових топологічних помилок при стандартній сегментації.](figs/figure_ch3_topological_problems.pdf)
*Рисунок 3.2: Приклади типових топологічних помилок при стандартній сегментації (розриви міокарда, некоректне вкладення) та концепція їх виправлення за допомогою запропонованих обмежень.*

Ми формулюємо наступні анатомічні обмеження, які повинні виконуватися для коректної сегментації серця (ілюстрація на рис. 3.2):

*   **Топологічне обмеження вкладеності (C1):** Порожнина ЛШ повинна бути повністю оточена міокардом (Міо) на всіх зрізах, де присутні обидві структури.
*   **Топологічне обмеження суміжності (C2):** ПШ повинен бути суміжним з міокардом, розділеним міжшлуночковою перегородкою, але не повинен перетинатися з порожниною ЛШ.
*   **Геометричне обмеження безперервності (C3):** Усі сегментовані області повинні бути однозв'язними (single connected components), за винятком випадків біфуркації на краях об'єму (що рідко зустрічається на 2D зрізах середини серця).

Мотивація розробки методу SKIF-Seg полягає у створенні механізму, який дозволяє "вмонтувати" ці обмеження безпосередньо в процес навчання мережі, уникаючи складних етапів пост-обробки, які не є диференційовними та не покращують репрезентативну здатність самої моделі [16].

### 3.2.3. Алгоритмічна формалізація SKIF-Seg

Архітектура базується на U-Net з кодувальником (encoder) та декодувальником (decoder). Ключовою модифікацією є заміна стандартних skip-connections на модулі Expert-Guided Attention (EGA).

![Архітектура SKIF-Seg з інтегрованими модулями Expert-Guided Attention.](figs/figure_ch3_skifseg_arch.pdf)
*Рисунок 3.3: Архітектура SKIF-Seg з інтегрованими модулями Expert-Guided Attention (EGA) та функцією втрат TAAC. Показано потік інформації через skip-connections, керований експертними картами.*

Нехай $x^{(l)} \in \mathbb{R}^{H_l \times W_l \times C_l}$ — карта ознак з $l$-го рівня кодувальника, а $g^{(l)} \in \mathbb{R}^{H_l \times W_l \times C_g}$ — сигнал стробування (gating signal) з попереднього рівня декодувальника. У SKIF-Seg ми вводимо додатковий вхід — карту експертних знань $\mathcal{E}^{(l)}$, яка масштабується до роздільної здатності рівня $l$.

Для забезпечення стабільного навчання та ефективності методу визначено оптимальні значення гіперпараметрів, що наведені у Таблиці 3.1.

**Таблиця 3.1.** Конфігурація гіперпараметрів навчання для моделі SKIF-Seg.

| Параметр | Значення |
| :--- | :--- |
| Оптимізатор | Adam |
| Швидкість навчання (learning rate) | $1 \times 10^{-4}$ |
| Розмір батчу | 8 |
| Кількість епох | 200 |
| Коефіцієнт ваги $\lambda_{enc}$ | 1.0 |
| Коефіцієнт ваги $\lambda_{adj}$ | 0.5 |
| Коефіцієнт ваги $\lambda_{overlap}$ | 0.5 |

**Математична модель модуля EGA:**

1.  **Лінійна проекція та інтеграція сигналів:**
    Карта ознак, сигнал стробування та карта експертних знань проектуються в проміжний простір ознак розмірності $F_{int}$:

$$
W_x x^{(l)}_i + W_g g^{(l)}_i + W_e \mathcal{E}^{(l)}_i + b_g,
$$

    де $W_x, W_g, W_e$ — вагові матриці згорток $1\times1$, $b_g$ — зміщення, $i$ — просторовий індекс пікселя.

2.  **Активація нелінійності:**
    Застосовується функція активації (наприклад, ReLU) для внесення нелінійності $\sigma_1(\cdot)$:

$$
q_{att}^{(l)} = \sigma_1 \left( W_x x^{(l)} + W_g g^{(l)} + W_e \mathcal{E}^{(l)} + b_g \right).
$$

3.  **Генерація коефіцієнтів уваги:**
    Отриманий сигнал проектується в скалярний простір (1 канал) та проходить через сигмоїду $\sigma_2(z) = \frac{1}{1+e^{-z}}$ для отримання коефіцієнтів уваги $\alpha^{(l)} \in [0, 1]$:

$$
\alpha^{(l)} = \sigma_2 \left( W_\psi q_{att}^{(l)} + b_\psi \right),
$$

    де $W_\psi$ — вагова матриця вихідної згортки.

4.  **Модуляція ознак:**
    Вихідна карта ознак $\hat{x}^{(l)}$ отримується шляхом поелементного множення вхідних ознак на коефіцієнти уваги:

$$
\hat{x}^{(l)} = \alpha^{(l)} \odot x^{(l)}.
$$

![Детальна схема модуля EGA (Expert-Guided Attention).](figs/figure_ch3_ega_detail.pdf)
*Рисунок 3.4: Детальна схема модуля EGA (Expert-Guided Attention), що демонструє об'єднання вхідних ознак, сигналу стробування та карти експертних знань для генерації маски уваги.*

Введення члена $W_e \mathcal{E}^{(l)}$ є критичним нововведенням (див. рис. 3.4). $\mathcal{E}^{(l)}$ містить апріорну інформацію про ймовірність знаходження межі об'єкта або складної зони в даному пікселі. Це створює градієнтний потік, що змушує мережу приділяти більше "уваги" (ваги) саме тим регіонам, які є анатомічно значущими, навіть якщо контрастність зображення в них є низькою.

**Топологічно-Обізнані Анатомічні Обмеження (TAAC).** Функція втрат $\mathcal{L}_{TAAC}$ розроблена для покарання за порушення топологічних інваріантів. Вона базується на теорії функцій знакової відстані (Signed Distance Functions, SDF).

![Концепція функцій знакової відстані (SDF) для анатомічних структур.](figs/figure_ch3_sdf_concept.pdf)
*Рисунок 3.5: Концепція функцій знакової відстані (SDF) для анатомічних структур: (а) Бінарна маска, (б) Карта SDF, де значення відображають відстань до межі (негативні всередині, позитивні ззовні).*

Для кожної анатомічної структури $k$ визначимо прогнозовану карту ймовірностей $P_k(x)$ та SDF істинної маски $\Phi_k(x)$ (рис. 3.5). Властивість SDF полягає в тому, що $\Phi_k(x) < 0$ всередині об'єкта, $\Phi_k(x) > 0$ ззовні, а $|\Phi_k(x)|$ дорівнює відстані до найближчої точки границі $\partial \Omega_k$.

1.  **Втрата оточення (Enclosure Loss) $\mathcal{L}_{enc}$.** Для забезпечення того, щоб ЛШ був оточений міокардом, ми вимагаємо, щоб область ЛШ знаходилася всередині "зовнішньої оболонки" міокарда, але не перетиналася з самим міокардом.
    Формалізуємо це через взаємодію SDF. Нехай $\Phi_{Myo}^{in}(x)$ та $\Phi_{Myo}^{out}(x)$ — відстані до внутрішньої та зовнішньої меж міокарда відповідно. Умова вкладеності ЛШ означає, що для всіх $x$, де $P_{LV}(x) \approx 1$, має виконуватися умова знаходження всередині порожнини, утвореної міокардом.
    Ми пропонуємо наступне формулювання втрати:

$$
\mathcal{L}_{enc} = \sum_{x \in \Omega} P_{LV}(x) \cdot \text{ReLU}(\Phi_{Myo}^{combined}(x)),
$$

    де $\Phi_{Myo}^{combined}(x)$ — спеціально сконструйована карта відстаней, яка є додатною за межами зовнішнього контуру міокарда. Таким чином, будь-який піксель, класифікований як ЛШ ($P_{LV} > 0$), що знаходиться за межами міокарда ($\Phi > 0$), створює позитивний штраф.

2.  **Втрата суміжності (Adjacency Loss) $\mathcal{L}_{adj}$.** Для забезпечення контакту між ПШ та міокардом без їх перекриття, ми використовуємо втрату, що мінімізує середню відстань між поверхнями у зоні контакту, одночасно штрафуючи перетин.

$$
\mathcal{L}_{adj} = \sum_{x \in \Omega} P_{RV}(x) \cdot \exp(-\alpha \cdot |\Phi_{Myo}(x)|) \cdot \mathbb{I}(\Phi_{Myo}(x) > 0),
$$

    де експоненційний член діє як "магніт", притягуючи ПШ до міокарда, але індикаторна функція та структура мережі (Softmax) запобігають проникненню всередину.

![Візуалізація дії компонентів функції втрат TAAC.](figs/figure_ch3_topological_losses.pdf)
*Рисунок 3.6: Візуалізація дії компонентів функції втрат TAAC: $\mathcal{L}_{enc}$ штрафує вихід ЛШ за межі міокарда, $\mathcal{L}_{adj}$ забезпечує прилягання ПШ, $\mathcal{L}_{overlap}$ запобігає перекриттю.*

3.  **Втрата перекриття (Overlap Loss) $\mathcal{L}_{overlap}$** (див. рис. 3.6). Хоча Softmax гарантує суму ймовірностей рівну 1, він не забороняє ситуацію, коли $P_{LV}=0.5$ і $P_{RV}=0.5$. Щоб забезпечити чіткі межі (бінарність рішень), вводиться штраф за добуток ймовірностей несумісних класів:

$$
\mathcal{L}_{overlap} = \sum_{(k, m) \in \mathcal{K}_{conflict}} \sum_{x \in \Omega} P_k(x) \cdot P_m(x),
$$

    де $\mathcal{K}_{conflict}$ — множина пар класів, що не можуть перетинатися (наприклад, ЛШ та ПШ).

Загальна цільова функція:

$$
\mathcal{L}_{Total} = \mathcal{L}_{Dice} + \mathcal{L}_{CE} + \lambda_{TAAC} (\mathcal{L}_{enc} + \mathcal{L}_{adj} + \mathcal{L}_{overlap}).
$$

Гіперпараметр $\lambda_{TAAC}$ поступово збільшується під час навчання (warm-up strategy), дозволяючи мережі спочатку вивчити грубі ознаки, а потім уточнити топологію.

### 3.2.4. Алгоритм навчання та реалізація SKIF-Seg

Наведемо формальний алгоритм роботи методу.

**Вхідні дані:** Набір навчальних даних $\mathcal{D} = \{(I_i, M_i, E_i)\}_{i=1}^N$, де $I_i$ — зображення, $M_i$ — маска, $E_i$ — експертна карта.
**Вихідні дані:** Оптимізовані параметри мережі $\theta^*$.

**Крок 1: Попередня обробка.**
*   Нормалізація інтенсивності $I_i$ (Z-score).
*   Генерація карт відстаней $\Phi_k$ з масок $M_i$ за допомогою алгоритму Евклідового перетворення відстані (EDT).

**Крок 2: Ініціалізація.**
*   Ініціалізація ваг $\theta$ (He initialization).
*   Встановлення $\lambda_{TAAC} = 0$.

**Крок 3: Ітеративне навчання (для кожної епохи $t$).**
*   Для кожного міні-батчу $B \subset \mathcal{D}$:
    *   Пряме поширення:
        *   Отримати карти ознак кодувальника.
        *   Обчислити коефіцієнти уваги $\alpha^{(l)}$ за формулою модифікованої уваги, використовуючи $E_i$.
        *   Отримати прогноз $P = f_\theta(I_i, E_i)$.
    *   Обчислення втрат:
        *   Обчислити $\mathcal{L}_{Dice}(P, M_i)$ та $\mathcal{L}_{CE}(P, M_i)$.
        *   Якщо $t > T_{warmup}$, обчислити $\mathcal{L}_{TAAC}$ за формулами TAAC.
        *   $\mathcal{L}_{batch} = \mathcal{L}_{base} + \lambda(t) \mathcal{L}_{TAAC}$.
    *   Зворотне поширення:
        *   Обчислити градієнти $\nabla_\theta \mathcal{L}_{batch}$.
        *   Оновити ваги: $\theta \leftarrow \theta - \eta \cdot \text{Adam}(\nabla_\theta)$.

### 3.2.5. Експериментальна валідація та аналіз результатів

Для валідації методу використовувався загальнодоступний набір даних ACDC (Automated Cardiac Diagnosis Challenge) [26], що містить 100 пацієнтів з різними патологіями.

**Протокол експерименту.** Мережа навчалася протягом 200 епох. Розмір батчу — 8. Оптимізатор — Adam з початковою швидкістю навчання $10^{-4}$. Використовувалася 5-кратна перехресна валідація.

У Таблиці 3.2 наведено порівняння запропонованого методу з базовими архітектурами.

**Таблиця 3.2.** Порівняння продуктивності сегментації на тестовому наборі ACDC. Метрики: коефіцієнт Дайса (DSC, %) та відстань Хаусдорфа 95% (HD95, мм). $\uparrow$ — краще більше, $\downarrow$ — краще менше.

| Модель | ЛШ (DSC) $\uparrow$ | ЛШ (HD95) $\downarrow$ | ПШ (DSC) $\uparrow$ | ПШ (HD95) $\downarrow$ | Міо (DSC) $\uparrow$ | Міо (HD95) $\downarrow$ |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| U-Net (Baseline) | $93.0 \pm 1.6$ | $8.0 \pm 2.2$ | $90.0 \pm 2.1$ | $8.5 \pm 2.5$ | $85.5 \pm 2.5$ | $9.8 \pm 3.1$ |
| Att-U-Net [151] | $93.8 \pm 1.5$ | $7.2 \pm 2.0$ | $91.0 \pm 2.0$ | $7.8 \pm 2.3$ | $86.5 \pm 2.4$ | $8.9 \pm 2.9$ |
| U-Net + TAAC (Ours) | $94.5 \pm 1.4$ | $6.5 \pm 1.9$ | $92.0 \pm 1.8$ | $7.0 \pm 2.1$ | $87.8 \pm 2.2$ | $7.5 \pm 2.5$ |
| SKIF-Seg (Proposed) | **$95.5 \pm 1.2$** | **$5.5 \pm 1.8$** | **$93.0 \pm 1.7$** | **$6.0 \pm 2.0$** | **$89.0 \pm 2.0$** | **$6.5 \pm 2.3$** |

Аналіз результатів показує, що SKIF-Seg забезпечує статистично значуще покращення ($p < 0.01$) за всіма метриками. Найбільш показовим є зниження метрики HD95 для міокарда (з 9.8 мм до 6.5 мм), що свідчить про усунення грубих топологічних викидів. Окреме використання TAAC дає приріст, але комбінація з EGA (SKIF-Seg) дає найкращий результат, підтверджуючи гіпотезу про синергію: увага допомагає локалізувати складні межі, а TAAC гарантує їхню зв'язність.

![Якісне порівняння результатів сегментації.](figs/figure_ch3_segment_skifseg.pdf)
*Рисунок 3.7: Якісне порівняння результатів сегментації: (a) Оригінальне зображення; (b) Базова U-Net: помітні розриви в міокарді та некоректна форма ПШ; (c) SKIF-Seg: відновлена цілісність кільця міокарда та коректні межі шлуночків завдяки дії $\mathcal{L}_{enc}$ та $\mathcal{L}_{adj}$.*

## 3.3. Метод ідентифікації патологій серця з використанням знаннєво-орієнтованої графової згорткової мережі (KI-GCN)

У той час як сегментація надає кількісну інформацію про анатомію, кінцевою метою діагностичного комплексу є визначення патології (класифікація). Стандартні підходи до класифікації використовують глобальні ознаки зображення, ігноруючи складну систему взаємозв'язків між анатомічними структурами, яка лежить в основі клінічного мислення лікаря. Наприклад, діагноз "Гіпертрофічна кардіоміопатія" (HCM) базується не просто на потовщенні міокарда, а на специфічному співвідношенні товщини перегородки до задньої стінки.

### 3.3.1. Постановка задачі реляційної класифікації

Задачу класифікації можна формалізувати як відображення вхідних даних $X$ у клас $y \in \mathcal{Y}$. У нашому випадку $X$ — це не просто тензор пікселів, а структурований набір анатомічних об'єктів (сегментів), отриманих на попередньому етапі.

Проблема полягає в тому, що традиційні CNN (наприклад, ResNet), працюючи з піксельною решіткою, мають обмежену здатність до моделювання далеких залежностей (long-range dependencies) та реляційних міркувань (relational reasoning). Вони можуть вивчити текстурні ознаки фіброзу, але їм важко "зрозуміти" концепцію "відношення об'ємів".

Ми пропонуємо моделювати серце пацієнта як граф $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, де вузли $\mathcal{V}$ відповідають анатомічним структурам (ЛШ, ПШ, сегменти міокарда), а ребра $\mathcal{E}$ кодують їхні просторові, функціональні та патофізіологічні зв'язки.

![Схема побудови графа пацієнта з масок сегментації.](figs/figure_ch3_graph_construction.pdf)
*Рисунок 3.8: Схема побудови графа пацієнта з масок сегментації. Вузли представляють анатомічні регіони (ЛШ, ПШ, Міо), а ребра — просторові та часові (ED-ES) зв'язки.*

### 3.3.2. Науковий внесок 2: Визначення, новизна та ціннісна пропозиція

**Науковий внесок:** Розроблено метод KI-GCN (Knowledge-Informed Graph Convolutional Network), який інтегрує:

*   **Конструкцію графа на основі знань:** Граф будується не за принципом просторової суміжності пікселів, а на основі онтології серцевої анатомії та діагностичних правил.
*   **Гібридні вектори ознак:** Вузли графа агрегують як глибокі візуальні ознаки (deep visual features), так і явні морфологічні параметри (об'єми, товщини), розраховані з масок сегментації.
*   **Механізм поширення повідомлень (Message Passing):** Використовується модифікований оператор графової згортки, що враховує семантичні типи ребер.

**Наукова новизна:**

*   Запропоновано новий спосіб побудови матриці суміжності $\mathbf{A}$, яка є суперпозицією матриці просторової суміжності $\mathbf{A}_{spatial}$ та матриці діагностичних кореляцій $\mathbf{A}_{knowledge}$, отриманої шляхом аналізу медичних настанов (clinical guidelines). Це дозволяє моделі "звертати увагу" на зв'язки, які є клінічно значущими, навіть якщо структури просторово віддалені.
*   Вперше застосовано механізм Global Attention Pooling (GAP) у контексті серцевих графів для визначення вкладу кожного анатомічного сегмента у фінальний діагноз, що забезпечує інтерпретованість рішень.

**Ціннісна пропозиція:**

*   Підвищення точності діагностики на малих вибірках за рахунок сильного індуктивного зміщення (inductive bias), внесеного графовою структурою.
*   Забезпечення прозорості прийняття рішень: модель може "пояснити", які саме взаємозв'язки (наприклад, між ЛШ та ПШ) призвели до діагнозу.

### 3.3.3. Порівняльний аналіз із супутніми дослідженнями

Застосування Graph Neural Networks (GNN) у медицині набуває популярності. Існують роботи, що використовують GNN для класифікації гістологічних знімків [126] або аналізу функціональної зв'язності мозку. Однак, у кардіології більшість робіт обмежується аналізом поверхонь (meshes) для симуляції фізики.

Відмінність KI-GCN полягає в тому, що граф представляє не фізичну сітку, а семантичну мережу понять. На відміну від "чорних скриньок" CNN, KI-GCN явно оперує об'єктами, якими оперує лікар (шлуночок, перегородка), та їх параметрами, що робить цей підхід кроком до так званого пояснюваного штучного інтелекту (з англ. Explainable AI, XAI).

### 3.3.4. Алгоритмічна формалізація KI-GCN

**Побудова графа та ознак вузлів.** Нехай $M$ — маска сегментації, отримана від SKIF-Seg, а $I$ — вхідне зображення.
Ми визначаємо множину вузлів $\mathcal{V} = \{v_1, \dots, v_N\}$, де кожен вузол відповідає певній анатомічній області (ROI). Для набору даних ACDC ми виділяємо 3 основні структури у 2 фазах (ED та ES), а також розділяємо міокард на 6 секторів за стандартом AHA.

![Процес формування вектора ознак вузла.](figs/figure_ch3_node_features.pdf)
*Рисунок 3.9: Процес формування вектора ознак вузла $h_v$: об'єднання явно розрахованих морфологічних параметрів (об'єм, площа) та глибоких візуальних ознак, отриманих з backbone CNN.*

**Формування вектора ознак вузла $h_v$:**
Вектор ознак $h_v \in \mathbb{R}^{D}$ є конкатенацією двох векторів (рис. 3.9):

$$
h_v = [ f_{morph}(v) \parallel f_{deep}(v) ],
$$

де:
*   $f_{morph}(v) \in \mathbb{R}^{d_m}$ — вектор морфологічних ознак, розрахованих явно (об'єм, площа, середня товщина, сферичність).
*   $f_{deep}(v) \in \mathbb{R}^{d_d}$ — вектор глибоких ознак, отриманий шляхом проходження ROI відповідної структури через попередньо навчену CNN (backbone), наприклад, ResNet-18, з використанням ROI-Pooling.

Детальний склад ознак, що використовуються для формування вектора вузла, наведено у Таблиці 3.3.

**Таблиця 3.3.** Склад вектора ознак для вузлів графа у моделі KI-GCN [152].

| Тип ознак | Компоненти |
| :--- | :--- |
| Морфологічні | Клінічно стандартні індекси (об'єми, фракція викиду, маса, товщина стінки), розраховані на основі масок SKIF-Seg. |
| Глибокі (Deep Features) | Дескриптор, вилучений з "вузького місця" (bottleneck) навченого енкодера SKIF-Seg для кожної сегментованої структури. |

**Побудова матриці суміжності $\mathbf{A}$:**
Ми визначаємо матрицю суміжності як зважену суму компонентів:

$$
\mathbf{A} = \mathbf{A}_{spatial} + \gamma \mathbf{A}_{knowledge},
$$

де:
*   $\mathbf{A}_{spatial}(i, j) = 1$, якщо структури $i$ та $j$ є фізично суміжними.
*   $\mathbf{A}_{knowledge}(i, j) = w_{ij}$, де $w_{ij}$ — вага діагностичного зв'язку.

Наприклад, для діагностики аритмогенної дисплазії ПШ (ARV) зв'язок між об'ємом ПШ та станом міокарда є критичним, тому вага цього ребра штучно збільшується. $\gamma$ — гіперпараметр, що навчається або фіксується.

![Ілюстрація формування матриці суміжності.](figs/figure_ch3_adjacency_matrix.pdf)
*Рисунок 3.10: Ілюстрація формування матриці суміжності $\mathbf{A}$ як комбінації просторових зв'язків та експертних знань $\mathbf{A}_{knowledge}$.*

**Графова згортка та поширення знань.**
Ми використовуємо спектральну графову згортку за Кіпфом та Веллінгом (рис. 3.11). Правило оновлення ознак вузлів на шарі $l+1$:

$$
H^{(l+1)} = \sigma \left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} \Theta^{(l)} \right),
$$

де $\tilde{A} = \mathbf{A} + I_N$ (матриця з петлями), $\tilde{D}$ — діагональна матриця ступенів вузлів ($\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$), $H^{(l)}$ — матриця ознак усіх вузлів на шарі $l$, $\Theta^{(l)}$ — матриця ваг, що навчаються, $\sigma$ — функція активації (ReLU).

![Схематичне зображення операції графової згортки.](figs/figure_ch3_gcn_layer.pdf)
*Рисунок 3.11: Схематичне зображення операції графової згортки: агрегація інформації від сусідніх вузлів (анатомічних структур) для оновлення представлення поточного вузла.*

Ця операція фактично реалізує обмін інформацією між анатомічними структурами. Вузол "ЛШ" оновлює свій стан, отримуючи інформацію від вузла "Міокард" та "ПШ", враховуючи силу зв'язку, визначену в $\mathbf{A}$.

**Глобальний пулінг та класифікація.**
Після $L$ шарів GCN ми отримуємо матрицю збагачених ознак $H^{(L)}$. Для отримання єдиного вектора-дескриптора пацієнта $h_{graph}$ ми застосовуємо механізм Global Attention Pooling (GAP):

$$
\alpha = \text{Softmax}(w_{gate}^T \tanh(W_{gate} H^{(L)T})),
$$

$$
h_{graph} = \sum_{i=1}^N \alpha_i h_i^{(L)},
$$

де $\alpha_i$ — вага важливості $i$-го вузла (анатомічної структури) для прийняття рішення.

![Механізм Global Attention Pooling (GAP).](figs/figure_ch3_gap_mechanism.pdf)
*Рисунок 3.12: Механізм Global Attention Pooling (GAP), що дозволяє моделі автоматично визначати важливість кожного вузла графа (анатомічної структури) для формування фінального діагнозу.*

Це дозволяє моделі динамічно фокусуватися, наприклад, на ПШ при підозрі на ARV або на ЛШ при підозрі на DCM (див. рис. 3.12).

Фінальна класифікація здійснюється через багатошаровий перцептрон (MLP):

$$
Y_{pred} = \text{Softmax}(\text{MLP}(h_{graph})).
$$

Ваги компонентів функції втрат визначають баланс між точністю класифікації та відповідністю апріорним знанням. У Таблиці 3.4 наведено емпірично визначені значення, що використовувалися при навчанні.

**Таблиця 3.4.** Вагові коефіцієнти компонентів функції втрат для навчання моделі класифікації [152].

| Компонент втрат | Вага |
| :--- | :--- |
| $w_D$ (Dice) | 1.0 |
| $w_{CE}$ (Cross-Entropy) | 0.5 |
| $\lambda_{TAAC}$ (Топологічні обмеження) | 0.1 |

### 3.3.5. Алгоритм роботи KI-GCN

**Вхідні дані:** Множина пацієнтів $\mathcal{P}$, база знань $\mathcal{K}_{rules}$.
**Вихідні дані:** Навчена модель класифікації.

**Крок 1: Підготовка графів.**
Для кожного пацієнта $p \in \mathcal{P}$:
*   Виконати сегментацію за допомогою SKIF-Seg.
*   Розрахувати морфологічні ознаки $F_{morph}$.
*   Вилучити глибокі ознаки $F_{deep}$ з backbone CNN.
*   Сформувати матрицю ознак $H^{(0)}$ та матрицю суміжності $\mathbf{A}$.

**Крок 2: Навчання GNN.**
*   Мінімізувати функцію втрат перехресної ентропії:

$$
\mathcal{L}_{class} = - \sum_{c=1}^{N_{classes}} Y_{true, c} \log(Y_{pred, c}).
$$

*   Використовувати регуляризацію ваг уваги для забезпечення розрідженості (L1-norm на $\alpha$), щоб підвищити інтерпретованість.

### 3.3.6. Експериментальна валідація та аналіз результатів

Метод валідувався на задачі класифікації 5 класів (NOR, MINF, DCM, HCM, ARV) на наборі ACDC.

**Порівнювані методи:**
1.  3D-CNN (Baseline): Реснет-подібна мережа, що працює безпосередньо з вокселями.
2.  Handcrafted SVM: SVM, навчений лише на морфологічних ознаках (об'єми, EF).
3.  Standard GCN: GCN з матрицею суміжності, заснованою лише на просторовому сусідстві (без $\mathbf{A}_{knowledge}$).
4.  KI-GCN: Запропонований метод.

Результати класифікації представлені у Таблиці 3.5.

**Таблиця 3.5.** Порівняння продуктивності класифікації захворювань серця на тестовому наборі ACDC. $\pm$ позначає стандартне відхилення.

| Модель | Точність (%) | Макро F1 | Влучність | Повнота | AUC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| Базова CNN (3D ResNet) | $85.0 \pm 3.5$ | $0.84 \pm 0.04$ | $0.85 \pm 0.04$ | $0.84 \pm 0.05$ | $0.92 \pm 0.03$ |
| Базова морфологія (SVM) | $88.5 \pm 2.8$ | $0.88 \pm 0.03$ | $0.89 \pm 0.03$ | $0.88 \pm 0.04$ | $0.94 \pm 0.02$ |
| Стандартна GCN | $90.5 \pm 2.5$ | $0.90 \pm 0.03$ | $0.91 \pm 0.03$ | $0.90 \pm 0.03$ | $0.95 \pm 0.02$ |
| KI-GCN (Proposed) | **$94.0 \pm 2.0$** | **$0.94 \pm 0.02$** | **$0.94 \pm 0.02$** | **$0.94 \pm 0.02$** | **$0.97 \pm 0.01$** |

KI-GCN демонструє найкращі результати (Точність 94.0%), перевершуючи як "чорну скриньку" CNN (85.0%), так і класичний морфологічний аналіз (88.5\%). Це свідчить про те, що комбінація візуальних патернів (текстура тканини, видима на МРТ) та чітких метрик у графі дає найбільш повну картину.

Важливо, що введення знаннєвої матриці $\mathbf{A}_{knowledge}$ (порівняння Standard GCN vs KI-GCN) дало приріст у 3.5%, що підтверджує важливість явного моделювання діагностичних зв'язків.

![Інтерпретація ваг уваги $\alpha$ для різних класів захворювань.](figs/figure_ch3_attention_weights.pdf)
*Рисунок 3.13: Інтерпретація ваг уваги $\alpha$ (GAP weights) для різних класів захворювань. Наприклад, для ARV (аномалії ПШ) модель автоматично призначає найбільшу вагу вузлу "Правий Шлуночок".*

Аналіз ваг уваги $\alpha$ (GAP weights), показаний на рисунку 3.13, виявив цікаві закономірності:
*   Для пацієнтів з ARV, вага вузла "Правий Шлуночок" була в середньому в 2.5 рази вищою, ніж у інших класів.
*   Для пацієнтів з HCM, максимальні ваги отримували сегменти перегородки міокарда.

Це підтверджує, що модель не просто вивчила статистичні кореляції, а "зрозуміла" клінічну суть патологій, що робить її рішення інтерпретованими та надійними.

## 3.4. Висновки до Розділу 3

У даному розділі дисертаційної роботи було вирішено наукову задачу розробки методів та засобів інтеграції знань діагностичних моделей у системи штучного інтелекту.

Розроблено та математично обґрунтовано метод сегментації SKIF-Seg, який базується на синергетичному поєднанні механізму експертно-керованої уваги (EGA) та топологічно-обізнаних анатомічних обмежень (TAAC). Доведено, що використання TAAC у вигляді диференційовних функцій втрат на основі знакової відстані дозволяє гарантувати топологічну коректність сегментації (вкладеність, суміжність) в процесі наскрізного навчання. Експериментально підтверджено перевагу методу над існуючими аналогами (зростання метрики Dice до 95.5% для ЛШ, зменшення відстані Хаусдорфа для міокарда до 6.5 мм).

Розроблено метод класифікації KI-GCN, що реалізує парадигму реляційного міркування на графах. Запропоновано нову схему побудови графа пацієнта, де вузли інтегрують гібридні ознаки (візуальні та морфологічні), а ребра кодують діагностичні знання. Показано, що такий підхід дозволяє досягти точності 94.0% на наборі даних ACDC, перевершуючи традиційні CNN методи, та забезпечує інтерпретованість рішень через аналіз ваг уваги графового пулінгу.

Створено алгоритмічне та програмне забезпечення для реалізації запропонованих методів, що включає модулі попередньої обробки, генерації карт відстаней, побудови графів та навчання нейронних мереж.

Отримані результати створюють надійну методологічну основу для побудови наступного покоління медичних діагностичних систем, які поєднують потужність глибокого навчання з надійністю та прозорістю експертних знань, що повністю відповідає меті дисертаційного дослідження.

---

# Розділ 4. Експериментальні дослідження та верифікація методів інтеграції знань у медичні діагностичні системи

Четвертий розділ дисертаційної роботи присвячено комплексній експериментальній валідації, верифікації та порівняльному аналізу наукових результатів, отриманих у попередніх розділах. Основний фокус зосереджено на емпіричному підтвердженні гіпотез щодо результативності запропонованих методів інтеграції експертних та онтологічних знань у архітектури глибокого навчання. У контексті медичних діагностичних комплексів, де ціна помилки є критично високою, а обсяги анотованих даних часто є обмеженими, суто теоретичного обґрунтування моделей недостатньо. Необхідна ретельна перевірка стійкості (robustness), узагальнюючої здатності (generalization capability) та інтерпретованості (interpretability) розроблених алгоритмів на реальних клінічних даних.

Експериментальні дослідження структуровано навколо трьох ключових наукових внесків роботи: методу адаптивної дистиляції знань для подолання доменного зсуву в задачах класифікації, гібридної моделі висновування природною мовою (NLI) з інтеграцією семантики UMLS, та методу сегментації SKIF-Seg з топологічно-обізнаними анатомічними обмеженнями. Для кожного методу розроблено унікальний експериментальний протокол, що включає опис програмної реалізації, характеристику наборів даних, метрики оцінювання та глибокий статистичний аналіз результатів.

## 4.1. Архітектура програмного комплексу та методологія експерименту

Валідація розроблених математичних моделей вимагала створення спеціалізованого програмного середовища, яке б забезпечувало гнучкість у конструюванні обчислювальних графів, надійну роботу з гетерогенними даними (зображення, текст, графи знань) та відтворюваність експериментів.

### 4.1.1. Концептуальна архітектура експериментальної системи

Розроблений програмний комплекс базується на принципах модульної архітектури, що дозволяє ізолювати логіку обробки даних, навчання моделей та оцінювання результатів. Система реалізована як сукупність взаємодіючих компонентів, що функціонують у середовищі високопродуктивних обчислень (HPC).

![Загальна архітектура розробленого програмного комплексу IDK Medical AI.](figs/figure_ch4_software_arch.pdf)
*Рисунок 4.1: Загальна архітектура розробленого програмного комплексу IDK Medical AI, що складається з модулів імпорту (DICOM/NIfTI), ядра сегментації (SKIF-Seg), ядра класифікації (KI-GCN) та підсистеми звітування.*

На рисунку 4.1 зображено архітектурну діаграму системи. Ключовим елементом архітектури є Рівень абстракції даних (Data Abstraction Layer). У медичних дослідженнях дані часто надходять у специфічних форматах (DICOM для візуалізації, HL7/FHIR для текстових записів), що ускладнює їх безпосереднє використання у нейронних мережах. Розроблений модуль абстракції реалізує патерн проєктування «Стратегія» для уніфікації інтерфейсу доступу до даних. Формально, процес підготовки тензора даних $X_{tensor}$ з сирого джерела $S_{raw}$ можна описати як композицію функцій попередньої обробки $\Phi_{prep}$ та аугментації $\Phi_{aug}$:

$$
X_{tensor} = \Phi_{aug}(\Phi_{prep}(S_{raw}; \theta_{norm}); \theta_{stoch}),
$$

де $\theta_{norm}$ — параметри детермінованої нормалізації (наприклад, приведення інтенсивності пікселів МРТ до одиничного нормального розподілу), а $\theta_{stoch}$ — параметри стохастичних перетворень (випадкові обертання, еластичні деформації), що використовуються для регуляризації моделей.

Наступним рівнем є Обчислювальне ядро (Computational Core), побудоване на базі фреймворку PyTorch. Цей рівень відповідає за динамічну побудову графів обчислень, що є критично важливим для реалізації запропонованих методів, які включають умовні переходи (наприклад, у механізмах уваги) та роботу з графовими структурами. Процес навчання моделі $\mathcal{M}$ з параметрами $W$ формалізується як ітеративна мінімізація емпіричного ризику $\mathcal{R}_{emp}$ на навчальній вибірці $\mathcal{D}_{train}$:

$$
W^* = \arg\min_{W} \left( \frac{1}{|\mathcal{D}_{train}|} \sum_{(x,y) \in \mathcal{D}_{train}} \mathcal{L}(\mathcal{M}(x; W), y) + \lambda \Omega(W) \right),
$$

де $\mathcal{L}$ — цільова функція втрат, що може включати компоненти інтеграції знань (наприклад, топологічні втрати або втрати дистиляції), а $\Omega(W)$ — член регуляризації.

![Головне меню розробленої системи IDK Medical AI.](figs/figure_ch4_ui_main.pdf)
*Рисунок 4.2: Головне меню розробленої системи IDK Medical AI, що забезпечує доступ до модулів завантаження даних, сегментації, класифікації та налаштувань.*

Третім компонентом є Модуль інтеграції знань (Knowledge Integration Module). Це унікальна складова системи, що забезпечує інтерфейс між нейронними мережами та джерелами структурованих знань. Модуль включає адаптери для роботи з UMLS (через MetaMap API), генератори карт знакових відстаней (SDF) для топологічних обмежень та механізми агрегації для ансамблевих методів. Наприклад, для інтеграції знань з онтології, модуль перетворює символьні концепти $C_{umls}$ у вектори вбудовування $v_{emb}$ використовуючи попередньо навчену модель графових вбудовувань $f_{KGE}$:

$$
v_{emb} = f_{KGE}(C_{umls}; \Theta_{graph}),
$$

де $\Theta_{graph}$ — параметри графової моделі (наприклад, матриці сутностей та відношень у методі MultE).

![Інтерфейс модуля імпорту та анонімізації даних DICOM.](figs/figure_ch4_ui_import.pdf)
*Рисунок 4.3: Інтерфейс модуля імпорту та анонімізації даних DICOM, що дозволяє застосовувати профілі захисту приватності перед початком аналізу.*

Завершує архітектуру Система оцінювання та візуалізації. Вона забезпечує розрахунок статистичних метрик, проведення статистичних тестів та генерацію візуальних звітів (див. рис. 4.3).

### 4.1.2. Технічні деталі реалізації та середовище виконання

Для забезпечення високої продуктивності та відтворюваності, програмна реалізація базувалася на стеку технологій Python (версія 3.8+).

![Інтерфейс вікна запуску модуля сегментації SKIF-Seg.](figs/figure_ch4_ui_segmentation.pdf)
*Рисунок 4.4: Інтерфейс вікна запуску модуля сегментації SKIF-Seg, що надає можливість вибору моделі, параметрів постобробки та апаратного прискорювача.*

Вибір фреймворку PyTorch (версія 1.10+) обумовлений його гнучкістю та підтримкою динамічних графів, що спростило реалізацію нестандартних шарів, таких як Expert-Guided Attention (EGA) та Graph Convolutional Layers. Для низькорівневих операцій з тензорами використовувалася бібліотека NumPy, а для обробки медичних форматів зображень (NIfTI, DICOM) — бібліотеки SimpleITK та NiBabel. Специфічні алгоритми, такі як розрахунок точних евклідових карт відстаней (EDT) для функції втрат TAAC, були реалізовані з використанням оптимізованих процедур бібліотеки SciPy, що забезпечило прийнятну швидкість навчання.

![Налаштування обчислювальних ресурсів.](figs/figure_ch4_ui_hardware.pdf)
*Рисунок 4.5: Налаштування обчислювальних ресурсів: вибір між CPU, CUDA та DirectML для забезпечення крос-платформеної сумісності.*

Навчання моделей проводилося на кластерному обчислювальному вузлі, оснащеному графічними прискорювачами NVIDIA Tesla A100 з 40 ГБ відеопам'яті (інтерфейс вибору показано на рис. 4.5).

## 4.2. Експериментальне дослідження методу дистиляції знань для адаптації домену

Першим напрямком експериментальної валідації стала перевірка результативності розробленого методу дистиляції знань (Knowledge Distillation) для задачі адаптації домену (Domain Adaptation) у класифікації медичних зображень.

### 4.2.1. Експериментальна установка: Набори даних та базові моделі

Для моделювання реалістичного сценарію доменного зсуву було використано три масивні набори даних рентгенографії грудної клітки:
*   **ChestX-ray14 (CXR14):** 112,120 зображень. Використовувався як Початковий Домен 1.
*   **CheXpert:** 224,316 зображень. Використовувався як Початковий Домен 2.
*   **MIMIC-CXR:** 377,110 зображень. Використовувався як Цільовий Домен.

Завдання полягало у бінарній класифікації наявності патології. Як базові моделі (Baselines) для порівняння були обрані:
1.  **Target Only:** ResNet-18, навчена виключно на малій розміченій вибірці цільового домену.
2.  **Source Only:** ResNet-50, застосована безпосередньо до цільового домену.
3.  **Fine-tuning:** Попереднє навчання на початкових даних + доналаштування.
4.  **DANN:** Стандартний метод адаптації домену без дистиляції.

### 4.2.2. Результати та аналіз дистиляції

Результати експериментів, проведених на тестовій вибірці MIMIC-CXR, представлено у Таблиці 4.1.

**Таблиця 4.1.** Порівняння результативності методів адаптації домену на тестовому наборі MIMIC-CXR. Результати представлено як середнє значення AUC-ROC (%) $\pm$ стандартне відхилення.

| Метод | 500 зразків | 1000 зразків | 2000 зразків |
| :--- | :---: | :---: | :---: |
| Target Only (ResNet-18) | 72.15 $\pm$ 1.20 | 75.40 $\pm$ 0.95 | 78.10 $\pm$ 0.80 |
| Source Only (ResNet-50) | 74.80 $\pm$ 0.00 | 74.80 $\pm$ 0.00 | 74.80 $\pm$ 0.00 |
| Fine-tuning | 76.50 $\pm$ 0.85 | 79.20 $\pm$ 0.70 | 81.50 $\pm$ 0.60 |
| DANN [37] | 77.10 $\pm$ 1.05 | 79.80 $\pm$ 0.90 | 82.20 $\pm$ 0.75 |
| Запропонована Multi-Teacher KD | **81.45 $\pm$ 0.65** | **83.90 $\pm$ 0.55** | **86.10 $\pm$ 0.50** |

Аналіз отриманих даних дозволяє зробити кілька важливих висновків. По-перше, метод Target Only демонструє найнижчі результати, що підтверджує неможливість навчання глибоких мереж "з нуля" в умовах дефіциту даних. По-друге, запропонований метод Multi-Teacher KD демонструє статистично значуще покращення ($p < 0.01$) порівняно з усіма базовими методами. Навіть при використанні лише 500 розмічених зразків, наша модель досягає AUC 81.45%, що перевершує результат DANN на 4.35%.

**Таблиця 4.2.** Абляційне дослідження: вплив адаптивного зважування (AW) на ефективність цільового домену [147].

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без AW | 84.0 | 83.0 | 83.5 | 83.2 | 88.5 |
| EMTKD (з AW) | **88.5** | **87.5** | **88.0** | **87.7** | **92.5** |

**Таблиця 4.3.** Абляційне дослідження: вплив доменної адаптації (DA) у моделях-вчителях [147].

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без DA | 81.2 | 80.0 | 80.5 | 80.2 | 85.0 |
| EMTKD (з DA) | **88.5** | **87.5** | **88.0** | **87.7** | **92.5** |

**Таблиця 4.4.** Абляційне дослідження: вплив напівкерованого навчання (SSL) [147].

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без SSL | 85.5 | 84.5 | 85.0 | 84.7 | 89.5 |
| EMTKD (з SSL) | **88.5** | **87.5** | **88.0** | **87.7** | **92.5** |

![Візуалізація простору ознак за допомогою t-SNE.](figs/figure_ch4_tsne_kdb.pdf)
*Рисунок 4.6: Візуалізація простору ознак за допомогою t-SNE: запропонований метод формує чіткі кластери, що свідчить про успішну адаптацію доменно-інваріантних ознак.*

![Візуалізація адаптивних ваг для трьох вчителів.](figs/figure_ch4_adaptive_weights.pdf)
*Рисунок 4.7: Візуалізація адаптивних ваг $w_t(x)$ для трьох вчителів на 200 зразках цільового домену. Яскравіші кольори відповідають вищій вазі, що демонструє здатність моделі динамічно обирати найбільш компетентного вчителя.*

![Матриця плутанини (Confusion Matrix) для запропонованого методу EMTKD.](figs/figure_ch4_confusion_emtkd.pdf)
*Рисунок 4.8: Матриця плутанини (Confusion Matrix) для запропонованого методу EMTKD на цільовому домені Dataset B.*

![Динаміка зменшення функції втрат під час навчання.](figs/figure_ch4_loss_convergence.pdf)
*Рисунок 4.9: Динаміка зменшення функції втрат під час навчання: запропонований метод (суцільна лінія) демонструє швидшу збіжність та нижче фінальне значення втрат порівняно з DANN.*

![Діаграма результатів абляційного дослідження.](figs/figure_ch4_ablation_chart.pdf)
*Рисунок 4.10: Діаграма результатів абляційного дослідження: внесок кожного компонента (адаптивне зважування, SSL, доменна адаптація) у загальну точність моделі.*

## 4.3. Експериментальна валідація методу покращення медичного NLI

Наступним етапом досліджень стала оцінка гібридної моделі для задачі висновування природною мовою (NLI) у медичній сфері.

### 4.3.1. Експериментальна установка та набори даних

Основним інструментом валідації став набір даних MedNLI [115]. Для порівняння використовувалися такі базові моделі:
1.  BioELMo (Baseline).
2.  ESIM-know (лише знання UMLS).
3.  BioELMo + Sentiment (лише тональність).
4.  Запропонована гібридна модель.

### 4.3.2. Результати та аналіз помилок

Результати тестування на наборі MedNLI представлені у Таблиці 4.5.

**Таблиця 4.5.** Порівняльна характеристика результативності моделей на тестовому наборі MedNLI. Метрики: Точність (Accuracy) та F1-міра.

| Модель | Точність (%) | Влучність (%) | Повнота (%) | F1-міра (%) |
| :--- | :---: | :---: | :---: | :---: |
| BioELMo (Baseline) | 79.73 $\pm$ 0.45 | 78.55 $\pm$ 0.50 | 78.15 $\pm$ 0.48 | 78.23 $\pm$ 0.46 |
| ESIM-know (UMLS only) | 80.22 $\pm$ 0.40 | 79.05 $\pm$ 0.42 | 78.67 $\pm$ 0.45 | 78.76 $\pm$ 0.41 |
| BioELMo + Sentiment | 80.60 $\pm$ 0.38 | 79.48 $\pm$ 0.35 | 79.30 $\pm$ 0.39 | 79.19 $\pm$ 0.37 |
| Запропонована Гібридна Модель | **81.14 $\pm$ 0.31** | **80.08 $\pm$ 0.35** | **79.62 $\pm$ 0.40** | **79.85 $\pm$ 0.33** |

![ROC-криві для моделі NLI на наборі даних MedNLI.](figs/figure_ch4_nli_roc.pdf)
*Рисунок 4.11: ROC-криві для моделі NLI на наборі даних MedNLI. Високі значення AUC для всіх класів (зокрема Contradiction) підтверджують ефективність інтеграції вектора тональності.*

![Матриця плутанини для NLI моделі.](figs/figure_ch4_nli_confusion.pdf)
*Рисунок 4.12: Матриця плутанини для NLI моделі: демонстрація високої точності розпізнавання класів Entailment та Contradiction.*

Аналіз результатів свідчить про те, що запропонований гібридний підхід демонструє найкращу продуктивність. Для класу "Contradiction" (Суперечність) повнота зросла з 82% до 85%, що пояснюється інтеграцією вектора тональності, який дозволяє моделі чітко розрізняти ствердження та заперечення.

## 4.4. Експериментальна валідація методу SKIF-Seg з топологічними обмеженнями

Третім етапом стала валідація методу сегментації SKIF-Seg, призначеного для аналізу МРТ серця.

### 4.4.1. Результати та аналіз анатомічної коректності

Кількісні результати оцінки на тестовій вибірці наведено у Таблиці 4.6.

**Таблиця 4.6.** Результати сегментації структур серця на наборі ACDC.

| Модель | ЛШ (DSC) | ЛШ (HD95) | Міо (DSC) | Міо (HD95) | ПШ (DSC) | ПШ (HD95) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| U-Net (Baseline) | 93.0 $\pm$ 1.6 | 8.0 $\pm$ 2.2 | 85.5 $\pm$ 2.5 | 9.8 $\pm$ 3.1 | 90.0 $\pm$ 2.1 | 8.5 $\pm$ 2.5 |
| U-Net + EGA | 94.2 $\pm$ 1.4 | 6.8 $\pm$ 2.0 | 87.0 $\pm$ 2.2 | 8.2 $\pm$ 2.7 | 91.5 $\pm$ 1.9 | 7.2 $\pm$ 2.3 |
| U-Net + TAAC | 94.5 $\pm$ 1.5 | 6.5 $\pm$ 1.9 | 87.8 $\pm$ 2.4 | 7.5 $\pm$ 2.5 | 92.0 $\pm$ 2.0 | 6.8 $\pm$ 2.1 |
| SKIF-Seg | **95.5 $\pm$ 1.2** | **5.5 $\pm$ 1.8** | **89.0 $\pm$ 2.0** | **6.5 $\pm$ 2.3** | **93.0 $\pm$ 1.7** | **6.0 $\pm$ 2.0** |

![Інтерфейс модуля класифікації KI-GCN у розробленій системі.](figs/figure_ch4_ui_classification.pdf)
*Рисунок 4.13: Інтерфейс модуля класифікації KI-GCN у розробленій системі, що відображає побудований граф пацієнта та ймовірності діагнозів.*

**Таблиця 4.7.** Порівняння з сучасними методами на ACDC (Середній Dice) [148].

| Метод | ЛШ | Міокард | ПШ | Середній Dice |
| :--- | :---: | :---: | :---: | :---: |
| U-Net [150] | 0.951 | 0.895 | 0.930 | 0.925 |
| nnU-Net [153] | **0.968** | 0.909 | **0.945** | **0.941** |
| MedNeXt [154] | 0.966 | 0.910 | 0.942 | 0.939 |
| Запропонований SKIF-Seg | 0.965 | **0.912** | 0.941 | 0.939 |

![Розподіл коефіцієнтів Дайса для методу SKIF-Seg.](figs/figure_ch4_dice_boxplot.pdf)
*Рисунок 4.14: Розподіл коефіцієнтів Дайса для методу SKIF-Seg на наборах ACDC та M&Ms-2. Високі медіанні значення та малий міжквартильний розмах свідчать про стабільність методу.*

![Візуальне порівняння сегментації: U-Net vs SKIF-Seg.](figs/figure_ch4_seg_visual_skifseg.pdf)
*Рисунок 4.15: Візуальне порівняння сегментації: Базова U-Net з розривом міокарда проти SKIF-Seg з відновленою топологією.*

**Таблиця 4.8.** Абляційне дослідження на ACDC: оцінка приросту продуктивності [148].

| Структура | Приріст DSC (pp) від TAAC | Зменшення HD95 (мм) від TAAC | Приріст DSC (pp) від EGA | Зменшення HD95 (мм) від EGA |
| :--- | :---: | :---: | :---: | :---: |
| ЛШ | 1.0 | 1.3 | 0.4 | 0.5 |
| Міо | 2.1 | 2.5 | 0.7 | 0.8 |
| ПШ | 2.0 | 1.6 | 0.8 | 0.9 |

**Таблиця 4.9.** Метрики топологічної правдоподібності [148].

| Набір даних | Модель | TER (%) $\downarrow$ | RingBreak (\%) $\downarrow$ | LV-RV-Overlap (\%) $\downarrow$ | ClosedRing (\%) $\uparrow$ |
| :--- | :--- | :---: | :---: | :---: | :---: |
| ACDC | Baseline U-Net | 9.1 | 10.5 | 2.6 | 89.4 |
| | SKIF-Seg (Our) | **3.4** | **4.1** | **0.6** | **96.8** |
| M&Ms-2 | Baseline U-Net | 12.7 | 14.9 | 3.7 | 86.2 |
| | SKIF-Seg (Our) | **5.1** | **6.0** | **0.9** | **95.1** |

![Кількісна оцінка топологічної коректності.](figs/figure_ch4_topological_metrics.pdf)
*Рисунок 4.16: Кількісна оцінка топологічної коректності: порівняння відсотка топологічно валідних масок (Closed Rings) та частоти помилок (Ring Breaks).*

**Таблиця 4.10.** Деградація продуктивності SKIF-Seg при зміні домену [148].

| Структура | $\Delta$DSC (pp) $\downarrow$ | $\Delta$HD95 (мм) $\downarrow$ |
| :--- | :---: | :---: |
| ЛШ | 1.5 | 1.3 |
| Міо | 1.8 | 1.4 |
| ПШ | 1.6 | 1.8 |

![Матриця плутанини для модуля діагностичної класифікації KI-GCN.](figs/figure_ch4_kigcn_confusion.pdf)
*Рисунок 4.17: Матриця плутанини для модуля діагностичної класифікації KI-GCN. Висока точність класифікації підтверджує якість вхідних сегментаційних масок.*

**Таблиця 4.11.** Метрики калібрування до та після температурного масштабування [148].

| Налаштування | Brier $\downarrow$ | ECE $\downarrow$ |
| :--- | :---: | :---: |
| Pre (без масштабування) | 0.08 | 0.04 |
| Post (temp. scaling, $\tau=2.1$) | **0.07** | **0.03** |

![Діаграма надійності (Reliability Diagram) для KI-GCN.](figs/figure_ch4_reliability_diagram.pdf)
*Рисунок 4.18: Діаграма надійності (Reliability Diagram) для KI-GCN. Близькість кривої до діагоналі свідчить про хороше калібрування ймовірностей.*

![Модуль експорту та звітування системи IDK Medical AI.](figs/figure_ch4_ui_export.pdf)
*Рисунок 4.19: Модуль експорту та звітування системи IDK Medical AI, що дозволяє зберігати результати, маніфести експериментів та візуалізації.*

## 4.5. Аналіз обчислювальної результативності та оптимізація інференсу

Крім оцінки точності, важливим аспектом валідації є аналіз обчислювальної складності.

![Порівняння часу інференсу (мс/об'єм).](figs/figure_ch4_inference_time.pdf)
*Рисунок 4.20: Порівняння часу інференсу (мс/об'єм) для різних апаратних конфігурацій (CPU, CUDA, DirectML) та моделей. Запропонована SKIF-Seg має незначний оверхед порівняно з базовою U-Net.*

Було проведено порівняння часу інференсу на CPU та GPU. Запропонована модель SKIF-Seg, незважаючи на складнішу структуру під час навчання, під час інференсу має лише незначне збільшення обчислювальних витрат (+5% до часу U-Net), що робить її придатною для клінічного впровадження.

## 4.6. Висновки до розділу

Експериментальні дослідження, проведені у цьому розділі, надали вичерпні емпіричні докази результативності розроблених методів інтеграції знань у системи штучного інтелекту медичних діагностичних комплексів.

По-перше, валідація методу багато-вчителевої дистиляції довела його здатність вирішувати проблему доменного зсуву. По-друге, експерименти з гібридною моделлю NLI підтвердили, що інтеграція онтологічних знань UMLS та аналізу тональності дозволяє досягти нового рівня розуміння семантики медичних текстів. По-третє, оцінка методу SKIF-Seg показала, що введення топологічно-обізнаних анатомічних обмежень дозволяє отримувати сегментації, які є анатомічно правдоподібними. Узагальнюючи, результати експериментів переконливо свідчать на користь парадигми навчання, інформованого знаннями.

---

# References

[1] B. J. Erickson et al., "Machine learning for medical imaging," *RadioGraphics*, vol. 37, no. 2, pp. 505–515, 2017.

[2] G. Litjens et al., "A survey on deep learning in medical image analysis," *Medical Image Analysis*, vol. 42, pp. 60–88, 2017.

[3] Z. Zhang et al., "Deep learning in medical image analysis," *Annual Review of Biomedical Engineering*, vol. 21, 2019.

[4] T. Debelee et al., "Survey of deep learning in medical image analysis," *arXiv preprint*, 2019.

[5] B. Huynh et al., "Digital mammographic tumor classification," *Journal of Medical Imaging*, 2016.

[6] N. Wu et al., "Deep learning for breast cancer screening," *IEEE Trans. Med. Imaging*, 2019.

[7] W. Zhu et al., "DeepMulti-path: Deep learning for pulmonary nodule detection," *IEEE Trans. Med. Imaging*, 2018.

[8] F. Ciompi et al., "Automatic classification of pulmonary nodules," *Medical Image Analysis*, 2015.

[9] L. Li et al., "Attention based glaucoma detection," *IEEE CVPR*, 2019.

[10] A. Esteva et al., "Dermatologist-level classification of skin cancer with deep neural networks," *Nature*, vol. 542, 2017.

[11] T. Majtner et al., "Combining deep learning and hand-crafted features for skin lesion classification," *IEEE ISBI*, 2016.

[12] Y. Xie et al., "External knowledge integration in medical AI," *IEEE Trans. Med. Imaging*, 2021.

[13] K. Yu et al., "Medical Knowledge Graph," *arXiv preprint*, 2020.

[14] Q. Guan et al., "Diagnose like a radiologist," *IEEE Trans. Pattern Anal. Mach. Intell.*, 2018.

[15] X. Wang et al., "Knowledge-guided deep learning," *Medical Physics*, 2020.

[16] A. Chaban, "Integrating Diagnostic Models: A Revolutionary Approach in AI-Driven Healthcare," *Proc. Int. Conf. on Medical AI*, 2024.

[17] A. Halevy et al., "The unreasonable effectiveness of data," *IEEE Intelligent Systems*, 2009.

[18] Y. Fang et al., "Few-shot learning in medical imaging," *IEEE Trans. Med. Imaging*, 2024.

[19] X. Wang et al., "ChestX-ray8: Hospital-scale chest X-ray database," *IEEE CVPR*, 2017.

[20] J. Irvin et al., "CheXpert: A large chest radiograph dataset," *AAAI*, 2019.

[21] A. Bustos et al., "PadChest: A large chest x-ray image dataset," *Medical Image Analysis*, 2020.

[22] K. Yan et al., "DeepLesion: automated mining of large-scale lesion annotations," *IEEE CVPR*, 2018.

[23] A. Johnson et al., "MIMIC-CXR: A large publicly available database of chest radiographs," *arXiv preprint*, 2019.

[24] S. Wang et al., "CMRxMotion challenge," *MICCAI*, 2022.

[25] C. Wang et al., "CMRxRecon challenge," *MICCAI*, 2024.

[26] O. Bernard et al., "Deep learning techniques for automatic MRI cardiac multi-structures segmentation," *IEEE Trans. Med. Imaging*, 2018.

[27] A. Di Martino et al., "The autism brain imaging data exchange," *Molecular Psychiatry*, 2014.

[28] M. Weiner et al., "The Alzheimer's disease neuroimaging initiative," *Alzheimer's & Dementia*, 2017.

[29] S. Lee et al., "LDCT-IQ: Low dose CT image quality assessment," *Medical Physics*, 2023.

[30] S. Bakas et al., "Identifying the best machine learning algorithms for brain tumor segmentation," *arXiv preprint*, 2018.

[31] H. Elbatel et al., "Long-tailed distribution in medical imaging," *IEEE Access*, 2023.

[32] Y. Zhang et al., "Deep learning for imbalanced medical data," *Computer Methods and Programs in Biomedicine*, 2023.

[33] H. Chen et al., "Deep learning for healthcare," *IEEE Access*, 2016.

[34] D. Karimi et al., "Reducing the Hausdorff distance in medical image segmentation," *IEEE Trans. Med. Imaging*, 2019.

[35] D. Kingma and J. Ba, "Adam: A method for stochastic optimization," *ICLR*, 2015.

[36] Z. Zhang et al., "GANs for medical image augmentation," *IEEE Access*, 2018.

[37] Y. Ganin et al., "Domain-adversarial training of neural networks," *JMLR*, 2016.

[38] J. Yosinski et al., "How transferable are features in deep neural networks?," *NeurIPS*, 2014.

[39] Y. Song et al., "Transfer learning in medical imaging," *Journal of Healthcare Engineering*, 2024.

[40] Z. Liang et al., "Prostate cancer classification using transfer learning," *Medical Physics*, 2020.

[41] R. Bakalo et al., "Pathology detection in ultrasound," *IEEE Trans. Ultrasonics*, 2019.

[42] J. Gou et al., "Knowledge distillation: A survey," *Int. J. Comput. Vis.*, 2021.

[43] G. Maicas et al., "Training deep neural networks with curriculum learning," *IEEE Trans. Med. Imaging*, 2018.

[44] Y. Tang et al., "Curriculum learning for medical image analysis," *MICCAI*, 2018.

[45] X. Liu et al., "Anatomical knowledge integration," *IEEE Trans. Med. Imaging*, 2018.

[46] X. Chen et al., "Shape prior integration," *MICCAI*, 2019.

[47] X. Luo et al., "Incorporating shape priors into deep learning," *IEEE Trans. Med. Imaging*, 2020.

[48] Y. Xie et al., "Fusing deep learning and handcrafted features," *IEEE Trans. Biomed. Eng.*, 2018.

[49] M. Buty et al., "Shape features for medical image analysis," *IEEE ISBI*, 2016.

[50] M. Alilou et al., "Texture features for cancer classification," *Scientific Reports*, 2017.

[51] Y. Guo et al., "Attention mechanisms in computer vision," *IEEE Access*, 2020.

[52] G. Brauwers et al., "A general survey on attention mechanisms in deep learning," *IEEE Trans. Knowl. Data Eng.*, 2021.

[53] M. Huisman et al., "A survey of deep meta-learning," *Artificial Intelligence Review*, 2021.

[54] A. Krizhevsky et al., "ImageNet classification with deep convolutional neural networks," *NeurIPS*, 2012.

[55] K. Simonyan and A. Zisserman, "Very deep convolutional networks for large-scale image recognition," *ICLR*, 2014.

[56] K. He et al., "Deep residual learning for image recognition," *CVPR*, 2016.

[57] G. Huang et al., "Densely connected convolutional networks," *CVPR*, 2017.

[58] D. Kim et al., "Deep learning in corneal ulcer diagnosis," *Ophthalmology*, 2019.

[59] P. Li et al., "Pulmonary nodule detection," *IEEE Trans. Med. Imaging*, 2019.

[60] M. Alom et al., "Recurrent residual U-Net for medical image segmentation," *Journal of Medical Imaging*, 2018.

[61] M. Havaei et al., "Brain tumor segmentation with deep neural networks," *Medical Image Analysis*, 2017.

[62] P. Yap et al., "Deep learning for brain segmentation," *IEEE Trans. Biomed. Eng.*, 2018.

[63] M. Ghafoorian et al., "Deep multi-scale architectures for white matter hyperintensity segmentation," *NeuroImage*, 2017.

[64] J. Hagerty et al., "Neonatal brain segmentation," *IEEE Trans. Med. Imaging*, 2019.

[65] S. Zheng et al., "Conditional random fields as recurrent neural networks," *ICCV*, 2015.

[66] M. Moradi et al., "Semantic labeling of cardiac CT," *IEEE Trans. Med. Imaging*, 2016.

[67] Q. Li et al., "Transfer learning for medical image classification," *IEEE Access*, 2017.

[68] H. Cao et al., "Deep learning for medical imaging," *IEEE Access*, 2018.

[69] G. Li et al., "Knowledge distillation for medical imaging," *IEEE Trans. Med. Imaging*, 2020.

[70] S. Nabavi et al., "Meta-knowledge distillation," *IEEE CVPR*, 2024.

[71] S. Nabavi et al., "Domain adaptation via distillation," *IEEE Trans. Med. Imaging*, 2021.

[72] Y. Li et al., "Shape and intensity distillation," *MICCAI*, 2023.

[73] S. Zhai et al., "Point supervision for segmentation," *CVPR*, 2023.

[74] Z. Fan et al., "Transformer feature recombination," *IEEE Trans. Med. Imaging*, 2023.

[75] Z. Wang et al., "Black-box domain adaptation," *ICLR*, 2023.

[76] C. Termritthikun et al., "Explainable knowledge distillation," *IEEE Access*, 2023.

[77] V. Murthy et al., "Multi-task learning for glioma classification," *MICCAI*, 2017.

[78] N. Wu et al., "Multi-task learning for breast cancer," *IEEE Trans. Med. Imaging*, 2018.

[79] M. Liao et al., "Alzheimer's disease diagnosis with multi-task learning," *Medical Image Analysis*, 2019.

[80] L. Jin et al., "Fracture detection with curriculum learning," *IEEE Trans. Med. Imaging*, 2020.

[81] R. Zhao et al., "Glaucoma detection," *IEEE ISBI*, 2020.

[82] A. Jesson et al., "Adaptive sampling," *MICCAI*, 2017.

[83] F. Liu et al., "ACPL: Anti-curriculum pseudo-labelling," *CVPR*, 2022.

[84] Z. Yang et al., "MommiNet: Mammographic analysis," *MICCAI*, 2020.

[85] Y. Liu et al., "Symmetry in medical imaging," *IEEE Trans. Med. Imaging*, 2020.

[86] J. Liu et al., "Siamese networks for medical analysis," *IEEE Access*, 2019.

[87] X. Zhang et al., "Melanoma screening," *IEEE Trans. Med. Imaging*, 2020.

[88] Y. Xie et al., "Multi-view nodule analysis," *Pattern Recognition*, 2019.

[89] S. Wang et al., "Dual-path networks," *IEEE Trans. Med. Imaging*, 2020.

[90] Y. Bar et al., "Deep learning for chest pathology," *IEEE ISBI*, 2015.

[91] I. Oksuz et al., "Integrated attention for cardiac MRI," *Medical Image Analysis*, 2023.

[92] Z. Cui et al., "Fistula prediction with attention," *MICCAI*, 2020.

[93] L. Fang et al., "OCT segmentation with hard attention," *IEEE Trans. Med. Imaging*, 2019.

[94] X. Xu et al., "Incorporating vessel attention for cataract," *IEEE Access*, 2024.

[95] E. Mendelson et al., "BI-RADS atlas," *ACR*, 2013.

[96] W. Cai et al., "Deep learning and handcrafted features," *IEEE Trans. Med. Imaging*, 2019.

[97] Z. Feng et al., "Breast cancer classification," *IEEE Access*, 2020.

[98] N. Antropova et al., "Feature fusion for breast cancer," *Medical Physics*, 2017.

[99] W. Xia et al., "Radiomics for tumor invasiveness," *IEEE Trans. Biomed. Eng.*, 2020.

[100] Y. Xie et al., "Edge-aware deep learning," *IEEE Trans. Med. Imaging*, 2021.

[101] S. Hussein et al., "Tumor grade prediction," *IEEE ISBI*, 2017.

[102] Z. Zhang et al., "MDNet: Interpretability in medical diagnosis," *CVPR*, 2017.

[103] A. Larrazabal et al., "Anatomical priors for segmentation," *IEEE Trans. Med. Imaging*, 2019.

[104] T. Schlegl et al., "Local binary patterns in deep learning," *IPMI*, 2017.

[105] J. Devlin et al., "BERT: Pre-training of deep bidirectional transformers," *NAACL*, 2018.

[106] J. Lee et al., "BioBERT: a pre-trained biomedical language representation model," *Bioinformatics*, 2019.

[107] X. Wang et al., "TieNet: Text-image embedding network," *CVPR*, 2018.

[108] B. Jing et al., "On the automatic generation of medical imaging reports," *ACL*, 2017.

[109] G. Liu et al., "Clinical report generation," *AAAI*, 2019.

[110] K. Zeghdaoui et al., "Medical text classification," *IEEE Access*, 2021.

[111] L. Hong et al., "Medical text mining," *JAMIA*, 2013.

[112] P. Chen et al., "Multi-source medical text analysis," *IEEE Access*, 2019.

[113] A. Chaban, "Enhancing medical NLI with integrated domain knowledge and sentiment analysis," *IEEE Trans. Knowl. Data Eng.*, 2024.

[114] A. Gajbhiye et al., "ExBERT: Extending BERT with knowledge," *NAACL*, 2021.

[115] C. Herlihy et al., "MedNLI artifacts," *ACL*, 2021.

[116] Q. Chen et al., "Enhanced LSTM for natural language inference," *ACL*, 2017.

[117] Q. Jin et al., "Probing biomedical embeddings," *BioNLP*, 2019.

[118] T. Khatib et al., "Patient-centric knowledge graphs," *Journal of Biomedical Informatics*, 2024.

[119] P. Veličković et al., "Graph attention networks," *ICLR*, 2018.

[120] Y. Zhang et al., "Knowledge graph for medical diagnosis," *IEEE Access*, 2020.

[121] J. Gao et al., "Leveraging knowledge graphs," *IEEE Trans. Med. Imaging*, 2025.

[122] X. Huang et al., "Knowledge graph embedding," *AAAI*, 2018.

[123] R. Ying et al., "Hierarchical graph representation learning," *NeurIPS*, 2018.

[124] M. Zhang et al., "End-to-end deep graph convolutional networks," *AAAI*, 2018.

[125] Z. Ying et al., "GNNExplainer: Generating explanations for graph neural networks," *NeurIPS*, 2019.

[126] Y. Zhang et al., "Semi-supervised graph learning," *IEEE Trans. Med. Imaging*, 2022.

[127] C. Xiao et al., "Prior knowledge in graph classification," *IEEE Access*, 2020.

[128] G. Yang et al., "DAGAN: Deep de-aliasing generative adversarial networks," *IEEE Trans. Med. Imaging*, 2017.

[129] S. Dar et al., "Image synthesis in multi-contrast MRI," *IEEE Trans. Med. Imaging*, 2018.

[130] A. Chartsias et al., "Adversarial image synthesis," *MICCAI*, 2017.

[131] S. You et al., "Diffusion models for medical imaging," *CVPR*, 2023.

[132] H. Yedder et al., "Deep learning for optical tomography," *IEEE Trans. Med. Imaging*, 2019.

[133] I. Ahmad et al., "Content-based image retrieval," *IEEE Access*, 2017.

[134] Y. Anavi et al., "Binary texture descriptors," *IEEE Trans. Med. Imaging*, 2015.

[135] Y. Anavi et al., "Metadata integration in CBIR," *IEEE ISBI*, 2016.

[136] A. Khatami et al., "Deep feature retrieval," *IEEE Access*, 2018.

[137] C. Li et al., "Knowledge-driven report generation," *AAAI*, 2019.

[138] Y. Li et al., "Reinforcement learning for report generation," *MICCAI*, 2018.

[139] Z. Li et al., "MVP-Net: Multi-view FPN for nodule detection," *MICCAI*, 2019.

[140] A. Aronson et al., "Overview of the MetaMap transfer," *AMIA*, 2010.

[141] K. Johnson et al., "Classical Language Toolkit," *CLTK*, 2021.

[142] L. Amos et al., "UMLS knowledge sources," *NLM*, 2020.

[143] G. Wimmer et al., "Celiac disease diagnosis," *IEEE Trans. Med. Imaging*, 2016.

[144] H. Yang et al., "Thyroid nodule classification," *IEEE Trans. Med. Imaging*, 2019.

[145] H. Chao et al., "Retinal image analysis," *IEEE Trans. Med. Imaging*, 2020.

[146] A. Chaban, "Approach to Medical AI," *Ukrainian Journal of Telemedicine*, 2024.

[147] A. Chaban, "EMTKD at the edge: An adaptive multi-teacher knowledge distillation for robust cardiac MRI classification," *IEEE Access*, 2025.

[148] A. Chaban, "Intelligent Information System for Knowledge Integration into Artificial Intelligence Models," *Cybernetics and Systems Analysis*, 2025.

[149] M. Peters et al., "Deep contextualized word representations," *NAACL*, 2018.

[150] O. Ronneberger et al., "U-Net: Convolutional networks for biomedical image segmentation," *MICCAI*, 2015.

[151] O. Oktay et al., "Attention U-Net: Learning where to look for the pancreas," *MIDL*, 2018.

[152] A. Chaban, "METHOD OF DOMAIN KNOWLEDGE INTEGRATION VIA GRAPH NEURAL NETWORKS," *Herald of KhPI*, 2025.

[153] F. Isensee et al., "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation," *Nature Methods*, 2021.

[154] S. Roy et al., "MedNeXt: Transformer-driven scaling of ConvNets for medical image segmentation," *MICCAI*, 2023.