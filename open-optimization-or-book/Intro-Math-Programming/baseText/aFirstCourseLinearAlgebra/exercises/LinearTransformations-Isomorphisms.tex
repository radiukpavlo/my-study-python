\Opensolutionfile{solutions}[ex]
\section*{Exercises}

\begin{enumialphparenastyle}

\begin{ex} Let $V$ and $W$ be subspaces of $\mathbb{R}^{n}$ and $\mathbb{R}^{m}$
respectively and let $T:V\rightarrow W$ be a linear transformation. Suppose
that $\left\{ T\vect{v}_{1},\cdots ,T\vect{v}_{r}\right\} $ is linearly
independent. Show that it must be the case that $\left\{ \vect{v}_{1},\cdots ,
\vect{v}_{r}\right\} $ is also linearly independent.
\begin{sol}
If $\sum_i^r a_i \vect{v}_r =0$, then using linearity properties of $T$ we get 
\[ 0 = T(0) =  T(\sum_i^r a_i \vect{v}_r) = 
\sum_i^r a_i T(\vect{v}_r).\]
Since we assume that  $\left\{ T\vect{v}_{1},\cdots ,T\vect{v}_{r}\right\} $ is linearly
independent, we must have all $a_i=0$, and therefore we conclude that 
 $\left\{ \vect{v}_{1},\cdots ,
\vect{v}_{r}\right\} $ is also linearly independent.
\end{sol}
\end{ex}


\begin{ex} Let 
\begin{equation*}
V=\mbox{span}\left\{ \leftB 
\begin{array}{c}
1 \\ 
1 \\ 
2 \\ 
0
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
1 \\ 
1 \\ 
0 \\ 
1
\end{array}
\rightB \right\}
\end{equation*}
Let $T\vect{x}=A\vect{x}$ where $A$ is the matrix 
\begin{equation*}
\leftB 
\begin{array}{cccc}
1 & 1 & 1 & 1 \\ 
0 & 1 & 1 & 0 \\ 
0 & 1 & 2 & 1 \\ 
1 & 1 & 1 & 2
\end{array}
\rightB
\end{equation*}
Give a basis for $\func{im}\left( T\right) $.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Let 
\begin{equation*}
V=\mbox{span}\left\{ \leftB 
\begin{array}{c}
1 \\ 
0 \\ 
0 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
1 \\ 
1 \\ 
1 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
1 \\ 
4 \\ 
4 \\ 
1
\end{array}
\rightB \right\}
\end{equation*}
Let $T\vect{x}=A\vect{x}$ where $A$ is the matrix 
\begin{equation*}
\leftB 
\begin{array}{cccc}
1 & 1 & 1 & 1 \\ 
0 & 1 & 1 & 0 \\ 
0 & 1 & 2 & 1 \\ 
1 & 1 & 1 & 2
\end{array}
\rightB
\end{equation*}
Find a basis for $\func{im}\left( T\right) $. In this case, the original
vectors do not form an independent set.

\begin{sol}
Since the third vector is a linear combinations of the first two, then
the image of the third vector will also be a linear combinations of
the image of the first two.  However the image of the first two
vectors are linearly independent (check!), and hence form a basis of
the image.

Thus a basis for $\func{im}\left( T\right) $ is: 

\begin{equation*}
V=\mbox{span}\left\{ \leftB 
\begin{array}{c}
2 \\ 
0 \\ 
1 \\ 
3
\end{array}
\rightB ,\leftB 
\begin{array}{c}
4 \\ 
2 \\ 
4 \\ 
5
\end{array}
\rightB  \right\}
\end{equation*}

\end{sol}
\end{ex}


\begin{ex} If $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{r}\right\} $ is linearly
independent and $T$ is a one to one linear transformation, show that $
\left\{ T\vect{v}_{1},\cdots ,T\vect{v}_{r}\right\} $ is also linearly
independent. Give an example which shows that if $T$ is only linear, it can
happen that, although $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{r}\right\} $ is
linearly independent, $\left\{ T\vect{v}_{1},\cdots ,T\vect{v}_{r}\right\} $
is not. In fact, show that it can happen that each of the $T\vect{v}_{j}$
equals 0.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Let $V$ and $W$ be subspaces of $\mathbb{R}^{n}$ and $\mathbb{R}^{m}$
respectively and let $T:V\rightarrow W$ be a linear transformation. Show
that if $T$ is onto $W$ and if $\left\{ \vect{v}_{1},\cdots ,\vect{v}
_{r}\right\} $ is a basis for $V,$ then $\func{span}\left\{ T\vect{v}
_{1},\cdots ,T\vect{v}_{r}\right\} =W$.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Define $T:\mathbb{R}^{4}\rightarrow \mathbb{R}^{3}$ as follows. 
\begin{equation*}
T\vect{x}=\leftB 
\begin{array}{rrrr}
3 & 2 & 1 & 8 \\ 
2 & 2 & -2 & 6 \\ 
1 & 1 & -1 & 3
\end{array}
\rightB \vect{x}
\end{equation*}
Find a basis for $\func{im}\left( T\right) $. Also find a basis for $\ker
\left( T\right) .$
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Define $T:\mathbb{R}^{3}\rightarrow \mathbb{R}^{3}$ as follows. 
\begin{equation*}
T\vect{x}=\leftB 
\begin{array}{ccc}
1 & 2 & 0 \\ 
1 & 1 & 1 \\ 
0 & 1 & 1
\end{array}
\rightB \vect{x}
\end{equation*}
where on the right, it is just matrix multiplication of the vector $\vect{x}$
which is meant. Explain why $T$ is an isomorphism of $\mathbb{R}^{3}$ to $
\mathbb{R}^{3}$.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Suppose $T:\mathbb{R}^{3}\rightarrow \mathbb{R}^{3}$ is a linear
transformation given by 
\begin{equation*}
T\vect{x}=A\vect{x}
\end{equation*}
where $A$ is a $3\times 3$ matrix. Show that $T$ is an isomorphism if and
only if $A$ is invertible.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Suppose $T:\mathbb{R}^{n}\rightarrow \mathbb{R}^{m}$ is a linear
transformation given by 
\begin{equation*}
T\vect{x}=A\vect{x}
\end{equation*}
where $A$ is an $m\times n$ matrix. Show that $T$ is never an isomorphism if 
$m\neq n$. In particular, show that if $m>n,$ $T$ cannot be onto and if $
m<n, $ then $T$ cannot be one to one.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Define $T:\mathbb{R}^{2}\rightarrow \mathbb{R}^{3}$ as follows. 
\begin{equation*}
T\vect{x}=\leftB 
\begin{array}{cc}
1 & 0 \\ 
1 & 1 \\ 
0 & 1
\end{array}
\rightB \vect{x}
\end{equation*}
where on the right, it is just matrix multiplication of the vector $\vect{x}$
which is meant. Show that $T$ is one to one. Next let $W=\func{im}\left(
T\right) .$ Show that $T$ is an isomorphism of $\mathbb{R}^{2}$ and $\func{im
}\left( T\right) $.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} In the above problem, find a $2\times 3$ matrix $A$ such that the
restriction of $A$ to $\func{im}\left( T\right) $ gives the same result as $
T^{-1}$ on $\func{im}\left( T\right) $. \textbf{Hint:\ }You might let $A$ be
such that 
\begin{equation*}
A\leftB 
\begin{array}{c}
1 \\ 
1 \\ 
0
\end{array}
\rightB =\leftB 
\begin{array}{c}
1 \\ 
0
\end{array}
\rightB ,\ A\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1
\end{array}
\rightB =\leftB 
\begin{array}{c}
0 \\ 
1
\end{array}
\rightB
\end{equation*}
now find another vector $\vect{v}\in \mathbb{R}^{3}$ such that 
\begin{equation*}
\left\{ \leftB 
\begin{array}{c}
1 \\ 
1 \\ 
0
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1
\end{array}
\rightB ,\vect{v}\right\}
\end{equation*}
is a basis. You could pick 
\begin{equation*}
\vect{v}=\leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB
\end{equation*}
for example. Explain why this one works or one of your choice works. Then
you could define $A\vect{v}$ to equal some vector in $\mathbb{R}^{2}.$
Explain why there will be more than one such matrix $A$ which will deliver
the inverse isomorphism $T^{-1}$ on $\func{im}\left( T\right) $.
%\begin{sol}
%\end{sol}
\end{ex}


\begin{ex} Now let $V$ equal $\func{span}\left\{ \leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1
\end{array}
\rightB \right\} $ and let $T:V\rightarrow W$ be a linear transformation
where 
\begin{equation*}
W=\func{span}\left\{ \leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1 \\ 
0
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1 \\ 
1
\end{array}
\rightB \right\}
\end{equation*}
$\ $\ and 
\begin{equation*}
T\leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1
\end{array}
\rightB =\leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1 \\ 
0
\end{array}
\rightB ,T\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1
\end{array}
\rightB =\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1 \\ 
1
\end{array}
\rightB 
\end{equation*}
Explain why $T$ is an isomorphism. Determine a matrix $A$ which, when
multiplied on the left gives the same result as $T$ on $V$ and a matrix $B$
which delivers $T^{-1}$ on $W$. \textbf{Hint:\ }You need to have 
\begin{equation*}
A\leftB 
\begin{array}{cc}
1 & 0 \\ 
0 & 1 \\ 
1 & 1
\end{array}
\rightB =\leftB 
\begin{array}{cc}
1 & 0 \\ 
0 & 1 \\ 
1 & 1 \\ 
0 & 1
\end{array}
\rightB
\end{equation*}
Now enlarge $\leftB 
\begin{array}{c}
1 \\ 
0 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
1
\end{array}
\rightB $ to obtain a basis for $\mathbb{R}^{3}$. You could add in $\leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB $ for example, and then pick another vector in $\mathbb{R}^{4}$ and
let $A\leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB $ equal this other vector. Then you would have 
\begin{equation*}
A\leftB 
\begin{array}{ccc}
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
1 & 1 & 1
\end{array}
\rightB =\leftB 
\begin{array}{ccc}
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
1 & 1 & 0 \\ 
0 & 1 & 1
\end{array}
\rightB
\end{equation*}
This would involve picking for the new vector in $\mathbb{R}^{4}$ the vector 
$\leftB 
\begin{array}{cccc}
0 & 0 & 0 & 1
\end{array}
\rightB ^{T}.$ Then you could find $A$. You can do something similar to find
a matrix for $T^{-1}$ denoted as $B$.
%\begin{sol}
%\end{sol}
\end{ex}

\end{enumialphparenastyle}