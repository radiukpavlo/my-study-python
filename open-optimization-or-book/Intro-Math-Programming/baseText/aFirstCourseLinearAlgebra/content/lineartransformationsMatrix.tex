\section{The Matrix of a Linear \texorpdfstring{\\}{ } Transformation}

\begin{outcome}
\begin{enumerate}
\item[A.]  Find the matrix of a linear transformation and determine the action on a vector in $\mathbb{R}^n$.   
\end{enumerate}
\end{outcome}

In the above examples, the action of the linear transformations was to multiply by a matrix. 
It turns out that this is always the case for linear transformations.
If $T$ is \textbf{any} linear transformation which maps $\mathbb{R}^{n}$ to 
$\mathbb{R}^{m},$ there is \textbf{always} an $m\times n$ matrix $A$ with the
property that
\begin{equation}
T\left(\vect{x}\right) = A\vect{x} \label{matrixoftransf}
\end{equation}
for all $\vect{x} \in \mathbb{R}^{n}$.

\begin{theorem}{Matrix of a Linear Transformation}{matrixlintransf}
Let $T:\mathbb{R}^{n}\mapsto \mathbb{R}^{m}$ be a linear transformation. Then we can find a matrix $A$ such that $T(\vect{x}) = A\vect{x}$. 
 In this case, we say that $T$ is {\em determined\em} or {\em induced\em}
by the matrix $A$.
\end{theorem}

Here is why. Suppose $T:\mathbb{R}^{n}\mapsto \mathbb{R}^{m}$ is a linear transformation and you want to find
the matrix defined by this linear transformation as described in \ref{matrixoftransf}.
 Note that
\begin{equation*}
\vect{x} =\leftB
\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}
\rightB = x_{1}\leftB
\begin{array}{c}
1 \\
0 \\
\vdots \\
0
\end{array}
\rightB + x_{2}\leftB
\begin{array}{c}
0 \\
1 \\
\vdots \\
0
\end{array}
\rightB +\cdots + x_{n}\leftB
\begin{array}{c}
0 \\
0 \\
\vdots \\
1
\end{array}
\rightB = \sum_{i=1}^{n}x_{i}\vect{e}_{i}
\end{equation*}
where $\vect{e}_{i}$ is the $i^{th}$ column of $I_n$, that is the $n \times
1$ vector which has zeros in every slot but the $i^{th}$ and a 1 in
this slot.

Then since $T$ is linear,
\begin{eqnarray*}
T\left( \vect{x} \right)&=&\sum_{i=1}^{n}x_{i}T\left( \vect{e}_{i}\right) \\
&=&\leftB
\begin{array}{ccc}
| &  & | \\
T\left( \vect{e}_{1}\right) & \cdots & T\left( \vect{e}_{n}\right) \\
| &  & |
\end{array}
\rightB \leftB
\begin{array}{c}
x_{1} \\
\vdots \\
x_{n}
\end{array}
\rightB \\
&=& A\leftB
\begin{array}{c}
x_{1} \\
\vdots \\
x_{n}
\end{array}
\rightB
\end{eqnarray*}
Therefore,  the desired matrix is obtained from constructing the $i^{th}$
column as $T\left( \vect{e}_{i}\right) .$ We state this formally as the
following theorem.

\begin{theorem}{Matrix of a Linear Transformation}{matrixoflineartransformation}
Let $T: \mathbb{R}^{n} \mapsto \mathbb{R}^{m}$ be a linear transformation. Then the matrix $A$ satisfying $T\left(\vect{x}\right)=A\vect{x}$ \index{linear transformation!matrix}is given by
\begin{equation*}
A=
\leftB
\begin{array}{ccc}
| &  & | \\
T\left( \vect{e}_{1}\right) & \cdots & T\left( \vect{e}_{n}\right) \\
| &  & |
\end{array}
\rightB
\end{equation*}
where $\vect{e}_{i}$ is the $i^{th}$ column of $I_n$, and then $T\left( \vect{e}_{i}
\right)$ is the $i^{th}$ column of $A.$
\end{theorem}

The following Corollary is an essential result.

\begin{corollary}{Matrix and Linear Transformation}{matrixlintransfequivalence}
A transformation $T$ is a linear transformation if and only if it is a matrix transformation. 
\end{corollary}

Consider the following example.

\begin{example}{The Matrix of a Linear Transformation}{matrixoflineartransformation}
Suppose $T$ is a linear transformation, $T:\mathbb{R}^{3}\rightarrow \mathbb{
R}^{2}$ where 
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
0 \\
0
\end{array}
\rightB =\leftB
\begin{array}{r}
1 \\
2
\end{array}
\rightB ,\ T\leftB
\begin{array}{r}
0 \\
1 \\
0
\end{array}
\rightB =\leftB
\begin{array}{r}
9 \\
-3
\end{array}
\rightB ,\ T\leftB
\begin{array}{r}
0 \\
0 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
1 \\
1
\end{array}
\rightB
\end{equation*}
Find the matrix $A$ of $T$ such that $T \left( \vect{x} \right)=A\vect{x}$  for all $\vect{x}$.
\end{example}

\begin{solution} By Theorem \ref{thm:matrixoflineartransformation} we construct $A$ as follows:
\begin{equation*}
A = 
\leftB
\begin{array}{ccc}
| &  & | \\
T\left( \vect{e}_{1}\right) & \cdots & T\left( \vect{e}_{n}\right) \\
| &  & |
\end{array}
\rightB
\end{equation*}

In this case, $A$ will be a $2 \times 3$ matrix, so we need to find $T
\left(\vect{e}_1 \right), T \left(\vect{e}_2 \right),$ and $T \left(\vect{e}_3
\right)$. Luckily, we have been given these values so we can fill in
$A$ as needed, using these vectors as the columns of $A$.  Hence,
\begin{equation*}
A=\leftB
\begin{array}{rrr}
1 & 9 & 1 \\
2 & -3 & 1
\end{array}
\rightB
\end{equation*}
\end{solution}

In this example, we were given the resulting vectors of $T \left(\vect{e}_1 \right), 
T \left(\vect{e}_2 \right),$ and $T \left(\vect{e}_3 \right)$. Constructing the matrix $A$ was simple, as we
could simply use these vectors as the columns of $A$. The next example shows how to find $A$ when we are not given the $T \left(\vect{e}_i \right)$ so clearly. 

\begin{example}{The Matrix of Linear Transformation: Inconveniently \\ Defined}{2x2inconvenientmatrixoflintransf}
Suppose $T$ is a linear transformation, $T:\mathbb{R}^{2}\rightarrow \mathbb{R}^{2}$ and
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
1 \\
2
\end{array}
\rightB ,\ T\leftB
\begin{array}{r}
0 \\
-1 
\end{array}
\rightB =\leftB
\begin{array}{r}
3 \\
2
\end{array}
\rightB
\end{equation*}
Find the matrix $A$ of $T$ such that $T \left( \vect{x} \right)=A\vect{x}$  for all $\vect{x}$.
\end{example}

\begin{solution} By Theorem \ref{thm:matrixoflineartransformation} to find this matrix, we need to determine the action of $T$ on
$\vect{e}_{1}$ and $\vect{e}_{2}$. In Example \ref{exa:matrixoflineartransformation}, we were given these resulting vectors.
However, in this example, we have been given $T$ of two different vectors. How can we find out the action
of $T$ on $\vect{e}_{1}$ and $\vect{e}_{2}$? In particular for $\vect{e}_{1}$, suppose there exist $x$ and $y$ such that
\begin{equation}
\leftB
\begin{array}{r}
1 \\
0
\end{array}
\rightB = x\leftB
\begin{array}{r}
1\\
1
\end{array}
\rightB +y\leftB
\begin{array}{r}
0 \\
-1 
\end{array}
\rightB 
\label{matrixvalues}
\end{equation}

Then, since $T$ is linear,
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
0 
\end{array}
\rightB  = x T\leftB
\begin{array}{r}
1 \\
1
\end{array}
\rightB +y T\leftB
\begin{array}{r}
0 \\
-1 
\end{array}
\rightB
\end{equation*}

Substituting in values, this sum becomes
\begin{equation}
T\leftB
\begin{array}{r}
1 \\
0 
\end{array}
\rightB = 
 x\leftB
\begin{array}{r}
1 \\
2
\end{array}
\rightB +y\leftB
\begin{array}{r}
3 \\
2
\end{array}
\rightB 
\label{matrixvalues2}
\end{equation}

Therefore, if we know the values of $x$ and $y$ which satisfy \ref{matrixvalues}, we can substitute these into equation \ref{matrixvalues2}. By doing so,
we find $T\left(\vect{e}_1\right)$ which is the first column of the matrix $A$. 

We proceed to find $x$ and $y$. We do so by solving \ref{matrixvalues}, which can be done by solving the system
\begin{equation*}
\begin{array}{c}
x = 1 \\
x - y = 0
\end{array}
\end{equation*}

We see that $x=1$ and $y=1$ is the solution to this system. 
Substituting these values into equation \ref{matrixvalues2}, we have 
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
0 
\end{array}
\rightB = 
 1 \leftB
\begin{array}{r}
1 \\
2
\end{array}
\rightB + 1 \leftB
\begin{array}{r}
3 \\
2
\end{array}
\rightB 
= 
 \leftB
\begin{array}{r}
1 \\
2
\end{array}
\rightB + \leftB
\begin{array}{r}
3 \\
2
\end{array}
\rightB
=
\leftB
\begin{array}{r}
4 \\
4
\end{array}
\rightB
\end{equation*}

Therefore $\leftB
\begin{array}{r}
4 \\
4
\end{array}
\rightB$
is the first column of $A$. 

Computing the second column is done in the same way, and is left as an exercise.

The resulting matrix $A$ is given by 
\begin{equation*}
A
=
\leftB
\begin{array}{rr}
4 & -3 \\
4 & -2
\end{array}
\rightB
\end{equation*}
\end{solution}

This example illustrates a very long procedure for finding the matrix of $A$. While this method is reliable and
will always result in the correct matrix $A$, the following procedure provides an alternative method. 

\begin{procedure}{Finding the Matrix of Inconveniently Defined Linear Transformation}{findingmatrixoflineartransformation}
Suppose $T:\mathbb{R}^{n}\rightarrow \mathbb{R}^{m}$ is a linear transformation. Suppose there exist vectors $\left\{ \vect{a}_{1},\cdots ,\vect{a}_{n}\right\} $ in $\mathbb
{R}^{n}$ such that $\leftB
\begin{array}{ccc}
\vect{a}_{1} & \cdots & \vect{a}_{n}
\end{array}
\rightB ^{-1}$ exists, and 
\begin{equation*}
T \left(\vect{a}_{i}\right)=\vect{b}_{i}
\end{equation*}
Then the matrix of $T$ must be of the form
\begin{equation*}
\leftB
\begin{array}{ccc}
\vect{b}_{1} & \cdots & \vect{b}_{n}
\end{array}
\rightB \leftB
\begin{array}{ccc}
\vect{a}_{1} & \cdots & \vect{a}_{n}
\end{array}
\rightB ^{-1}
\end{equation*}
\end{procedure}

We will illustrate this procedure in the following example. You may also find it useful
to work through Example \ref{exa:2x2inconvenientmatrixoflintransf} using this procedure.

\begin{example}{Matrix of a Linear Transformation \\ Given Inconveniently}{inconvenientmatrixlintransf}
Suppose $T:\mathbb{R}^{3}\rightarrow \mathbb{R}^{3}$ is a linear
transformation and
\begin{equation*}
T\leftB
\begin{array}{r}
1 \\
3 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
0 \\
1 \\
1
\end{array}
\rightB ,T\leftB
\begin{array}{r}
0 \\
1 \\
1
\end{array}
\rightB =\leftB
\begin{array}{r}
2 \\
1 \\
3
\end{array}
\rightB ,T\leftB
\begin{array}{r}
1 \\
1 \\
0
\end{array}
\rightB =\leftB
\begin{array}{r}
0 \\
0 \\
1
\end{array}
\rightB
\end{equation*}
Find the matrix of this linear transformation.
\end{example}

\begin{solution}
By Procedure \ref{proc:findingmatrixoflineartransformation}, 
$A=  \leftB
\begin{array}{rrr}
1 & 0 & 1 \\
3 & 1 & 1 \\
1 & 1 & 0
\end{array}
\rightB ^{-1}$ and 
 $B=\leftB
\begin{array}{rrr}
0 & 2 & 0 \\
1 & 1 & 0 \\
1 & 3 & 1
\end{array}
\rightB$

Then, Procedure \ref{proc:findingmatrixoflineartransformation} claims that the matrix of $T$ is 
\begin{equation*}
C= BA^{-1} 
=\leftB
\begin{array}{rrr}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{array}
\rightB
\end{equation*}

Indeed you can first verify that $T(\vect{x})=C\vect{x}$ for the 3 vectors above:

\begin{equation*}
 \leftB
\begin{array}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{array}
\rightB \leftB
\begin{array}{c}
1 \\
3 \\
1
\end{array}
\rightB =\leftB
\begin{array}{c}
0 \\
1 \\
1
\end{array}
\rightB ,\ \leftB
\begin{array}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{array}
\rightB \leftB
\begin{array}{c}
0 \\
1 \\
1
\end{array}
\rightB =\leftB
\begin{array}{c}
2 \\
1 \\
3
\end{array}
\rightB
\end{equation*}
\begin{equation*}
\leftB
\begin{array}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{array}
\rightB \leftB
\begin{array}{c}
1 \\
1 \\
0
\end{array}
\rightB =\leftB
\begin{array}{c}
0 \\
0 \\
1
\end{array}
\rightB
\end{equation*}

But more generally $T(\vect{x})= C\vect{x}$ for any $\vect{x}$. To see this, let $\vect{y}=A^{-1}\vect{x}$ and then using linearity of $T$:
\[ T(\vect{x})= T(A\vect{y}) = T \left( \sum_i \vect{y}_i\vect{a}_i \right) = \sum \vect{y}_i T(\vect{a}_i) \sum \vect{y}_i \vect{b}_i = B\vect{y} = BA^{-1}\vect{x} = C\vect{x}\]
\end{solution}

Recall the dot product discussed earlier. Consider the map $\vect{v}$\textbf{$\mapsto $}
$\func{proj}_{\vect{u}}\left( \vect{v}\right) $ which takes a vector a transforms it to its projection onto a given vector $\vect{u}$. It turns out that
this map is linear, a result which follows from the properties of the
dot product. This is shown as follows.
\begin{eqnarray*}
\func{proj}_{\vect{u}}\left( k \vect{v}+ p \vect{w}\right)
&=&\left( \vspace{0.05in}\frac{(k \vect{v}+ p \vect{w})\dotprod \vect{u}}{
\vect{u}\dotprod \vect{u}}\right) \vect{u} \\
&=& k  \left( \vspace{0.05in}\frac{
\vect{v}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}\right) \vect{u}+p \left( \vspace{
0.05in}\frac{\vect{w}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}\right) \vect{u} \\
&=& k \; \func{proj}_{\vect{u}}\left( \vect{v}\right) +p \; \func{proj}
_{\vect{u}}\left( \vect{w}\right) 
\end{eqnarray*}

Consider the following example.

\begin{example}{Matrix of a Projection Map}{projectionmatrix}
Let $\vect{u} = \leftB \begin{array}{r}
1 \\
2 \\
3
\end{array}
\rightB$ and let $T$ be the projection map $T: \mathbb{R}^3 \mapsto \mathbb{R}^3$ defined by 
\[
T(\vect{v}) = \func{proj}_{\vect{u}}\left( \vect{v}\right)
\]
for any $\vect{v} \in \mathbb{R}^3$.  
\begin{enumerate}
\item Does this transformation come from
multiplication by a matrix?
\item If so, what is the matrix?
\end{enumerate}
\end{example}

\begin{solution}
\begin{enumerate}
\item
First, we have just seen that $T (\vect{v}) = \func{proj}_{\vect{u}}\left( \vect{v}\right)$ is linear. Therefore by Theorem \ref{thm:matrixlintransf}, we can find a matrix $A$ such that $T(\vect{x}) = A\vect{x}$. 

\item
The columns of the matrix for $T$ are defined above as $T(\vect{e}_{i})$. 
It follows that $T(\vect{e}_{i}) = \func{proj}
_{\vect{u}}\left( \vect{e}_{i}\right) $ gives the $i^{th}$ column of the
desired matrix. Therefore, we need to find
\begin{equation*}
\func{proj}_{\vect{u}}\left( \vect{e}_{i}\right) = \left( \vspace{0.05in}
\frac{\vect{e}_{i}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}\right)
\vect{u}
\end{equation*}
For the given vector $\vect{u}$ , this implies the columns of the desired
matrix are
\begin{equation*}
\vspace{0.05in}\frac{1}{14}\leftB
\begin{array}{r}
1 \\
2 \\
3
\end{array}
\rightB ,\vspace{0.05in}\frac{2}{14}\leftB
\begin{array}{r}
1 \\
2 \\
3
\end{array}
\rightB ,\vspace{0.05in}\frac{3}{14}\leftB
\begin{array}{r}
1 \\
2 \\
3
\end{array}
\rightB 
\end{equation*}
which you can verify.
Hence the matrix of $T$ is
\begin{equation*}
\vspace{0.05in}\frac{1}{14}\leftB
\begin{array}{rrr}
1 & 2 & 3 \\
2 & 4 & 6 \\
3 & 6 & 9
\end{array}
\rightB 
\end{equation*}
\end{enumerate}
\end{solution}