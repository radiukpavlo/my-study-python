{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# CNN-KCL: Automatic Myocarditis Diagnosis using Convolutional Neural Network Combined with K-means Clustering\n",
    "**Danial Sharifrazi et al.**\n",
    "* This code is related to the mentioned paper. Please cite the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringFunc(x_data,y_data,k):    \n",
    "    import numpy as np\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    " \n",
    "    print('Start Clustering.............!')\n",
    "    normals=[]\n",
    "    sicks=[]\n",
    "    for i in range(len(y_data)):\n",
    "        if y_data[i]==0:\n",
    "            normals.append(x_data[i])\n",
    "        else:\n",
    "            sicks.append(x_data[i])\n",
    "\n",
    "    normals=np.array(normals)\n",
    "    sicks=np.array(sicks)\n",
    "\n",
    "\n",
    "    model=KMeans(n_clusters=k)   \n",
    "    y_n=model.fit_predict(normals)  \n",
    "    y_s=model.fit_predict(sicks)\n",
    "    \n",
    "\n",
    "    y_s2=[]\n",
    "    for item in y_s:\n",
    "        y_s2.append(item+k)\n",
    "\n",
    "\n",
    "    y_n=list(y_n)\n",
    "    y_n.extend(y_s2)\n",
    "    y=np.array(y_n)\n",
    "\n",
    "\n",
    "    normals=list(normals)\n",
    "    sicks=list(sicks)\n",
    "    normals.extend(sicks)\n",
    "    x=np.array(normals)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetPlot(net_histories,n_epch):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "  \n",
    "    losses=[]\n",
    "    val_losses=[]\n",
    "    accuracies=[]\n",
    "    val_accuracies=[]\n",
    "\n",
    "    for item in net_histories:\n",
    "        \n",
    "        history=item.history\n",
    "        loss=history['loss']\n",
    "        val_loss=history['val_loss']\n",
    "        accuracy=history['acc']\n",
    "        val_accuracy=history['val_acc']\n",
    "        \n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "\n",
    "    losses2=np.zeros((1,n_epch))\n",
    "    val_losses2=np.zeros((1,n_epch))\n",
    "    accuracies2=np.zeros((1,n_epch))\n",
    "    val_accuracies2=np.zeros((1,n_epch))\n",
    "\n",
    "    for i in losses:\n",
    "        losses2+=i\n",
    "\n",
    "    for i in val_losses:\n",
    "        val_losses2+=i\n",
    "    \n",
    "    for i in accuracies:\n",
    "        accuracies2+=i\n",
    "    \n",
    "    for i in val_accuracies:\n",
    "        val_accuracies2+=i\n",
    "\n",
    "\n",
    "    # 10 is number of folds\n",
    "    losses2=(losses2/10).flatten()\n",
    "    accuracies2=(accuracies2/10).flatten()\n",
    "    val_losses2=(val_losses2/10).flatten()\n",
    "    val_accuracies2=(val_accuracies2/10).flatten()\n",
    "\n",
    "    plt.figure('Accracy Diagram',dpi=600)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(accuracies2,color='black')\n",
    "    plt.plot(val_accuracies2,color='green')\n",
    "    plt.legend(['Train Data','Validation Data'])\n",
    "    plt.savefig('Accuracy Diagram.jpg')\n",
    "\n",
    "    plt.figure('Loss Diagram',dpi=600)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(losses2,color='black')\n",
    "    plt.plot(val_losses2,color='green')\n",
    "    plt.legend(['Train Data','Validation Data'])\n",
    "    plt.savefig('Loss Diagram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepCNN(x_data,y_data,k):\n",
    "\n",
    "    import datetime\n",
    "    from sklearn.metrics import ( auc, classification_report,\n",
    "                                confusion_matrix, roc_curve)\n",
    "    from sklearn.model_selection import KFold, train_test_split\n",
    "    from keras.layers import Conv1D,Dense, Dropout, Flatten\n",
    "    from keras.losses import binary_crossentropy\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.utils import np_utils\n",
    "    from keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "\n",
    "    print('Start Deep Learning............!')\n",
    "\n",
    "\n",
    "    lst_loss=[]\n",
    "    lst_acc=[]\n",
    "    lst_reports=[]\n",
    "    lst_AUC=[]\n",
    "    lst_matrix=[]\n",
    "    lst_times=[]\n",
    "    lst_history=[]\n",
    "    fold_number=1\n",
    "    n_epch=30\n",
    "\n",
    "    kfold=KFold(n_splits=10,shuffle=True,random_state=None)\n",
    "    for train,test in kfold.split(x_data,y_data):\n",
    "\n",
    "        x_train=x_data[train]\n",
    "        x_test=x_data[test]\n",
    "        y_train=y_data[train]\n",
    "        y_test=y_data[test]\n",
    "\n",
    "        x_train,y_train=clusteringFunc(x_train,y_train,k)\n",
    "        x_test,y_test=clusteringFunc(x_test,y_test,k)\n",
    "\n",
    "\n",
    "        x_train=x_train.reshape((x_train.shape[0],100,100))\n",
    "        x_test=x_test.reshape((x_test.shape[0],100,100))\n",
    "\n",
    "        x_train,x_valid,y_train,y_valid=train_test_split(x_train,y_train,test_size=0.2,random_state=None)\n",
    "\n",
    "\n",
    "        print(f'train: {x_train.shape}  {y_train.shape}')\n",
    "        print(f'test: {x_test.shape}  {y_test.shape}')\n",
    "        print(f'valid: {x_test.shape}  {y_valid.shape}')\n",
    "\n",
    "\n",
    "        calback=CSVLogger(f'logger_fold{fold_number}.log')\n",
    "\n",
    "        y_train=np_utils.to_categorical(y_train)\n",
    "        y_test=np_utils.to_categorical(y_test)\n",
    "        y_valid=np_utils.to_categorical(y_valid)\n",
    "\n",
    "\n",
    "\n",
    "        # CNN Architecture\n",
    "        model=Sequential()\n",
    "        model.add(Conv1D(32,3,padding='same',activation='relu',strides=2,input_shape=(100,100)))\n",
    "        model.add(Conv1D(64,3,padding='same',activation='relu',strides=2))\n",
    "        model.add(Conv1D(128,3,padding='same',activation='relu',strides=2))\n",
    "        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n",
    "        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n",
    "        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256,activation='relu'))\n",
    "        model.add(Dense(128,activation='relu'))\n",
    "        model.add(Dense(64,activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(k*2,activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "        model.compile(optimizer=Adam(),loss=binary_crossentropy,metrics=['accuracy'])\n",
    "            \n",
    "        start=datetime.datetime.now()\n",
    "        net_history=model.fit(x_train, y_train, batch_size=512, epochs=n_epch,validation_data=(x_valid,y_valid),callbacks=[calback])\n",
    "        end=datetime.datetime.now()\n",
    "        training_time=end-start\n",
    "\n",
    "        model.save(f'CNN_fold{fold_number}.h5')\n",
    "\n",
    "        test_loss, test_acc=model.evaluate(x_test,y_test)\n",
    "\n",
    "        predicts=model.predict(x_test)\n",
    "        predicts=predicts.argmax(axis=1)\n",
    "        actuals=y_test.argmax(axis=1)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(actuals, predicts, pos_label=1)\n",
    "        a=auc(fpr,tpr)\n",
    "        r=classification_report(actuals,predicts)\n",
    "        c=confusion_matrix(actuals,predicts)\n",
    "\n",
    "\n",
    "\n",
    "        lst_history.append(net_history)\n",
    "        lst_times.append(training_time)\n",
    "        lst_acc.append(test_acc)\n",
    "        lst_loss.append(test_loss)\n",
    "        lst_AUC.append(a)\n",
    "        lst_reports.append(r)\n",
    "        lst_matrix.append(c)\n",
    "\n",
    "        fold_number+=1\n",
    "\n",
    "        \n",
    "    # plot loss and accuracy diagrams\n",
    "    NetPlot(lst_history,n_epch)\n",
    "\n",
    "    path=f'CNN_Kmeans_Results.txt' \n",
    "    f1=open(path,'a')\n",
    "    f1.write('\\nAccuracies: '+str(lst_acc)+'\\nLosses: '+str(lst_loss))\n",
    "    f1.write('\\n\\nMetrics for all Folds: \\n\\n')\n",
    "    for i in range(len(lst_reports)):\n",
    "        f1.write(str(lst_reports[i]))\n",
    "        f1.write('\\n\\nTraining Time: '+str(lst_times[i])+'\\nAUC: '+str(lst_AUC[i]))\n",
    "        f1.write('\\n\\nCofusion Matrix: \\n'+str(lst_matrix[i])+'\\n\\n__________________________________________________________\\n')\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actuals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mactuals\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actuals' is not defined"
     ]
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Data():    \n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from skimage.io import imread\n",
    "    import glob\n",
    "    import os\n",
    "\n",
    "\n",
    "    normals=[]\n",
    "    #main_path='/kaggle/input/myocarditis-dataset/Normal/'\n",
    "    main_path='E:/Datasets/dataset_myocarditis/Normal/'\n",
    "    main_folders=next(os.walk(main_path))[1]\n",
    "    for i in main_folders:\n",
    "        path=main_path+i+'/'\n",
    "        folders=next(os.walk(path))[1]\n",
    "        for x in folders:\n",
    "            new_path=path+x+'/'\n",
    "            data=glob.glob(new_path+'*.jpg')\n",
    "            if len(data)<1:\n",
    "                indent_folders=next(os.walk(new_path))[1]\n",
    "                for y in indent_folders:\n",
    "                    new_path=new_path+y+'/'\n",
    "                    data=glob.glob(new_path+'*.jpg')\n",
    "            normals.extend(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #read sicks files\n",
    "    sicks=[]\n",
    "    #main_path='/kaggle/input/myocarditis-dataset/Sick/'\n",
    "    main_path='E:/Datasets/dataset_myocarditis/Sick/'\n",
    "    main_folders=next(os.walk(main_path))[1]\n",
    "    for i in main_folders:\n",
    "        path=main_path+i+'/'\n",
    "        folders=next(os.walk(path))[1]\n",
    "        for x in folders:\n",
    "            new_path=path+x+'/'\n",
    "            data=glob.glob(new_path+'*.jpg')\n",
    "            if len(data)<1:\n",
    "                indent_folders=next(os.walk(new_path))[1]\n",
    "                for y in indent_folders:\n",
    "                    new_path=new_path+y+'/'\n",
    "                    data=glob.glob(new_path+'*.jpg')\n",
    "            sicks.extend(data)\n",
    "    \n",
    "    #load normal files\n",
    "    labels_n=[]\n",
    "    train_data_n=[]\n",
    "    for id in normals:    \n",
    "        img=imread(id)\n",
    "        img=cv2.resize(img,(100,100))\n",
    "        # img=img.astype('float32')\n",
    "        img=img.flatten()\n",
    "        train_data_n.append(img)\n",
    "        labels_n.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    #load sick files\n",
    "    labels_s=[]\n",
    "    train_data_s=[]\n",
    "    for id in sicks:    \n",
    "        img=imread(id)\n",
    "        img=cv2.resize(img,(100,100))\n",
    "        # img=img.astype('float32')\n",
    "        img=img.flatten()\n",
    "        train_data_s.append(img)\n",
    "        labels_s.append(1)\n",
    "\n",
    "    train_data_n.extend(train_data_s)\n",
    "    labels_n.extend(labels_s)\n",
    "\n",
    "    x_data=np.array(train_data_n)\n",
    "    y_data=np.array(labels_n)\n",
    "\n",
    "    \n",
    "    # calling deep learning method\n",
    "    k=2\n",
    "    DeepCNN(x_data,y_data,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Deep Learning............!\n",
      "Start Clustering.............!\n",
      "Start Clustering.............!\n",
      "train: (70907, 100, 100)  (70907,)\n",
      "test: (9849, 100, 100)  (9849,)\n",
      "valid: (9849, 100, 100)  (17727,)\n",
      "Epoch 1/30\n",
      "139/139 [==============================] - 7s 23ms/step - loss: 0.3833 - accuracy: 0.6843 - val_loss: 0.1889 - val_accuracy: 0.8477\n",
      "Epoch 2/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.1709 - accuracy: 0.8688 - val_loss: 0.1322 - val_accuracy: 0.8917\n",
      "Epoch 3/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.1251 - accuracy: 0.9014 - val_loss: 0.1342 - val_accuracy: 0.8909\n",
      "Epoch 4/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0981 - accuracy: 0.9220 - val_loss: 0.1133 - val_accuracy: 0.9123\n",
      "Epoch 5/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0842 - accuracy: 0.9333 - val_loss: 0.1130 - val_accuracy: 0.9119\n",
      "Epoch 6/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0762 - accuracy: 0.9398 - val_loss: 0.1114 - val_accuracy: 0.9186\n",
      "Epoch 7/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0711 - accuracy: 0.9437 - val_loss: 0.1084 - val_accuracy: 0.9259\n",
      "Epoch 8/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0598 - accuracy: 0.9516 - val_loss: 0.1080 - val_accuracy: 0.9288\n",
      "Epoch 9/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0591 - accuracy: 0.9532 - val_loss: 0.1029 - val_accuracy: 0.9262\n",
      "Epoch 10/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0550 - accuracy: 0.9563 - val_loss: 0.1047 - val_accuracy: 0.9233\n",
      "Epoch 11/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0528 - accuracy: 0.9579 - val_loss: 0.1028 - val_accuracy: 0.9303\n",
      "Epoch 12/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0482 - accuracy: 0.9616 - val_loss: 0.1099 - val_accuracy: 0.9320\n",
      "Epoch 13/30\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 0.0470 - accuracy: 0.9627 - val_loss: 0.1000 - val_accuracy: 0.9352\n",
      "Epoch 14/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0457 - accuracy: 0.9643 - val_loss: 0.1168 - val_accuracy: 0.9312\n",
      "Epoch 15/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0447 - accuracy: 0.9646 - val_loss: 0.1083 - val_accuracy: 0.9384\n",
      "Epoch 16/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0431 - accuracy: 0.9660 - val_loss: 0.1148 - val_accuracy: 0.9349\n",
      "Epoch 17/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0422 - accuracy: 0.9665 - val_loss: 0.1350 - val_accuracy: 0.9345\n",
      "Epoch 18/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0429 - accuracy: 0.9670 - val_loss: 0.1311 - val_accuracy: 0.9394\n",
      "Epoch 19/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0382 - accuracy: 0.9700 - val_loss: 0.1179 - val_accuracy: 0.9359\n",
      "Epoch 20/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0389 - accuracy: 0.9698 - val_loss: 0.1069 - val_accuracy: 0.9379\n",
      "Epoch 21/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0352 - accuracy: 0.9727 - val_loss: 0.1065 - val_accuracy: 0.9416\n",
      "Epoch 22/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0319 - accuracy: 0.9748 - val_loss: 0.1213 - val_accuracy: 0.9407\n",
      "Epoch 23/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0351 - accuracy: 0.9725 - val_loss: 0.1175 - val_accuracy: 0.9400\n",
      "Epoch 24/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0383 - accuracy: 0.9705 - val_loss: 0.1177 - val_accuracy: 0.9292\n",
      "Epoch 25/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0364 - accuracy: 0.9726 - val_loss: 0.1130 - val_accuracy: 0.9376\n",
      "Epoch 26/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0334 - accuracy: 0.9741 - val_loss: 0.1186 - val_accuracy: 0.9398\n",
      "Epoch 27/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0301 - accuracy: 0.9765 - val_loss: 0.1024 - val_accuracy: 0.9396\n",
      "Epoch 28/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0303 - accuracy: 0.9766 - val_loss: 0.1217 - val_accuracy: 0.9404\n",
      "Epoch 29/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0321 - accuracy: 0.9754 - val_loss: 0.1153 - val_accuracy: 0.9401\n",
      "Epoch 30/30\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 0.0325 - accuracy: 0.9761 - val_loss: 0.1036 - val_accuracy: 0.9375\n",
      "308/308 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9346\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mRead_Data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mRead_Data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# calling deep learning method\u001b[39;00m\n\u001b[0;32m     79\u001b[0m k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 80\u001b[0m \u001b[43mDeepCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mDeepCNN\u001b[1;34m(x_data, y_data, k)\u001b[0m\n\u001b[0;32m     89\u001b[0m predicts\u001b[38;5;241m=\u001b[39mpredicts\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     90\u001b[0m actuals\u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m fpr,tpr,_\u001b[38;5;241m=\u001b[39m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m a\u001b[38;5;241m=\u001b[39mauc(fpr,tpr)\n\u001b[0;32m     94\u001b[0m r\u001b[38;5;241m=\u001b[39mclassification_report(actuals,predicts)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:962\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[0;32m    874\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    875\u001b[0m ):\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m \n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:731\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    729\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    733\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    734\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "Read_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
