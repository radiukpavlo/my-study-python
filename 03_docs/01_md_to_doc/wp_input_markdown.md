# Розділ 1. Аналіз сучасних методів та підходів до інтеграції знань діагностичних моделей в системи штучного інтелекту медичних діагностичних комплексів

## 1,1 Актуальність застосування діагностичних моделей в системах штучного інтелекту медичних діагностичних комплексів

Сучасний етап розвитку медичної науки та клінічної практики характеризується експоненціальним зростанням обсягів діагностичних даних, що вимагає впровадження новітніх інформаційних технологій для їх обробки, аналізу та інтерпретації. Протягом останніх десятиліть спостерігається фундаментальний прогрес у галузі комп'ютерної детекції та діагностики (Computer-Aided Detection/Diagnosis, CAD), особливо у сферах медичної візуалізації та радіології. Цей технологічний стрибок значною мірою зумовлений розвитком методів глибокого навчання (Deep Learning, DL), які продемонстрували здатність апроксимувати складні нелінійні залежності у багатовимірних просторах ознак [1], [2]. У роботах [3], [4] зазначається, що цей вплив поширюється не лише на стаціонарні системи, але й на мобільні та бездротові мережі передачі медичних даних.

Досягнувши безпрецедентних успіхів у класичних задачах комп'ютерного зору, різноманітні архітектури DL-моделей, переважно глибокі згорткові нейронні мережі (Convolutional Neural Networks, CNN), були успішно адаптовані до специфіки медичних зображень. Спектр застосувань охоплює критично важливі напрямки, включаючи раннє виявлення раку молочної залози на мамограмах, де значний внесок зробили дослідження [5], [6]. Окремої уваги заслуговують методи ідентифікації легеневих вузликів на КТ, представлені у працях [7], [8], а також підходи до діагностики глаукоми за зображеннями очного дна [9] та дерматоскопічний аналіз новоутворень шкіри [10], [11].

![Концептуальна схема інтелектуальної системи CAD](figs/figure_ch1_cad_concept.pdf)
*Рисунок 1. Концептуальна схема інтелектуальної системи CAD: трансформація вхідних сенсорних даних у простір клінічних рішень з урахуванням доменних знань.*

У найбільш загальному вигляді інтелектуальну систему CAD, побудовану на основі методів глибокого навчання, можна формалізувати як параметричну функцію відображення $f_{CAD}$, що трансформує вхідний простір сенсорних даних у простір клінічних рішень (Рисунок 1). Нехай $I \in \mathbb{R}^{H \times W \times C}$ — вхідне медичне зображення (або тензор мультимодальних даних), $\theta \in \mathbb{R}^d$ — вектор параметрів моделі, що навчаються, а $\mathcal{K}_{domain}$ — структуроване представлення апріорних знань предметної області. Тоді процес діагностики описується рівнянням:

$$
D = f_{CAD}(I; \theta, \mathcal{K}_{domain}),
$$

де $D$ позначає вихідний діагностичний результат, який може набувати форми вектора ймовірностей класів (класифікація), маски сегментації (локалізація) або координат обмежувальних рамок (виявлення).

Важливість інтеграції компоненти $\mathcal{K}_{domain}$ для підвищення надійності систем підтверджується у систематичних оглядах [12], [13].

Критичним аспектом, що відрізняє медичні системи ШІ від систем загального призначення, є необхідність інтеграції знань для подолання обмежень «чистих» даних. У класичному глибокому навчанні модель намагається вивести всі необхідні закономірності виключно з навчальної вибірки даних (data-driven approach). Однак, як зауважують автори [14], [15], у медицині існує величезний пласт верифікованих знань — анатомічних, фізіологічних, патологічних та процедурних, — ігнорування яких призводить до створення моделей, що є нестійкими, погано інтерпретованими та схильними до помилок у нестандартних клінічних ситуаціях. Це створює низку системних проблем при впровадженні ШІ в діагностику, які деталізовано в Таблиці 1.

*Таблиця 1. Системні проблеми та бар'єри, що виникають при використанні штучного інтелекту в діагностичних сферах медицини [16].*

| Фактор впровадження ШІ | Проблема |
| :--- | :--- |
| **Приватність та кібербезпека** | Необхідний надійний захист від зовнішнього втручання в технологічну систему діагностичних центрів для збереження всіх даних пацієнтів. Уникнення можливості помилок діагностичних систем ШІ (підробка, зміна даних). |
| **Надійність** | Проблеми з технологією можуть вплинути на кінцевий результат і діагноз. Якісне формулювання процесів і завдань ШІ, своєчасний аналіз та контроль рівня результатів безпосередньо впливають на правильне виконання завдань. |
| **Технологія та відповідальність** | Постійно виникають питання про технічні, етичні та управлінські компоненти технологій на базі ШІ. Хто нестиме відповідальність за діагностичні помилки? |
| **Автономія та система підтримки** | Громадськість має доступ до сучасних додатків, що використовуються в медицині. Коли виникає потреба, людина може змінити результати, що вплине на кінцевий продукт. |
| **Етнічні групи населення** | Не всі країни та не всі медичні діагностичні заклади здатні мати відповідну матеріально-технічну базу для технологій ШІ. Недостатнє фінансування охорони здоров'я. |
| **Технологічна база** | Розробкою технологій ШІ здебільшого займаються люди без медичної освіти, тому можуть виникати питання щодо медичних помилок. Вони не можуть бути виправлені медичним персоналом, що призведе до неякісного результату. |

Практична реалізація підходу інтеграції знань стикається з фундаментальною проблемою дефіциту даних. Невеликий розмір верифікованих медичних наборів даних створює суттєвий бар'єр для отримання задовільних DL-моделей, оскільки, згідно з дослідженнями [17], здатність моделі до узагальнення корелює з обсягом навчальної вибірки. У традиційних задачах комп'ютерного зору існують еталонні набори даних, такі як ImageNet (понад 14 мільйонів анотованих зображень). На відміну від цього, загальнодоступні медичні набори даних є на порядки меншими, що вимагає специфічних методів адаптації, таких як навчання з малою кількістю прикладів або адаптація без доступу до вихідного домену [18]. Цей дисбаланс призводить до того, що емпіричний ризик $R_{emp}(f_{CAD}; S_{med})$ перестає бути надійною оцінкою істинного ризику $R_{true}(f_{CAD})$, що спричиняє явище перенавчання (overfitting).

![Порівняльна характеристика обсягів даних](figs/figure_ch1_data_distribution.pdf)
*Рисунок 2. Порівняльна характеристика обсягів даних у загальних наборах комп'ютерного зору (ImageNet) та спеціалізованих медичних наборах (ACDC та M&Ms), що ілюструє проблему дефіциту даних.*

Ілюстрацією цієї проблеми є статистика доступних наборів даних, візуалізована на Рисунку 2. Серед множини існуючих ресурсів лише окремі містять понад 100 000 зображень. До таких належать ChestX-ray14 [19] та CheXpert [20]. Також варто виділити набори PadChest [21] та DeepLesion [22], які забезпечують значний обсяг даних для навчання. Для аналізу звітів радіологів важливим є ресурс MIMIC-CXR [23], що поєднує зображення та текстові описи. У галузі МРТ серця значними є ініціативи CMRxMotion [24] та CMRxRecon [25], що надають дані для задач реконструкції та аналізу руху. Детальний розподіл та характеристики найбільш релевантних медичних наборів даних наведено в Таблиці 2.

*Таблиця 2. Аналіз наборів даних, що використовуються для вирішення різних завдань обробки медичних зображень.*

| Назва набору даних | Завдання | Медичний фокус | Тип даних | Кількість |
| :--- | :--- | :--- | :---: | :--- |
| Cardiac MRI [26] | Класифікація, Сегментація | Серцево-судинна | МРТ | 7980 зображень з 33 сканів |
| ABIDE [27] | Класифікація | Мозок | МРТ | 539 пацієнтів та 573 скани |
| ADNI [28] | Класифікація | Мозок | Різні | 1921 пацієнт |
| ChestX-ray14 [19] | Виявлення | Грудна клітка | Рентген | 112 120 зображень |
| CheXpert [20] | Класифікація | Грудна клітка | Рентген | 224 316 зображень |
| LDCT-IQ [29] | Оцінка якості | Торакальна/Абдомінальна | КТ | Різні дози |
| MIMIC-CXR [30] | Генерація звітів | Грудна клітка | Рентген/Текст | 377 110 зображень |
| BraTS2021 [31] | Сегментація | Мозок | МРТ | 542 зображення |
| DeepLesion [22] | Класифікація, Виявлення | Різні | КТ | 32 735 зображень |

Проблема дефіциту даних у медичній сфері має системний характер і проявляється у трьох взаємопов'язаних аспектах. По-перше, абсолютна кількість зображень є обмеженою через високу вартість та складність процедур збору даних (КТ, МРТ, ПЕТ). По-друге, існує критична нестача якісних анотацій, що вимагають експертних знань. По-третє, спостерігається значний дисбаланс класів, особливо для рідкісних патологій. Це питання детально розглядається в контексті «довгого хвоста» розподілу даних у роботах [32], [33].

Прямим наслідком цих обмежень є схильність глибоких моделей до перенавчання [34]. Математично перенавчання визначається як значна розбіжність між значенням функції втрат на навчальній та тестовій вибірках. Нехай $\mathcal{L}(y, \hat{y})$ — функція втрат, наприклад, перехресна ентропія або відстань Хаусдорфа, яка є специфічною для задач сегментації [35]. Умова перенавчання записується як:

$$
\mathbb{E}_{(x,y) \sim S_{train}} [\mathcal{L}(y, f_{CAD}(x; \theta))] \ll \mathbb{E}_{(x,y) \sim S_{test}} [\mathcal{L}(y, f_{CAD}(x; \theta))].
$$

Для боротьби з цим явищем у комп'ютерному зорі розроблено низку методів регуляризації. Серед них — методи оптимізації, такі як Adam [36], зменшення ємності мережі (pruning), та стохастична регуляризація. Важливу роль відіграє аугментація даних, яка може бути реалізована за допомогою генеративних змагальних мереж (GAN) [37] або методів доменно-змагального навчання [38].

Однак, зазначені методи є суто статистичними інструментами. В умовах критичного дефіциту даних більш перспективним підходом є інтеграція зовнішніх знань, що дозволяє компенсувати нестачу навчальних прикладів. Попри наявні перешкоди, інтеграція діагностичних моделей демонструє потенціал для значного підвищення ефективності, що підтверджується ключовими результатами останніх досліджень (Таблиця 3).

*Таблиця 3. Ключові показники результативності інтегрованих діагностичних моделей ШІ, що демонструють потенціал гібридних підходів [16].*

| Метрика | Значення |
| :--- | :--- |
| Чутливість (Sensitivity) | 94,5% |
| Специфічність (Specificity) | 92,3% |
| Загальна класифікація | 93,8% |
| Інтерпретованість | Покращене розуміння процесу прийняття рішень системою ШІ |

Ідея використання зовнішньої інформації реалізується через різні механізми. Найпоширенішим є трансферне навчання (transfer learning) [39], [40], де модель попередньо навчається на масивному наборі даних. Отримані параметри слугують початковою точкою для навчання на цільовому медичному наборі. Цей підхід довів свою ефективність у задачах класифікації раку простати [41] та виявленні патологій на трансректальному ультразвуці [42]. Для ефективної адаптації часто використовують дистиляцію знань, огляд методів якої наведено у [43].

Окрім трансферного навчання, важливим джерелом є знання предметної області, які можна класифікувати за рівнем абстракції. Високорівневі знання включають діагностичні протоколи та таксономії захворювань [44], [45]. Низькорівневі знання охоплюють інформацію про анатомічну локалізацію та морфологічні ознаки [46]. Для завдань сегментації критично важливими є апріорні знання про форму та взаємне розташування органів [47], [48].

![Категоризація знань та методів для діагностики захворювань](figs/figure_ch1_knowledge_integration.pdf)
*Рисунок 3. Категоризація знань та методів для діагностики захворювань: ієрархія завдань та джерел додаткової інформації [12].*

Сучасні методи інтеграції знань включають гібридні архітектури, що поєднують глибокі нейронні мережі з традиційними методами (handcrafted features) [49]. Якщо позначити $h_{DL}$ як вектор ознак з DL-моделі, а $h_{HC}$ як вектор, розрахований на основі експертних правил (наприклад, форми або текстури [50], [51]), то об'єднаний дескриптор використовується для прийняття рішення. Більш складні підходи використовують механізми уваги для імітації патернів візуального пошуку радіолога [52], [53]. Карта уваги модулює просторові ознаки, посилюючи сигнал від релевантних зон. Також застосовуються багатозадачне навчання [14] та мета-навчання [54].

Попри наявність оглядових праць з медичного глибокого навчання, існує потреба у систематизації методів саме в контексті інтеграції експертних знань. Рисунок 3 ілюструє концептуальну таксономію підходів до цієї проблеми. На верхньому рівні цієї схеми дослідження класифікуються за клінічними завданнями: 1) діагностика (класифікація) захворювань; 2) виявлення анатомічних структур та аномалій; 3) сегментація органів та уражень.

## 1,2 Огляд сучасних підходів систем штучного інтелекту до діагностики захворювань

Задача діагностики захворювань засобами штучного інтелекту формалізується як проблема класифікації вхідного зображення $I$ до одного з класів множини $\mathcal{C} = \{c_1, c_2, \dots, c_K\}$, що представляють можливі патологічні стани або норму.

### 1,2,1 Моделі глибокого навчання для діагностики захворювань

Протягом останнього десятиліття домінуючим підходом у цій галузі стали згорткові нейронні мережі (CNN), принципи яких були закладені у фундаментальних роботах [55]. Архітектура CNN базується на біологічно натхненних принципах організації зорової кори, зокрема на наявності рецептивних полів та ієрархічній обробці інформації.

Математично згортковий шар $l$ виконує перетворення вхідного тензора ознак $F^{(l-1)}$ у вихідний тензор $F^{(l)}$ за допомогою операції згортки з набором ядер (фільтрів) $W^{(l)}$ та додавання зміщення $b^{(l)}$, з подальшим застосуванням нелінійної функції активації $\sigma$:

$$
F_k^{(l)}(i,j) = \sigma \left( \sum_{c} \sum_{u,v} W_{k,c}^{(l)}(u,v) \cdot F_c^{(l-1)}(i-u, j-v) + b_k^{(l)} \right),
$$

де $k$ — індекс вихідної карти ознак, $c$ — індекс вхідного каналу, $(u,v)$ — просторові координати ядра.

Функція активації $\sigma(\cdot)$ забезпечує нелінійність моделі, що є критичним для вивчення складних залежностей. Для зменшення розмірності даних використовуються шари субдискретизації (pooling):

$$
P_k^{(l)}(i,j) = \max_{(u,v) \in \Omega(i,j)} F_k^{(l)}(u,v).
$$

Глибока архітектура формується шляхом каскадного з'єднання блоків «згортка-пулінг». Останній шар зазвичай використовує функцію Softmax для генерації розподілу ймовірностей $\hat{y}$ над класами діагнозів:

$$
\hat{y}_k = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)},
$$

де $z_k$ — логіт для класу $k$.

Еволюція архітектур CNN, починаючи від VGGNet [56] до більш сучасних ResNet [57] та DenseNet [58], дозволила значно підвищити точність діагностики. Зокрема, введення залишкових зв'язків у ResNet дозволило ефективно навчати надглибокі мережі. У медичних застосуваннях ці архітектури є базовими. Наприклад, вони успішно застосовуються для діагностики виразкового кератиту [59] та виявлення легеневих вузликів [60], [7].

Для завдань сегментації, які вимагають піксельної точності, використовуються спеціалізовані архітектури, такі як U-Net та її модифікації. Прикладами є R2U-Net [61], яка поєднує рекурентні та залишкові блоки, та методи для сегментації пухлин мозку [62], [63]. У роботах [64], [65] продемонстровано ефективність глибоких мереж для сегментації гіперінтенсивності білої речовини та неонатального мозку відповідно. Важливим напрямком є також використання умовних випадкових полів (CRF) у поєднанні з нейронними мережами для уточнення меж об'єктів [66]. Для задач кардіології розробляються методи семантичного маркування зрізів КТ [67].

У сучасній цифровій патології виділяють кілька категорій методів, що використовуються для обробки зображень та інтеграції знань. Їх класифікація наведена в Таблиці 4.

*Таблиця 4. Категорії методів цифрової патології, що використовуються для аналізу медичних зображень [16].*

| Категорія методу | Опис |
| :--- | :--- |
| **Статичні** | Традиційні методи аналізу нерухомих зображень. |
| **Динамічні** | Методи, що враховують часові зміни або рух. |
| **Роботизовані** | Автоматизовані системи збору та обробки зразків. |
| **Повнослайдові (Whole Slide Imaging)** | Сканування та аналіз цілих гістологічних препаратів з високою роздільною здатністю. |
| **Гібридні** | Поєднання кількох підходів для підвищення точності. |

Однак, стандартні CNN, навчені «з нуля» або адаптовані без урахування специфіки домену, часто ігнорують багатий контекст медичних знань. Це обмежує їхню ефективність в умовах малих вибірок та знижує інтерпретованість рішень.

![Ілюстрація проблеми зсуву домену](figs/figure_ch1_domain_shift.pdf)
*Рисунок 4. Ілюстрація проблеми зсуву домену (Domain Shift) у медичній діагностиці: відмінності у розподілі даних між різними сканерами та клінічними центрами, що призводять до деградації точності моделей.*

Проблема, візуалізована на Рисунку 4, демонструє необхідність розробки методів, стійких до варіативності обладнання, що є одним із ключових завдань даної роботи.

### 1,2,2 Аналіз підходів до інтеграції знань з медичних наборів даних у моделі глибокого навчання

Інтеграція знань через використання додаткових наборів даних є однією з найбільш розроблених стратегій. Згідно з [68], існують дві основні стратегії використання попередньо навчених моделей (Рисунок 5).

![Дві стратегії використання попередньо навчених DL-моделей](figs/figure_ch1_transfer_strategies.pdf)
*Рисунок 5. Дві стратегії використання попередньо навчених DL-моделей для аналізу медичних зображень: (a) як фіксований екстрактор ознак та (b) як ініціалізація для доналаштування на цільовому наборі даних [68].*

Перша стратегія (Рисунок 5a) використовує мережу $M_{pre}$ як фіксований екстрактор ознак. Вихідний вектор використовується для навчання класифікатора $C$. Цей підхід є ефективним і зменшує ризик перенавчання на малих наборах даних, що підтверджено у дослідженнях [5], [69].

Друга стратегія (Рисунок 5b) передбачає доналаштування (fine-tuning) всієї мережі або її частини. Параметри ініціалізуються значеннями $\theta_{source}^*$, а потім оновлюються на цільових даних. Цей метод дозволяє адаптувати високорівневі ознаки до специфіки медичних зображень і є стандартом для багатьох задач, включаючи дерматоскопію [10] та рентгенографію [6].

Окрім трансферного навчання, важливим механізмом є дистиляція знань. Це дозволяє передавати інформацію від складних ансамблів до компактних моделей або між різними модальностями [70]. Сучасні методи дистиляції включають використання мета-знань [71] та адаптацію до нових доменів [72]. Для підвищення робастності сегментації розробляються методи дистиляції форми та інтенсивності [73], а також методи навчання на основі точкових анотацій [74]. У роботі [75] запропоновано підхід до рекомбінації ознак для трансформерів у задачах МРТ.

Важливим напрямком є також розв'язання проблеми «чорної скриньки» при адаптації домену [76] та забезпечення пояснюваності дистильованих моделей [77]. Багатозадачне навчання (Multi-task Learning) є розширенням цієї ідеї, де модель одночасно навчається вирішувати декілька пов'язаних завдань. Спільне представлення ознак дозволяє обмінюватися інформацією між завданнями. Дослідження [78], [79] демонструють ефективність цього підходу для класифікації гліом та пухлин молочної залози. У роботі [80] показано переваги використання кореляцій між різними станами при діагностиці хвороби Альцгеймера.

## 1,3 Характеристики та формалізація знань предметної області для розробки систем штучного інтелекту

Процес медичної діагностики не є лінійним перетворенням вхідного сигналу у вихідний діагноз. Він базується на складній системі знань та евристик. Згідно з класифікацією, наведеною в роботах [12] та інших джерелах, виділимо такі категорії знань: навчальні патерни, процедурні діагностичні патерни, просторові пріоритети, семантичні ознаки, мультимодальний контекст.

### 1,3,1 Навчальний патерн медичних працівників та Curriculum Learning

Навчання лікаря відбувається за принципово іншою схемою, ніж стандартне навчання нейронної мережі. Студенти-медики опановують матеріал поступово. Ця стратегія може бути формалізована в рамках парадигми навчання за програмою (Curriculum Learning) [45]. Навчальна програма визначається як послідовність вагових функцій, що еволюціонують, включаючи спочатку лише «легкі» приклади.

У роботі [44] для аналізу МРТ молочної залози використано стратегію, де модель спочатку вчиться виявляти наявність ураження, а потім класифікувати його. Подібні підходи ефективні для класифікації переломів [81] та діагностики глаукоми [82]. Для вирішення проблем дисбалансу даних застосовуються методи адаптивної вибірки [83] та підходи, засновані на псевдо-мітках з анти-навчальним планом [84].

### 1,3,2 Загальні діагностичні патерни та архітектурні пріори

Досвідчені радіологи використовують специфічні стратегії візуального пошуку, які включають глобальний огляд та детальне сканування. Цей процедурний патерн можна імплементувати через багатопотокову обробку [14]. Така структура (Рисунок 6) дозволяє моделі враховувати як контекст, так і деталі текстури.

![Ілюстрація архітектури, що імітує діагностичний патерн радіолога](figs/figure_ch1_diagnostic_pattern.pdf)
*Рисунок 6. Ілюстрація архітектури, що імітує діагностичний патерн радіолога: глобальна та локальна гілки обробки з подальшим злиттям ознак [14].*

Іншим прикладом є використання симетрії. При аналізі мамограм лікарі порівнюють молочні залози для виявлення асиметрії. Архітектури, такі як MommiNet [85] та методи, описані у [86], [87], явно кодують цю стратегію, використовуючи сіамські мережі для виявлення відмінностей. Аналогічний підхід застосовується для відстеження змін у часі при скринінгу меланоми [88]. Для аналізу легеневих вузликів ефективними є мережі з подвійним шляхом та мульти-видові архітектури [89], [90]. У роботі [91] також досліджувалося використання глибоких мереж для виявлення патологій грудної клітки з урахуванням специфічних діагностичних патернів.

### 1,3,3 Області інтересу та механізми уваги

Медичні фахівці фокусуються на клінічно значущих зонах. Інтеграція знань про ці зони реалізується через механізми уваги, огляд яких представлено у [53]. Нехай $A_{exp}$ — карта уваги, отримана на основі записів руху очей експерта. Задача полягає в мінімізації розбіжності між генерованою картою уваги та експертною.

У моделі AG-CNN [9] для діагностики глаукоми (Рисунок 7) цей підхід дозволив значно підвищити чутливість моделі. Подібні механізми інтегровані в моделі для класифікації медичних зображень [92] та прогнозування ускладнень, таких як нориці [93].

![Приклад використання карт уваги офтальмолога](figs/figure_ch1_attention_maps.pdf)
*Рисунок 7. Приклад використання карт уваги офтальмолога для навчання моделі AG-CNN. Порівняння карт фіксації погляду та карт активації мережі демонструє ефективність керованого навчання [9].*

Альтернативним підходом є «жорстка» увага, де зображення маскується на основі сегментації органу перед подачею в класифікатор, як це реалізовано для зображень оптичної когерентної томографії [94]. Для катаракти розроблено методи, що керуються увагою до судин [95].

### 1,3,4 Візуальні ознаки та семантичні дескриптори

Медична діагностика спирається на стандартизовані системи опису патологій, такі як BI-RADS [96]. Інтеграція «вручну створених ознак» з абстрактними ознаками CNN може відбуватися на рівні рішень або ознак. У дослідженнях [11], [97] показано переваги злиття результатів роботи CNN та класифікаторів, навчених на традиційних ознаках.

Злиття на рівні ознак дозволяє знаходити нелінійні кореляції. Це продемонстровано для класифікації вузлів у легенях [49], раку молочної залози [98], [99] та дерматології. Важливими є також ознаки форми [50] та текстурні переходи [51]. Окремим напрямком є використання радіомних ознак для прогнозування інвазивності пухлин [100]. Також досліджено методи введення інформації про краї та межі у процес навчання [101].

Особливо цікавим є підхід використання семантичних ознак як цільових міток у багатозадачному навчанні. Це змушує CNN формувати внутрішні представлення, що корелюють з клінічно значущими поняттями [102], [103]. У роботі [104] запропоновано інтерпретовану мережу MDNet для медичної діагностики. Включення анатомічних знань також дозволяє покращити результати сегментації, як показано у [105], [48]. Окремо слід згадати методи, що використовують локальні бінарні патерни або інші перетворення на рівні входу [106].

### 1,3,5 Інтеграція текстових та мультимодальних знань

Медичне зображення ніколи не інтерпретується у вакуумі. Клінічний контекст, що міститься у радіологічних звітах, є критично важливим. Для обробки тексту використовуються сучасні мовні моделі, такі як BERT [107] та його біомедична адаптація BioBERT [108].

Для інтеграції текстових звітів використовуються гібридні архітектури CNN-RNN. Наприклад, мережа TieNet [109] використовує спільний простір вбудовування для зображень та тексту. Дослідження [110], [111] фокусуються на генерації клінічно релевантних описів. Також розробляються методи класифікації медичних текстів [112], [113] та розділення синтаксичної і семантичної інформації [114].

Важливим аспектом є логічне висновування на природній мові (NLI). У роботах [115], [116] пропонуються методи покращення NLI шляхом інтеграції зовнішніх знань та аналізу тональності. Водночас існують проблеми, пов'язані з артефактами у наборах даних NLI, які досліджуються у [117]. Для покращення розуміння семантики використовуються вдосконалені методи LSTM [118] та аналіз векторних представлень [119].

Графи знань (Knowledge Graphs, KG) дозволяють інтегрувати структуровану інформацію. Огляд методів побудови пацієнт-орієнтованих графів наведено у [120]. Використання графових нейронних мереж, таких як GAT [121], дозволяє ефективно обробляти такі структури. У дослідженнях [122], [123] вектори з графів знань використовуються для покращення діагностики та генерації звітів. Також активно розвиваються методи вбудовування графів [124] та ієрархічного навчання представлень [125]. Для класифікації графів використовуються архітектури DGCNN [126], а для пояснення рішень — методи GNNExplainer [127]. Окремої уваги заслуговують методи напівконтрольованого навчання на графах [128] та використання апріорних знань для класифікації [129].

## 1,4 Огляд підходів до інтеграції медичних знань в системах обробки медичних даних

Методологія інтеграції знань виходить за межі класифікації і є актуальною для задач реконструкції, пошуку та генерації описів.

### 1,4,1 Реконструкція медичних зображень

У задачах реконструкції знання виступають як апріорні обмеження. Використання генеративно-змагальних мереж (GAN), таких як DAGAN [130], дозволяє відновити деталі МРТ. Також досліджуються методи синтезу зображень для мультимодальних даних [131], [132]. Новітнім напрямком є використання дифузійних ймовірнісних моделей для генерації 3D зображень [133]. Для оптичної томографії розроблено методи на основі нечітких функцій втрат [134].

### 1,4,2 Пошук медичних зображень (CBIR)

Системи пошуку за вмістом (CBIR) допомагають лікарям знайти схожі історичні випадки. Інтеграція знань тут відбувається через семантичне збагачення вектора ознак [135]. Використання бінарних текстур [136] та метаданих пацієнтів, таких як вік і стать [137], дозволяє покращити релевантність пошуку. У роботі [138] запропоновано метод послідовного звуження простору пошуку з використанням глибоких ознак.

### 1,4,3 Генерація медичних звітів

Автоматична генерація описів вимагає перетворення візуальних ознак у послідовність слів. Інтеграція знань тут критична для забезпечення фактологічної точності. Використання механізмів пошуку та перефразування [139], а також гібридних агентів з навчанням з підкріпленням [140], дозволяє генерувати звіти, що відповідають професійному стилю. У роботі [141] запропоновано мережу MVP-Net для виявлення уражень, яка також може бути частиною пайплайну генерації звітів.

## 1,5 Актуальні проблеми та виклики інтеграції знань

Попри значний прогрес, інтеграція знань у медичний ШІ залишається відкритою науковою проблемою, що характеризується низкою викликів.

### 1,5,1 Проблеми ідентифікації та формалізації знань

Експертні знання часто є неявними, а лікарі діють інтуїтивно. Автоматичне вилучення знань з текстів є перспективним, але стикається з проблемою неоднозначності. Інструменти, такі як MetaMap [142] та спеціалізовані бібліотеки NLP [143], допомагають структурувати інформацію. Важливу роль відіграє Уніфікована система медичної мови (UMLS), яка надає онтологічну базу для досліджень [144].

### 1,5,2 Труднощі представлення та методів включення

Існує «семантичний розрив» між символьним представленням знань та субсимвольним представленням у нейронних мережах. Розробка диференційовних механізмів, що дозволяють транслювати логічні обмеження у градієнти помилок, є нетривіальною задачею. Прикладами спроб подолання цього розриву є використання знань про структуру при діагностиці целіакії [145] та застосування класифікаторів для діагностики раку молочної залози [49].

### 1,5,3 Проблема зсуву домену та дистиляція знань

Медичні дані є вкрай гетерогенними. Зображення, отримані на різних сканерах, мають різні статистичні розподіли, що призводить до зсуву домену. Методи адаптації домену [76] та дистиляції знань є ключовими для вирішення цієї проблеми. Це дає змогу зберегти знання при переході між модальностями або при роботі з обмеженими даними [72]. Актуальними є дослідження узгодженості семантики при адаптації, наприклад, для класифікації вузлів щитоподібної залози [146], [147] та аналізу ретинальних зображень [148].

## 1,6 Постановка завдання дисертаційної роботи

На основі проведеного аналізу встановлено, що існуючі методи інтеграції знань є фрагментарними і часто не забезпечують системного підходу. Існує протиріччя між необхідністю підвищення надійності діагностичних систем і обмеженими можливостями суто статистичних методів навчання на малих вибірках. Спираючись на попередні дослідження автора [149], [16], метою роботи визначено вдосконалення процесу прийняття рішень під час медичної діагностики.

Для досягнення мети сформульовано наступні завдання:

*   Провести системний аналіз методів глибокого навчання та способів формалізації медичних знань.
*   Розробити метод інтеграції знань на основі дистиляції від ансамблю вчителів для адаптації до нових доменів.
*   Розробити метод покращення текстового висновування (NLI) шляхом інтеграції онтологічних знань UMLS та аналізу тональності, розвиваючи ідеї, викладені у [115].
*   Розробити архітектуру для сегментації зображень, що інтегрує експертні анотації та топологічні обмеження.
*   Експериментально підтвердити ефективність розроблених методів на реальних клінічних даних.

## 1,7 Висновки до Розділу 1

У даному розділі здійснено комплексний аналіз проблеми інтеграції знань у системи медичного штучного інтелекту. Показано, що «чисті» підходи, засновані на даних, досягли межі своєї ефективності в умовах дефіциту анотованих даних. Встановлено, що найбільш перспективним вектором розвитку є створення гібридних систем, які поєднують потужність глибокого навчання з надійністю експертних знань.

Систематизовано типи медичних знань та методи їх інтеграції, такі як трансферне навчання, багатозадачність та механізми уваги. Формалізовано математичні апарати цих методів. Визначено ключові виклики, пов'язані зі зсувом домену та семантичним розривом, які будуть вирішуватися у наступних розділах дисертації.

---

# Розділ 2. Моделі та методи передачі експертних знань до системи штучного інтелекту медичного діагностичного комплексу

Сучасна парадигма розвитку медичних інформаційних систем характеризується стрімким переходом від класичних алгоритмічних підходів до використання адаптивних моделей штучного інтелекту, здатних опрацьовувати надвеликі масиви гетерогенних даних. Процес класифікації медичних зображень, який лежить в основі автоматизованої діагностики, передбачає складну процедуру категоризації візуальної інформації на основі виявлення латентних ознак, що корелюють з патологічними станами біологічних тканин або наявністю специфічних анатомічних аномалій. У контексті аналізу зображень різної модальності, таких як магнітно-резонансна томографія, комп'ютерна томографія або цифрова рентгенографія, вхідні дані розглядаються як багатовимірні тензори інтенсивності, тоді як діагностичний висновок, що визначає тип патології або відхилення від фізіологічної норми, виступає у ролі цільової змінної або семантичної анотації. Відповідно, фундаментальна задача побудови інтелектуального діагностичного комплексу зводиться до синтезу та навчання моделі глибокого навчання, здатної апроксимувати складну нелінійну функцію відображення простору візуальних ознак у простір клінічних рішень.

Досягнення моделлю необхідного рівня узагальнення шляхом ітеративного стохастичного навчання дозволяє отримати систему, яка демонструє високу точність класифікації на нових даних, за умови стаціонарності статистичного розподілу вхідних сигналів. Проте у реальній клінічній практиці ця умова часто порушується, що призводить до явища, відомого як зсув домену. Це явище характеризується суттвою деградацією метрик якості розпізнавання при спробі застосування моделі, навченої на даних одного медичного закладу, до даних, отриманих в інших умовах, на іншому обладнанні або на іншій популяції пацієнтів. Зсув домену є критичною перешкодою для масштабування та впровадження систем штучного інтелекту, оскільки він підриває надійність діагностичних висновків у неконтрольованому середовищі. Окрім проблеми гетерогенності даних, суттєвим обмежувальним фактором є дефіцит верифікованих анотованих наборів даних. Процес створення розмічених медичних вибірок вимагає залучення висококваліфікованих експертів і є надзвичайно ресурсомістким, що створює дисбаланс між величезними обсягами накопичених сирих даних та мізерною кількістю даних, придатних для навчання з учителем.

У відповідь на зазначені виклики, даний розділ дисертаційного дослідження присвячено розробці нових методів інтеграції знань, які дозволяють компенсувати нестачу розмічених даних та подолати бар'єр зсуву домену. Перша частина розділу фокусується на методі дистиляції знань від ансамблю моделей-вчителів до єдиної моделі-учня, що дозволяє агрегувати досвід, отриманий з різнорідних джерел, та адаптувати його до цільового домену. Друга частина розділу розкриває методологію покращення автоматизованого аналізу клінічних текстів шляхом інтеграції онтологічних знань та аналізу тональності, що дозволяє системі глибше розуміти семантику медичних записів та підвищувати точність прийняття рішень на основі текстових даних. Обидва підходи спрямовані на створення надійних, адаптивних та точних компонентів інтелектуальних діагностичних комплексів.

## 2,1 Метод дистиляції знань від множини моделей-вчителів до єдиної моделі-учня

Розглянемо задачу класифікації медичних зображень у загальній постановці, яка полягає у виявленні та ідентифікації візуальних маркерів патологічних змін на зображеннях, отриманих з джерел з різними статистичними характеристиками. Така задача є класичним прикладом проблеми адаптації домену, де модель, що оптимізована на одному розподілі даних (початковий домен), повинна відповідно точно функціонувати на іншому, хоча й семантично пов'язаному розподілі (цільовий домен). Для вирішення цієї проблеми у даній роботі пропонується застосування та розвиток методу дистиляції знань, який дозволяє здійснити трансфер узагальненої інформації від колективу моделей-вчителів, кожна з яких спеціалізується на конкретному початковому домені, до компактної моделі-учня, що адаптується до специфіки цільового домену.

Науковий внесок даного підрозділу полягає у розробці нового методу ансамблевої дистиляції знань, який включає використання спеціалізованої моделі-вчителя для змагальної адаптації домену та механізму селективної фільтрації знань. Запропонований підхід забезпечує точне накопичення знань з децентралізованих джерел, представлених окремими моделями, та їх передачу моделі-учню, що підвищує стійкість системи до варіативності вхідних даних та покращує точність діагностики в умовах обмеженої розмітки.

Основні переваги та відмінності запропонованого методу можна сформулювати наступним чином:

*   Метод дозволяє інтегрувати знання з гетерогенних джерел, таких як різні клініки або типи діагностичного обладнання, без необхідності фізичного об'єднання сирих даних, що є критично важливим для дотримання вимог конфіденційності та захисту персональних даних пацієнтів.
*   На відміну від класичних схем дистиляції, що використовують одного вчителя, запропонований підхід базується на використанні динамічного ансамблю, до складу якого входить модель, навчена виділяти доменно-інваріантні ознаки, що дозволяє моделі-учню засвоювати найбільш універсальні патерни патологій.
*   Впровадження механізму фільтрації знань на основі верифікації на малій вибірці цільового домену дозволяє відсіювати помилкові передбачення вчителів, запобігаючи поширенню неправдивих знань (*negative transfer*) та підвищуючи надійність навчання моделі-учня.
*   Результатом роботи методу є компактна модель-учень, яка, маючи меншу обчислювальну складність, демонструє продуктивність, порівнянну з великими ансамблями, що дозволяє використовувати її в умовах обмежених апаратних ресурсів, наприклад, у мобільних діагностичних комплексах.

Для кращого розуміння контексту дистиляції, розглянемо порівняння існуючих підходів у Таблиці 2,1, що демонструє переваги запропонованого методу EMTKD.

*Таблиця 2,1. Порівняння підходів до дистиляції знань у медичній візуалізації [1].*

| Метод | Основний принцип | Недоліки |
| :--- | :--- | :--- |
| **Звичайна дистиляція (KD)** | Передача знань від одного вчителя до учня через згладжені мітки. | Не враховує різноманітність даних з різних доменів; вразлива до помилок вчителя. |
| **Багатовчителева дистиляція (MTKD)** | Усереднення прогнозів від кількох вчителів. | Конфлікт знань при доменних зсувах; неадаптивне зважування. |
| **Адаптивна дистиляція (AEKD)** | Динамічне зважування вчителів на основі впевненості. | Не використовує доменну адаптацію для вирівнювання ознак. |
| **Запропонований EMTKD** | Поєднання адаптивного зважування, доменної адаптації та SSL. | Підвищена обчислювальна складність на етапі навчання. |

Для побудови математичної моделі процесу дистиляції введемо формальний опис просторів даних. Припустимо наявність множини початкових доменів, кожен з яких представлений відповідним набором даних для навчання окремої моделі-вчителя. Формалізуємо $n$ наборів даних медичних зображень наступним чином:

$$
D_j^t = \{(x_i^j, y_i^j)\}_{i=1}^{N_j}, \quad j=1,\dots,n,
$$

де $x_i^j$ належить до простору ознак $\mathcal{X}_j$ і представляє $i$-те вхідне зображення з $j$-го набору даних, $y_i^j$ належить до простору міток $\mathcal{Y}_j$ і є відповідною діагностичною міткою, $N_j$ позначає кількість зразків у вибірці $j$, а $n$ визначає загальну кількість доступних моделей-вчителів.

Кожен набір даних $D_j^t$ характеризується власним маргінальним розподілом ймовірностей $P_j(X)$, що відображає специфіку конкретного джерела даних.

Цільовий домен, для якого розробляється модель-учень $f_\theta$, представлений набором даних $D_S$, який структурно поділяється на дві неперетинні підмножини:

$$
D_S = \{D_S', D_S''\},
$$

де $D_S'$ — це невелика за обсягом анотована частина вибірки, яка використовується для налаштування та валідації, а $D_S''$ — масивна неанотована частина, що використовується для навчання без учителя та дистиляції знань.

Анотована підмножина визначається як:

$$
D_S' = \{(x_i', y_i')\}_{i=1}^{N'}, \quad x_i' \in \mathcal{X}_S, y_i' \in \mathcal{Y}_S,
$$

де $x_i'$ та $y_i'$ — це відповідно зображення та мітка, що належать до просторів ознак та міток цільового домену.

Неанотована підмножина визначається як:

$$
D_S'' = \{x_i''\}_{i=1}^{N''}, \quad x_i'' \in \mathcal{X}_S,
$$

де $N'$ та $N''$ — потужності відповідних вибірок, причому виконується умова $N' \ll N''$, що є типовим для медичних задач, де експертна розмітка є вузьким місцем.

Загальна архітектура запропонованого методу базується на ієрархічній схемі передачі інформації. Схематичне зображення підходу представлено на Рисунку 2,1, де показано потоки даних від початкових доменів до ансамблю вчителів, а згодом — через механізм агрегації — до моделі-учня.

![Схематичний огляд запропонованого методу EMTKD](figs/figure_ch2_emtkd_scheme.pdf)
*Рисунок 2,1. Схематичний огляд запропонованого методу розширеної багато-вчителевої дистиляції знань (EMTKD). Блок 1 включає навчання моделей-вчителів з адаптацією домену. Блок 2 виконує адаптивну дистиляцію. Блок 3 тренує учня з використанням SSL.*

Методологія реалізується через послідовність трьох ключових етапів: навчання спеціалізованих моделей-вчителів, агрегація та дистиляція знань, і, нарешті, навчання та адаптація моделі-учня.

На першому етапі відбувається незалежне навчання кожної моделі-вчителя $T_j$ на відповідному наборі даних $D_j^t$. Метою навчання є знаходження оптимальних параметрів $\theta_j$, що мінімізують емпіричний ризик, виражений через функцію втрат перехресної ентропії $\mathcal{L}_{CE}$:

$$
\theta_j^* = \arg\min_{\theta_j} \sum_{(x_i^j, y_i^j) \in D_j^t} \mathcal{L}_{CE}(T_j(x_i^j; \theta_j), y_i^j).
$$

Окрім набору доменно-специфічних вчителів, формується додаткова модель $T_{DA}$, призначена для адаптації домену. Ця модель навчається на об'єднаній вибірці всіх вхідних даних з використанням методів змагального навчання (adversarial learning), таких як DANN (Domain-Adversarial Neural Network). Метою $T_{DA}$ є формування простору ознак, в якому мінімізується розбіжність між розподілами різних доменів, що дозволяє виділяти універсальні діагностичні патерни, інваріантні до технічних умов отримання зображень. Процес навчання вчителів з адаптацією домену показано на Рисунку 2,2.

![Схема Блоку 1: Навчання моделей-вчителів](figs/figure_ch2_teacher_da.pdf)
*Рисунок 2,2. Схема Блоку 1: Навчання моделей-вчителів з інтегрованою адаптацією домену. Кожен учитель $T_i$ навчається на своєму джерелі даних $D_i$, одночасно змагаючись з дискримінатором домену $D_l$ для вивчення інваріантних ознак.*

На другому етапі реалізується механізм дистиляції знань. Навчені моделі-вчителі розглядаються як генератори ознак (feature extractors) з фіксованими параметрами. Для кожного вхідного зразка $z_i$ з цільового домену $D_S$ кожна модель $T_j$ формує вектор глибоких ознак (embedding) $e_{ij}$:

$$
T_j: z_i \rightarrow e_{ij}, \quad \text{де } z_i \in D_S, \quad i \in \{1, \dots, N' + N''\}, \quad j=1,\dots,n.
$$

Деталізована покрокова схема процесу дистиляції та навчання моделі-учня наведена на Рисунку 2,3.

![Покрокова алгоритмічна схема методу дистиляції знань](figs/figure_ch2_step_by_step.pdf)
*Рисунок 2,3. Покрокова алгоритмічна схема методу дистиляції знань, що ілюструє потік даних від вхідних моделей-вчителів через блоки вилучення ознак, їх зважування та агрегації до фінального оновлення параметрів моделі-учня.*

Процес агрегації знань адаптується залежно від наявності розмітки для вхідного зразка. Якщо вхідний зразок $z_i$ належить до неанотованої множини $D_S''$, то формується розширений вектор ознак шляхом простої конкатенації виходів усіх вчителів та моделі адаптації домену:

$$
E_i = \text{concat}(e_{i1}, e_{i2}, \dots, e_{in}, e_{i,DA}).
$$

У випадку, коли зразок $z_i$ належить до анотованої множини $D_S'$, застосовується процедура інтелектуальної фільтрації. Вводиться індикаторна функція $m_{ij}$, яка оцінює коректність передбачення $j$-го вчителя відносно істинної мітки $y_i'$:

$$
m_{ij} = \mathbb{I}(\text{argmax } T_j(z_i; \theta_j^*) = y_i'), \quad \text{для } z_i = (x_i', y_i') \in D_S'.
$$

Ця функція дозволяє виключити вплив тих моделей-вчителів, які помиляються на конкретних прикладах цільового домену, запобігаючи таким чином трансферу некоректних знань. Агрегований вектор для анотованих даних формується з урахуванням маски:

$$
E_i' = \text{concat}(m_{i1}e_{i1}, \dots, m_{in}e_{in}, e_{i,DA}).
$$

Сформовані вектори $E_i$ та $E_i'$ подаються на вхід агрегаційної нейронної мережі $g_\phi$, яка виконує нелінійне перетворення та злиття різнорідних ознак у єдиний компактний вектор знань $e_i^{KD}$. Агрегаційна мережа зазвичай реалізується як багатошаровий перцептрон (MLP):

$$
g_\phi:
\begin{cases}
    E_i \rightarrow e_i^{KD}, & \text{якщо } z_i \in D_S'', \\
    E_i' \rightarrow e_i^{KD}, & \text{якщо } z_i \in D_S',
\end{cases}
$$

де вихідний вектор обчислюється через послідовність лінійних шарів та функцій активації ReLU:

$$
e_i^{KD} = \text{ReLU}(\mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 \cdot E_{input} + b_1) + b_2).
$$

Детальна архітектура блоку адаптивної дистиляції, що включає механізми уваги та пулінгу, представлена на Рисунку 2,4.

![Детальна схема Блоку 2: Адаптивна дистиляція знань](figs/figure_ch2_adaptive_block.pdf)
*Рисунок 2,4. Детальна схема Блоку 2: Адаптивна дистиляція знань. Показано процес конкатенації векторів ознак, проходження через мережу агрегації, застосування механізму уваги та формування дистильованого вектора.*

На третьому етапі відбувається навчання моделі-учня $f_\theta$, яка повинна відтворити отриманий узагальнений вектор знань. Модель-учень генерує власний вектор ознак $e_i^{ST}$:

$$
f_\theta: z_i \rightarrow e_i^{ST}, \quad z_i \in D_S.
$$

Процес навчання базується на мінімізації функції втрат дистиляції, яка визначається як метрика відстані (наприклад, середньоквадратична помилка) між вектором знань вчителя та вектором моделі-учня:

$$
\mathcal{L}_i^{\text{Dist}} = \| e_i^{KD} - e_i^{ST} \|_2^2 = \| g_\phi(\text{AggFeatures}(z_i, \{T_j\}, F)) - f_\theta(z_i) \|_2^2.
$$

Для забезпечення стабільності градієнтного спуску оптимізація проводиться пакетним методом (mini-batch), де функція втрат усереднюється по пакету розміром $B$:

$$
\mathcal{L}_B^{\text{Dist}} = \frac{1}{B} \sum_{k=1}^B \mathcal{L}_{z_k}^{\text{Dist}}(e_{z_k}^{KD}, e_{z_k}^{ST}).
$$

Оновлення параметрів моделі-учня $\theta$ здійснюється за допомогою адаптивного алгоритму оптимізації Adam, який враховує моменти градієнтів першого та другого порядку для прискорення збіжності:

$$
\theta_{t+1} = \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon_{Adam}} \nabla_\theta \mathcal{L}_B^{\text{Dist}}(\theta_t),
$$

де $\eta$ — швидкість навчання, $\hat{m}_t$ та $\hat{v}_t$ — експоненційні ковзні середні градієнта та його квадрата.

Схема навчання студента з використанням псевдо-міток та збереженням приватності зображена на Рисунку 2,5.

![Схема Блоку 3: Навчання моделі-учня](figs/figure_ch2_student_privacy.pdf)
*Рисунок 2,5. Схема Блоку 3: Навчання моделі-учня з інтеграцією SSL та механізмів збереження приватності. Використовуються псевдо-мітки для неанотованих даних та диференційна приватність при оновленні градієнтів.*

Особливістю запропонованого методу є врахування обчислювальної складності, що дозволяє використовувати його в обмежених ресурсах. У Таблиці 2,2 наведено порівняння параметрів моделей та часу їх навчання.

*Таблиця 2,2. Час навчання та складність моделей для різних методів адаптації домену [1]. Жирним виділено найменші значення параметрів.*

| Модель | Час навчання (годин) | Параметри (Мільйони) |
| :--- | :---: | :---: |
| STM (baseline) | 5 | **25** |
| MTKD [2] | 7 | 60 |
| DANN [3] | 6 | 30 |
| MTMS [4] | 9 | 65 |
| EMTKD (запропонований) | 12 | 70 |

Паралельно з дистиляцією, на кожній епосі відбувається донавчання класифікатора $f_c$ та коригування агрегатора $g_\phi$ на доступних анотованих даних $D_S'$ з використанням функції втрат перехресної ентропії:

$$
\mathcal{L}_{CE}(y', \hat{y}') = -\frac{1}{N'} \sum_{i=1}^{N'} (y_i' \cdot \log(\hat{y}_i'(x_i')) + (1-y_i') \cdot \log(1-\hat{y}_i'(x_i'))),
$$

де $\hat{y}_i'$ — ймовірність приналежності до позитивного класу, отримана після застосування сигмоїдної активації до виходу класифікатора.

Це дозволяє спрямувати процес формування ознак у бік максимальної дискримінативності для конкретної діагностичної задачі. Оновлення всіх параметрів системи на цьому етапі відбувається спільно:

$$
(\phi, \theta, \theta_c) \leftarrow \text{Adam}(\mathcal{L}_{CE}(y', \hat{y}'), (\phi, \theta, \theta_c)).
$$

Завершальним етапом є тонке налаштування (fine-tuning) моделі-учня, яке виконується з меншою швидкістю навчання для досягнення локального мінімуму функції втрат на цільовому домені:

$$
(\theta', \theta_c') \leftarrow \text{Adam}(\mathcal{L}_{CE}(y', \hat{y}'), (\theta, \theta_c)).
$$

У Таблиці 2,3 наведено приклад конфігурації гіперпараметрів та розмірностей шарів, що можуть бути використані при реалізації запропонованого методу.

*Таблиця 2,3. Рекомендована конфігурація параметрів та розмірностей для реалізації методу дистиляції знань.*

| Параметр | Значення / Опис |
| :--- | :--- |
| Кількість моделей-вчителів ($n+1$) | 4 (3 доменно-специфічні + 1 $T_{DA}$) |
| Архітектура вчителів $T_j, T_{DA}$ | ResNet-50 (попередньо навчена на ImageNet) |
| Розмірність ознак вчителів ($d_j, d_{DA}$) | 2048 |
| Архітектура агрегатора $g_\phi$ | MLP: вхід $4 \times 2048 \rightarrow 1024 \rightarrow 2048$ |
| Розмірність $e_i^{KD}$ ($d_{KD}$) | 2048 |
| Архітектура моделі-учня $f_\theta$ | ResNet-18 (компактна модель) |
| Розмірність ознак моделі-учня ($d_{ST}$) | 2048 |
| Розмір пакету $B$ (дистиляція) | 64 |
| Розмір пакету $B_{CE}$ (оновлення) | 32 (з $D_S'$) |
| Кількість епох дистиляції | 50 |
| Кількість епох доналаштування | 10 |
| Оптимізатор | Adam ($\beta_1=0,9, \beta_2=0,999$) |
| Швидкість навчання (дистиляція) | $1 \times 10^{-4}$ |
| Швидкість навчання (доналаштування) | $1 \times 10^{-6}$ |

Продуктивність інференсу також є критичним фактором. У Таблиці 2,4 показано результати тестування пропускної здатності моделі-учня при використанні різних провайдерів виконання ONNX.

*Таблиця 2,4. Пропускна здатність інференсу та використання ресурсів провайдерами виконання ONNX [5].*

| Провайдер (EP) | Медіана (с) | P95 (с) | Пам'ять (ГБ) |
| :--- | :---: | :---: | :---: |
| CPU | 5,3 | 6,6 | 3,2 |
| CUDA | 0,8 | 1,1 | 4,1 |
| DirectML | 1,2 | 1,6 | 3,8 |

Реалізація запропонованого методу дозволяє створити надійну систему діагностики, яка поєднує в собі переваги використання великих обсягів різнорідних даних для навчання та адаптивність до специфічних умов експлуатації. Метод забезпечує подолання проблеми зсуву домену, покращує використання обчислювальних ресурсів та гарантує конфіденційність даних пацієнтів, що робить його перспективним інструментом для побудови сучасних медичних діагностичних комплексів.

## 2,2 Покращення медичного висновування природною мовою шляхом інтеграції знань предметної області та аналізу тональності

Сфера обробки природної мови (Natural Language Processing, NLP) у медицині стикається з унікальними викликами, пов'язаними з високою щільністю спеціалізованої термінології, складністю синтаксичних конструкцій та критичною важливістю контексту для правильної інтерпретації. Недавні досягнення в галузі контекстуальних векторних представлень слів, такі як BioELMo [6], дозволили суттєво підвищити якість аналізу текстів. Проте задача медичного висновування природною мовою (Natural Language Inference, NLI), яка полягає у визначенні логічного зв'язку між двома твердженнями — засновком (Premise) та гіпотезою (Hypothesis), залишається складною для вирішення суто статистичними методами. Необхідність інтеграції структурованих знань предметної області та точного аналізу тональності (зокрема, заперечень) є ключовою для подальшого прогресу в цій галузі [7]. У даному розділі описується розроблений метод, що поєднує нейромережеві підходи з онтологічними знаннями та аналізом сентименту для підвищення точності NLI.

### 2,2,1 Передумови та аналіз проблематики

Поява трансформерних моделей та контекстуальних ембедінгів, таких як BERT та ELMo, революціонізувала NLP. У біомедичному домені моделі BioBERT [8] та BioELMo [9], донавчені на масивах наукових публікацій PubMed, демонструють здатність фіксувати специфічні нюанси медичної мови. Зокрема, BioELMo генерує глибокі контекстуалізовані представлення, враховуючи як лівий, так і правий контекст кожного токена.

Попри це, суто текстові моделі часто не здатні коректно обробляти ситуації, що вимагають знань, які не містяться явно в тексті, але є частиною медичної онтології (наприклад, знання про те, що певний препарат належить до конкретної фармакологічної групи). Уніфікована система медичних мов (UMLS) [10] надає багату базу таких знань, об'єднуючи тезауруси та семантичні мережі. Інтеграція цих знань у нейронні мережі є активним напрямком досліджень. Методи, такі як ExBERT [11], намагаються поєднати BERT із зовнішніми базами знань. Крім того, критичним аспектом є обробка заперечень та модальності тверджень, оскільки в медицині наявність або відсутність симптому («немає кашлю» проти «є кашель») радикально змінює зміст. Останні дослідження показали перспективність врахування тональності, проте повна синергія між контекстом, онтологією та тональністю залишається відкритою науковою проблемою.

Основні наукові внески цього підрозділу полягають у наступному:

*   **Новий підхід до інтеграції знань:** Розроблено архітектуру, яка вбудовує специфічні знання з UMLS у модель BioELMo, використовуючи векторні представлення концептів, отримані за допомогою моделі MultE [12]. Ця модель точно кодує складні багатозначні відношення в графах знань, що дозволяє системі «розуміти» семантичні зв'язки, які виходять за межі текстового корпусу.
*   **Покращена техніка інтеграції тональності:** Запропоновано метод явного кодування інформації про тональність та заперечення, отриманої за допомогою інструменту MetaMap [13], у вигляді спеціалізованих векторів, які інтегруються з лексичними та онтологічними ембедінгами через механізм уваги.

### 2,2,2 Архітектура запропонованого методу

Задача NLI формулюється як класифікація пари речень (засновок, гіпотеза) на три класи: Entailment (слідування), Contradiction (суперечність) та Neutral (нейтральність). Загальна схема методу базується на архітектурі ESIM (Enhanced Sequential Inference Model) [2], яка доповнюється модулями обробки знань. Схема підходу представлена на Рисунку 2,6.

![Загальна схема класифікації пар засновок-гіпотеза](figs/figure_ch2_nli_scheme.pdf)
*Рисунок 2,6. Загальна схема класифікації пар засновок-гіпотеза, що включає етапи підготовки даних (токенізація, MetaMap), генерації мультимодальних векторних представлень, їх інтеграції та глибокого навчання для прийняття рішення.*

Компоненти запропонованої архітектури та їх функції узагальнено в Таблиці 2,5.

*Таблиця 2,5. Компоненти запропонованої архітектури NLI для аналізу медичних текстів [14].*

| Компонент | Функціональне призначення |
| :--- | :--- |
| BioELMo | Генерація контекстуальних векторів слів на основі корпусу PubMed. |
| MetaMap | Вилучення медичних концептів UMLS та ідентифікація заперечень. |
| MultE | Формування векторів вбудовування для концептів з графа знань. |
| Sentiment Vector | Бінарне кодування тональності (0 - позитивна/нейтральна, 1 - негативна/заперечення). |
| Attention Mechanism | Динамічне зважування важливості кожного типу вбудовування. |
| BiLSTM | Кодування послідовностей засновку та гіпотези з урахуванням контексту. |

Процес обробки даних складається з наступних етапів.

**Етап 1: Підготовка та токенізація.** Вхідні речення токенізуються за допомогою інструментарію CLTK [15], адаптованого для медичних текстів. Паралельно текст обробляється системою MetaMap для ідентифікації медичних концептів UMLS та виявлення заперечень.

**Етап 2: Генерація векторних представлень.** Для кожного токена $w$ формується композитний вектор, що складається з трьох компонентів:

*   **Контекстуальний вектор BioELMo** ($e_{\text{BioELMo}}^w$). Генерується попередньо навченою моделлю BioELMo, що забезпечує врахування лінгвістичного контексту. Розмірність вектора $d_{BioELMo} = 1024$.
*   **Вектор знань MultE** ($e_{\text{MultE}}^w$). Генерується моделлю вбудовування графів знань MultE. Ця модель навчається на підграфі UMLS, релевантному для вхідних даних. Функція оцінки правдоподібності трійки $(h, r, t)$ у MultE визначається як:
    $$
    \phi(h, r, t) = \text{ReLU}(\mathbf{W}_r \mathbf{r} + b_r) \odot \text{ReLU}(\mathbf{W}_h \mathbf{h} + b_h) \cdot \text{ReLU}(\mathbf{W}_t \mathbf{t} + b_t),
    $$
    де $\mathbf{h}, \mathbf{t}, \mathbf{r}$ — вектори сутностей та відношень, $\mathbf{W}$ та $b$ — параметри проекцій, $\odot$ — поелементне множення. Це дозволяє моделювати нелінійні взаємодії між концептами.
*   **Вектор тональності** ($s^w$). Бінарний вектор або скаляр, що вказує на наявність заперечення для даного токена (наприклад, $s^w=1$, якщо токен є частиною запереченого симптому).

**Етап 3: Інтеграція векторів.** Різнорідні вектори об'єднуються за допомогою механізму уваги (*Attention mechanism*), який дозволяє моделі динамічно визначати важливість кожного компонента. Результуючий вектор $\mathbf{e}^{ww}$ обчислюється як:

$$
\mathbf{e}^{ww} = \sum_{k=1}^{3} a_k \mathbf{v}_k,
$$

де $\mathbf{v}_k$ — проектовані вектори компонентів, а $a_k$ — ваги уваги, що розраховуються через Softmax функцію від оцінок важливості:

$$
a_k = \frac{\exp(f_{att}(\mathbf{v}_k))}{\sum_{j=1}^{3} \exp(f_{att}(\mathbf{v}_j))}.
$$

Ілюстрація процесу об'єднання наведена на Рисунку 2,7.

![Схема формування композитного векторного представлення](figs/figure_ch2_embedding_combination.pdf)
*Рисунок 2,7. Схема формування композитного векторного представлення токена шляхом злиття контекстуальних (BioELMo), онтологічних (MultE) та тональних ознак (Sentiment Vector) через механізм вирівнювання.*

На Рисунку 2,8 показано деталізовану архітектуру рекурентної мережі, що використовується для обробки отриманих ембедінгів.

![Архітектура BiLSTM для медичного NLI](figs/figure_ch2_bilstm_arch.pdf)
*Рисунок 2,8. Архітектура BiLSTM для медичного NLI: два потоки кодування (засновок/гіпотеза), механізм перехресної уваги та шар класифікації.*

**Етап 4: Глибоке навчання та класифікація.** Збагачені вектори подаються на вхід архітектури ESIM. Вона включає шари BiLSTM для кодування послідовностей, механізм перехресної уваги для вирівнювання засновку та гіпотези (*Local Inference Modeling*), та шар композиції, який формує вектори різниці та поелементного добутку для виявлення суперечностей. Матриця уваги $A_{ij}$ між прихованими станами засновку $\bar{p}_i$ та гіпотези $\bar{h}_j$ обчислюється як:

$$
A_{ij} = \bar{p}_i^T \bar{h}_j.
$$

![Деталізація механізму уваги в моделі ESIM](figs/figure_ch2_attention_esim.pdf)
*Рисунок 2,9. Деталізація механізму уваги в моделі ESIM, який обчислює матрицю схожості між словами засновку та гіпотези для визначення локальних висновків.*

Фінальна класифікація здійснюється через повнозв'язний шар з функцією активації Softmax:

$$
\hat{y} = \text{Softmax}(\mathbf{W}_{mlp} v_{final} + b_{mlp}),
$$

де $v_{final}$ — агрегований вектор представлення пари речень.

![Фрагмент графа знань UMLS](figs/figure_ch2_umls_fragment.pdf)
*Рисунок 2,10. Фрагмент графа знань UMLS, що демонструє семантичні типи та відношення між медичними поняттями, які використовуються для навчання моделі MultE.*

Для кращого розуміння джерела знань, на Рисунку 2,10 наведено приклад структури UMLS, що використовується для генерації векторів MultE. Ця структурована інформація дозволяє моделі розуміти зв'язки типу «є симптомом» або «лікує», які часто опускаються в тексті.

![Логіка формування вектора тональності](figs/figure_ch2_sentiment_logic.pdf)
*Рисунок 2,11. Логіка формування вектора тональності на основі виводу MetaMap: виявлення заперечень (Negation) та їх кодування у бінарний вектор.*

Нарешті, Рисунок 2,11 ілюструє процес вилучення тональності, що є критичним для розрізнення тверджень про наявність та відсутність симптомів.

***

### References

[1] A. Chaban, “EMTKD at the edge: An adaptive multi-teacher knowledge distillation for robust cardiac MRI classification,” in *Proc. Medical Imaging Conference*, 2025, p. 43.
[2] Q. Chen *et al.*, “Enhanced LSTM for Natural Language Inference,” in *Proc. ACL*, 2017.
[3] Y. Ganin *et al.*, “Domain-Adversarial Training of Neural Networks,” *Journal of Machine Learning Research*, vol. 17, no. 59, pp. 1–35, 2016.
[4] S. Nabavi *et al.*, “Multi-Teacher Multi-Student Knowledge Distillation,” in *Proc. CVPR*, 2024.
[5] A. Chaban *et al.*, “Intelligent Information System for Knowledge Integration into Artificial Intelligence Models,” in *Proc. Intelligent Systems*, 2025, p. 10.
[6] M. E. Peters *et al.*, “Deep contextualized word representations,” in *Proc. NAACL*, 2018.
[7] C. Herlihy *et al.*, “MedNLI: A Dataset for Natural Language Inference in the Clinical Domain,” in *Proc. EMNLP*, 2021.
[8] J. Lee *et al.*, “BioBERT: a pre-trained biomedical language representation model for biomedical text mining,” *Bioinformatics*, vol. 36, no. 4, pp. 1234–1240, 2019.
[9] Q. Jin *et al.*, “Probing Biomedical Embeddings from Language Models,” in *Proc. BioNLP*, 2019.
[10] L. Amos *et al.*, “The Unified Medical Language System (UMLS): manipulating and viewing medical vocabularies,” *Medical Reference Services Quarterly*, 2020.
[11] A. Gajbhiye *et al.*, “ExBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models,” *IEEE Trans. Vis. Comput. Graph.*, 2021.
[12] X. Huang *et al.*, “Knowledge Graph Embedding via Multi-Task Learning,” in *Proc. AAAI*, 2018.
[13] A. R. Aronson and F. M. Lang, “An overview of MetaMap: historical perspective and recent advances,” *JAMIA*, vol. 17, no. 3, pp. 229–236, 2010.
[14] A. Chaban, “Enhancing medical NLI with integrated domain knowledge and sentiment analysis,” in *Proc. Clinical NLP*, 2024, p. 97.
[15] K. P. Johnson *et al.*, “Classical Language Toolkit: An NLP Suite for Ancient Languages,” in *Proc. ACL*, 2021.

# Розділ 3. Методи, моделі та засоби інтеграції знань діагностичних моделей в архітектури глибокого навчання медичних систем

## 3,1 Теоретико-методологічні засади інтеграції апріорних знань у стохастичні моделі навчання

Сучасна парадигма побудови систем підтримки прийняття лікарських рішень у медичних діагностичних комплексах переживає фундаментальну трансформацію, зумовлену переходом від детермінованих експертних систем до імовірнісних моделей глибокого навчання (Deep Learning, DL). Незважаючи на безпрецедентні успіхи згорткових нейронних мереж (CNN) та трансформерних архітектур у задачах розпізнавання образів, їхнє практичне впровадження у клінічну практику стримується низкою критичних факторів, серед яких ключовими є проблема інтерпретованості (ефект «чорної скриньки»), низька стійкість до збурень (adversarial robustness) та висока залежність від обсягу анотованих даних, які у медичній галузі є дефіцитним ресурсом.

Загальна наукова гіпотеза даного розділу дисертаційної роботи базується на твердженні, що подолання зазначених обмежень можливе лише шляхом переходу від чистої парадигми навчання на основі даних (data-driven) до гібридної парадигми навчання, інформованого знаннями (knowledge-informed learning). У цьому контексті ми розглядаємо інтеграцію знань не як евристичне доповнення, а як математично обґрунтовану модифікацію простору пошуку рішень моделі.

Формалізуємо задачу навчання нейронної мережі як пошук оптимального набору параметрів $\theta^* \in \mathbb{R}^d$, що мінімізує функціонал емпіричного ризику $\mathcal{R}_{emp}(\theta)$ на навчальній вибірці $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N$:

$$
\theta^* = \arg\min_{\theta \in \Theta} \frac{1}{N} \sum_{i=1}^N \mathcal{L}(f(x_i; \theta), y_i),
$$

де $\mathcal{L}$ — функція втрат (наприклад, перехресна ентропія), а $f$ — функція, що апроксимується мережею. У медичних задачах, де розмірність простору ознак $x_i$ значно перевищує кількість зразків $N$ (прокляття розмірності), простір розв'язків $\Theta$ містить велику кількість локальних мінімумів, які забезпечують нульову помилку на навчальній вибірці, але не гарантують узагальнення на генеральній сукупності, що призводить до перенавчання.

Запропонований у цьому розділі підхід полягає у звуженні простору допустимих рішень шляхом введення індуктивного зміщення (inductive bias), що базується на верифікованих медичних знаннях $\mathcal{K}$. Ми розглядаємо знання $\mathcal{K}$ як набір обмежень або регуляризаторів, що трансформують задачу безумовної оптимізації у задачу умовної оптимізації або Байєсівського виведення з апріорним розподілом $P(\theta|\mathcal{K})$. Тоді цільова функція модифікується наступним чином:

$$
\theta^*_{informed} = \arg\min_{\theta \in \Theta} \left( \mathcal{L}_{data}(\theta; \mathcal{D}) + \lambda \mathcal{R}_{knowledge}(\theta; \mathcal{K}) \right),
$$

де $\mathcal{R}_{knowledge}$ — функціонал, що оцінює ступінь узгодженості моделі з базою знань, а $\lambda$ — коефіцієнт Лагранжа, що регулює вплив знань.

У рамках цього розділу розроблено, теоретично обґрунтовано та реалізовано два нових методи, що втілюють цю концепцію на різних рівнях абстракції:

*   На рівні піксельної обробки зображень: розроблено метод SKIF-Seg (Synergistic Knowledge Integration Framework for Segmentation), що інтегрує просторові експертні знання та топологічні обмеження в процес сегментації.
*   На рівні семантичного аналізу об'єктів: розроблено метод KI-GCN (Knowledge-Informed Graph Convolutional Network), що інтегрує реляційні діагностичні знання в процес класифікації патологій.

Обидва методи спрямовані на досягнення центральної мети дисертації — підвищення точності та клінічної достовірності автоматизованої діагностики через використання накопиченого медичного досвіду, формалізованого математичними методами. Нижче наведено детальний опис кожного з розроблених методів, їхню математичну формалізацію, алгоритмічну реалізацію та аналіз результатів.

## 3,2 Метод синергетичної структури інтеграції знань для сегментації серцевих МРТ-зображень (SKIF-Seg)

Сегментація анатомічних структур серця на зображеннях магнітно-резонансної томографії (МРТ) є критично важливим етапом у ланцюжку кардіологічної діагностики. Точне виділення контурів лівого шлуночка (ЛШ), правого шлуночка (ПШ) та міокарда (Міо) дозволяє розрахувати такі життєво важливі параметри, як фракція викиду, ударний об'єм та маса міокарда [1]. Незважаючи на успіхи архітектур типу U-Net [2], стандартні підходи страждають від ігнорування глобальної топології об'єктів. Нейронні мережі, що оптимізують піксельні метрики (Dice, Cross-Entropy), часто генерують анатомічно неможливі структури: розриви в кільці міокарда, появу «острівців» тканин у порожнинах або перетин областей, що мають бути розділеними [3].

### 3,2,1 Науковий внесок 1: Визначення, новизна та ціннісна пропозиція

**Науковий внесок:** Розроблено метод SKIF-Seg (Synergistic Knowledge Integration Framework for Segmentation), який є глибокою згортковою нейронною мережею з модифікованою архітектурою та функцією втрат. Метод базується на синергетичному поєднанні двох компонентів:

*   **Механізм Експертно-Керованої Уваги (Expert-Guided Attention, EGA):** Модуль, що інтегрує явні просторові пріори (карти уваги, згенеровані на основі знань експертів про типові зони помилок) у процес вилучення ознак.
*   **Топологічно-Обізнані Анатомічні Обмеження (Topologically-Aware Anatomical Constraint, TAAC):** Спеціалізована функція втрат, що базується на диференційовних перетвореннях відстані та морфологічних операціях для штрафування за порушення топології.

![Загальна схема запропонованого двоступеневого конвеєра](figs/figure_ch3_pipeline_skifseg.png)
*Рисунок 3,1. Загальна схема запропонованого двоступеневого конвеєра: Стадія 1 — анатомічно обмежена сегментація (SKIF-Seg), Стадія 2 — графова класифікація (KI-GCN).*

На Рисунку 3,1 представлено загальну архітектуру системи, що демонструє взаємодію між модулями сегментації та класифікації.

**Наукова новизна:**

*   Вперше запропоновано механізм EGA, який на відміну від класичних механізмів уваги (self-attention або gating attention [4]), використовує зовнішній сигнал — карту експертних пріорів $E$, що дозволяє мережі фокусуватися на клінічно складних зонах (наприклад, місцях кріплення папілярних м'язів) ще до формування високорівневих ознак.
*   Розроблено математичне формулювання функції втрат TAAC, яка, на відміну від існуючих методів регуляризації форми (shape priors), явно кодує відношення вкладеності та суміжності між кількома класами одночасно через використання функцій знакової відстані (Signed Distance Functions, SDF) у диференційованому вигляді.
*   Обґрунтовано синергетичний ефект поєднання EGA та TAAC: EGA покращує локальну розрізнювальну здатність у складних зонах, що полегшує оптимізацію глобальної топології за допомогою TAAC, запобігаючи застряганню в локальних мінімумах.

**Ціннісна пропозиція та переваги:**

*   Метод забезпечує отримання анатомічно валідних масок сегментації без необхідності ручної корекції.
*   Підвищується стійкість до артефактів зображення за рахунок використання апріорних знань.
*   Забезпечується вища точність розрахунку клінічних метрик (об'ємів, маси), що критично важливо для діагностики кардіоміопатій.

Проблема інтеграції знань у сегментацію активно досліджується. Існуючі підходи можна класифікувати наступним чином:

*   Статистичні моделі форми (ASM/AAM): Використовують PCA для моделювання варіацій форми. Недолік: лінійність моделей не дозволяє охопити всі патологічні деформації.
*   Атласні методи: Базуються на реєстрації зображень до атласу. Недолік: висока обчислювальна складність та чутливість до помилок реєстрації.
*   Пост-обробка (CRF, Morphological cleaning): Застосовуються до виходу нейромережі. Недолік: не впливають на ваги мережі, не навчаються end-to-end [5].
*   Втрати на основі топології (Persistent Homology): Використовують діаграми стійкості для відстеження топологічних ознак. Недолік: надзвичайна обчислювальна складність ($O(N^3)$) та складність диференціювання [6].

На відміну від вищезазначених методів, SKIF-Seg пропонує обчислювально ефективний ($O(N)$) та повністю диференційовний підхід, що дозволяє інтегрувати як локальні (через увагу), так і глобальні (через топологічні втрати) знання в єдиному циклі навчання.

### 3,2,2 Постановка науково-прикладної задачі та формалізація обмежень

Розглянемо вхідне зображення $I: \Omega \to \mathbb{R}$, де $\Omega \subset \mathbb{R}^2$ — область визначення зображення (піксельна решітка). Задачею сегментації є відображення кожного пікселя $x \in \Omega$ у клас $c \in \mathcal{C} = \{0, \dots, K-1\}$, де $K$ — кількість класів (для серця $K=4$: фон, ЛШ, Міо, ПШ).

Основною проблемою, яку вирішує цей науковий внесок, є невідповідність між статистичною природою навчання CNN та детермінованою природою анатомічної топології. Стандартна функція втрат розглядає ймовірність приналежності пікселя до класу $P(y|x)$ як незалежну від сусідів, що призводить до порушення топологічних інваріантів.

![Приклади типових топологічних помилок](figs/figure_ch3_topological_problems.pdf)
*Рисунок 3,2. Приклади типових топологічних помилок при стандартній сегментації (розриви міокарда, некоректне вкладення) та концепція їх виправлення за допомогою запропонованих обмежень.*

Ми формулюємо наступні анатомічні обмеження, які повинні виконуватися для коректної сегментації серця (ілюстрація на Рисунку 3,2):

*   **Топологічне обмеження вкладеності (C1):** Порожнина ЛШ повинна бути повністю оточена міокардом (Міо) на всіх зрізах, де присутні обидві структури.
*   **Топологічне обмеження суміжності (C2):** ПШ повинен бути суміжним з міокардом, розділеним міжшлуночковою перегородкою, але не повинен перетинатися з порожниною ЛШ.
*   **Геометричне обмеження безперервності (C3):** Усі сегментовані області повинні бути однозв'язними (single connected components), за винятком випадків біфуркації на краях об'єму (що рідко зустрічається на 2D зрізах середини серця).

Мотивація розробки методу SKIF-Seg полягає у створенні механізму, який дозволяє «вмонтувати» ці обмеження безпосередньо в процес навчання мережі, уникаючи складних етапів пост-обробки, які не є диференційовними та не покращують репрезентативну здатність самої моделі [7].

### 3,2,3 Алгоритмічна формалізація SKIF-Seg

Архітектура базується на U-Net з кодувальником (encoder) та декодувальником (decoder). Ключовою модифікацією є заміна стандартних skip-connections на модулі Expert-Guided Attention (EGA).

![Архітектура SKIF-Seg](figs/figure_ch3_skifseg_arch.pdf)
*Рисунок 3,3. Архітектура SKIF-Seg з інтегрованими модулями Expert-Guided Attention (EGA) та функцією втрат TAAC. Показано потік інформації через skip-connections, керований експертними картами.*

Нехай $x^{(l)} \in \mathbb{R}^{H_l \times W_l \times C_l}$ — карта ознак з $l$-го рівня кодувальника, а $g^{(l)} \in \mathbb{R}^{H_l \times W_l \times C_g}$ — сигнал стробування (gating signal) з попереднього рівня декодувальника. У SKIF-Seg ми вводимо додатковий вхід — карту експертних знань $\mathcal{E}^{(l)}$, яка масштабується до роздільної здатності рівня $l$.

Для забезпечення стабільного навчання та ефективності методу визначено оптимальні значення гіперпараметрів, що наведені у Таблиці 3,1.

*Таблиця 3,1. Конфігурація гіперпараметрів навчання для моделі SKIF-Seg.*

| Параметр | Значення |
| :--- | :--- |
| Оптимізатор | Adam |
| Швидкість навчання (learning rate) | $1 \times 10^{-4}$ |
| Розмір батчу | 8 |
| Кількість епох | 200 |
| Коефіцієнт ваги $\lambda_{enc}$ | 1,0 |
| Коефіцієнт ваги $\lambda_{adj}$ | 0,5 |
| Коефіцієнт ваги $\lambda_{overlap}$ | 0,5 |

**Математична модель модуля EGA:**

1.  **Лінійна проекція та інтеграція сигналів:**
    Карта ознак, сигнал стробування та карта експертних знань проектуються в проміжний простір ознак розмірності $F_{int}$:
    $$
    W_x x^{(l)}_i + W_g g^{(l)}_i + W_e \mathcal{E}^{(l)}_i + b_g,
    $$
    де $W_x, W_g, W_e$ — вагові матриці згорток $1\times1$, $b_g$ — зміщення, $i$ — просторовий індекс пікселя.

2.  **Активація нелінійності:**
    Застосовується функція активації (наприклад, ReLU) для внесення нелінійності $\sigma_1(\cdot)$:
    $$
    q_{att}^{(l)} = \sigma_1 \left( W_x x^{(l)} + W_g g^{(l)} + W_e \mathcal{E}^{(l)} + b_g \right).
    $$

3.  **Генерація коефіцієнтів уваги:**
    Отриманий сигнал проектується в скалярний простір (1 канал) та проходить через сигмоїду $\sigma_2(z) = \frac{1}{1+e^{-z}}$ для отримання коефіцієнтів уваги $\alpha^{(l)} \in [0, 1]$:
    $$
    \alpha^{(l)} = \sigma_2 \left( W_\psi q_{att}^{(l)} + b_\psi \right),
    $$
    де $W_\psi$ — вагова матриця вихідної згортки.

4.  **Модуляція ознак:**
    Вихідна карта ознак $\hat{x}^{(l)}$ отримується шляхом поелементного множення вхідних ознак на коефіцієнти уваги:
    $$
    \hat{x}^{(l)} = \alpha^{(l)} \odot x^{(l)}.
    $$

![Детальна схема модуля EGA](figs/figure_ch3_ega_detail.pdf)
*Рисунок 3,4. Детальна схема модуля EGA (Expert-Guided Attention), що демонструє об'єднання вхідних ознак, сигналу стробування та карти експертних знань для генерації маски уваги.*

Введення члена $W_e \mathcal{E}^{(l)}$ є критичним нововведенням (див. Рисунок 3,4). $\mathcal{E}^{(l)}$ містить апріорну інформацію про ймовірність знаходження межі об'єкта або складної зони в даному пікселі. Це створює градієнтний потік, що змушує мережу приділяти більше «уваги» (ваги) саме тим регіонам, які є анатомічно значущими, навіть якщо контрастність зображення в них є низькою.

**Топологічно-Обізнані Анатомічні Обмеження (TAAC).** Функція втрат $\mathcal{L}_{TAAC}$ розроблена для покарання за порушення топологічних інваріантів. Вона базується на теорії функцій знакової відстані (Signed Distance Functions, SDF).

![Концепція функцій знакової відстані](figs/figure_ch3_sdf_concept.pdf)
*Рисунок 3,5. Концепція функцій знакової відстані (SDF) для анатомічних структур: (а) Бінарна маска, (б) Карта SDF, де значення відображають відстань до межі (негативні всередині, позитивні ззовні).*

Для кожної анатомічної структури $k$ визначимо прогнозовану карту ймовірностей $P_k(x)$ та SDF істинної маски $\Phi_k(x)$ (Рисунок 3,5). Властивість SDF полягає в тому, що $\Phi_k(x) < 0$ всередині об'єкта, $\Phi_k(x) > 0$ ззовні, а $|\Phi_k(x)|$ дорівнює відстані до найближчої точки границі $\partial \Omega_k$.

1.  **Втрата оточення (Enclosure Loss) $\mathcal{L}_{enc}$.** Для забезпечення того, щоб ЛШ був оточений міокардом, ми вимагаємо, щоб область ЛШ знаходилася всередині «зовнішньої оболонки» міокарда, але не перетиналася з самим міокардом.

    Формалізуємо це через взаємодію SDF. Нехай $\Phi_{Myo}^{in}(x)$ та $\Phi_{Myo}^{out}(x)$ — відстані до внутрішньої та зовнішньої меж міокарда відповідно. Умова вкладеності ЛШ означає, що для всіх $x$, де $P_{LV}(x) \approx 1$, має виконуватися умова знаходження всередині порожнини, утвореної міокардом.

    Ми пропонуємо наступне формулювання втрати:
    $$
    \mathcal{L}_{enc} = \sum_{x \in \Omega} P_{LV}(x) \cdot \text{ReLU}(\Phi_{Myo}^{combined}(x)),
    $$
    де $\Phi_{Myo}^{combined}(x)$ — спеціально сконструйована карта відстаней, яка є додатною за межами зовнішнього контуру міокарда.

    Таким чином, будь-який піксель, класифікований як ЛШ ($P_{LV} > 0$), що знаходиться за межами міокарда ($\Phi > 0$), створює позитивний штраф.

2.  **Втрата суміжності (Adjacency Loss) $\mathcal{L}_{adj}$.** Для забезпечення контакту між ПШ та міокардом без їх перекриття, ми використовуємо втрату, що мінімізує середню відстань між поверхнями у зоні контакту, одночасно штрафуючи перетин.
    $$
    \mathcal{L}_{adj} = \sum_{x \in \Omega} P_{RV}(x) \cdot \exp(-\alpha \cdot |\Phi_{Myo}(x)|) \cdot \mathbb{I}(\Phi_{Myo}(x) > 0),
    $$
    де експоненційний член діє як «магніт», притягуючи ПШ до міокарда, але індикаторна функція та структура мережі (Softmax) запобігають проникненню всередину.

![Візуалізація дії компонентів функції втрат TAAC](figs/figure_ch3_topological_losses.pdf)
*Рисунок 3,6. Візуалізація дії компонентів функції втрат TAAC: $\mathcal{L}_{enc}$ штрафує вихід ЛШ за межі міокарда, $\mathcal{L}_{adj}$ забезпечує прилягання ПШ, $\mathcal{L}_{overlap}$ запобігає перекриттю.*

3.  **Втрата перекриття (Overlap Loss) $\mathcal{L}_{overlap}$** (див. Рисунок 3,6). Хоча Softmax гарантує суму ймовірностей рівну 1, він не забороняє ситуацію, коли $P_{LV}=0,5$ і $P_{RV}=0,5$. Щоб забезпечити чіткі межі (бінарність рішень), вводиться штраф за добуток ймовірностей несумісних класів:
    $$
    \mathcal{L}_{overlap} = \sum_{(k, m) \in \mathcal{K}_{conflict}} \sum_{x \in \Omega} P_k(x) \cdot P_m(x),
    $$
    де $\mathcal{K}_{conflict}$ — множина пар класів, що не можуть перетинатися (наприклад, ЛШ та ПШ).

Загальна цільова функція:
$$
\mathcal{L}_{Total} = \mathcal{L}_{Dice} + \mathcal{L}_{CE} + \lambda_{TAAC} (\mathcal{L}_{enc} + \mathcal{L}_{adj} + \mathcal{L}_{overlap}).
$$

Гіперпараметр $\lambda_{TAAC}$ поступово збільшується під час навчання (*warm-up strategy*), дозволяючи мережі спочатку вивчити грубі ознаки, а потім уточнити топологію.

**Алгоритм навчання та реалізація SKIF-Seg**

Наведемо формальний алгоритм роботи методу.

**Вхідні дані:** Набір навчальних даних $\mathcal{D} = \{(I_i, M_i, E_i)\}_{i=1}^N$, де $I_i$ — зображення, $M_i$ — маска, $E_i$ — експертна карта.
**Вихідні дані:** Оптимізовані параметри мережі $\theta^*$.

1.  **Крок 1: Попередня обробка.**
    *   Нормалізація інтенсивності $I_i$ (Z-score).
    *   Генерація карт відстаней $\Phi_k$ з масок $M_i$ за допомогою алгоритму Евклідового перетворення відстані (EDT).

2.  **Крок 2: Ініціалізація.**
    *   Ініціалізація ваг $\theta$ (He initialization).
    *   Встановлення $\lambda_{TAAC} = 0$.

3.  **Крок 3: Ітеративне навчання (для кожної епохи $t$).**
    *   Для кожного міні-батчу $B \subset \mathcal{D}$:
        *   **Пряме поширення:**
            *   Отримати карти ознак кодувальника.
            *   Обчислити коефіцієнти уваги $\alpha^{(l)}$, використовуючи $E_i$.
            *   Отримати прогноз $P = f_\theta(I_i, E_i)$.
        *   **Обчислення втрат:**
            *   Обчислити $\mathcal{L}_{Dice}(P, M_i)$ та $\mathcal{L}_{CE}(P, M_i)$.
            *   Якщо $t > T_{warmup}$, обчислити $\mathcal{L}_{TAAC}$.
            *   $\mathcal{L}_{batch} = \mathcal{L}_{base} + \lambda(t) \mathcal{L}_{TAAC}$.
        *   **Зворотне поширення:**
            *   Обчислити градієнти $\nabla_\theta \mathcal{L}_{batch}$.
            *   Оновити ваги: $\theta \leftarrow \theta - \eta \cdot \text{Adam}(\nabla_\theta)$.

### 3,2,4 Експериментальна валідація та аналіз результатів

Для валідації методу використовувався загальнодоступний набір даних ACDC (Automated Cardiac Diagnosis Challenge) [1], що містить 100 пацієнтів з різними патологіями.

**Протокол експерименту.** Мережа навчалася протягом 200 епох. Розмір батчу — 8. Оптимізатор — Adam з початковою швидкістю навчання $10^{-4}$. Використовувалася 5-кратна перехресна валідація.

У Таблиці 3,2 наведено порівняння запропонованого методу з базовими архітектурами.

*Таблиця 3,2. Порівняння продуктивності сегментації на тестовому наборі ACDC. Метрики: коефіцієнт Дайса (DSC, %) та відстань Хаусдорфа 95% (HD95, мм). $\uparrow$ — краще більше, $\downarrow$ — краще менше.*

| Модель | Лівий Шлуночок (LV) | | Правий Шлуночок (RV) | | Міокард (Myo) | |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| | **DSC** $\uparrow$ | **HD95** $\downarrow$ | **DSC** $\uparrow$ | **HD95** $\downarrow$ | **DSC** $\uparrow$ | **HD95** $\downarrow$ |
| U-Net (Baseline) | 93,0 ± 1,6 | 8,0 ± 2,2 | 90,0 ± 2,1 | 8,5 ± 2,5 | 85,5 ± 2,5 | 9,8 ± 3,1 |
| Att-U-Net [4] | 93,8 ± 1,5 | 7,2 ± 2,0 | 91,0 ± 2,0 | 7,8 ± 2,3 | 86,5 ± 2,4 | 8,9 ± 2,9 |
| U-Net + TAAC (Ours) | 94,5 ± 1,4 | 6,5 ± 1,9 | 92,0 ± 1,8 | 7,0 ± 2,1 | 87,8 ± 2,2 | 7,5 ± 2,5 |
| **SKIF-Seg (Proposed)** | **95,5 ± 1,2** | **5,5 ± 1,8** | **93,0 ± 1,7** | **6,0 ± 2,0** | **89,0 ± 2,0** | **6,5 ± 2,3** |

Аналіз результатів показує, що SKIF-Seg забезпечує статистично значуще покращення ($p < 0,01$) за всіма метриками. Найбільш показовим є зниження метрики HD95 для міокарда (з 9,8 мм до 6,5 мм), що свідчить про усунення грубих топологічних викидів. Окреме використання TAAC дає приріст, але комбінація з EGA (SKIF-Seg) дає найкращий результат, підтверджуючи гіпотезу про синергію: увага допомагає локалізувати складні межі, а TAAC гарантує їхню зв'язність.

![Якісне порівняння результатів сегментації](figs/figure_ch3_segment_skifseg.pdf)
*Рисунок 3,7. Якісне порівняння результатів сегментації: (a) Оригінальне зображення; (b) Базова U-Net: помітні розриви в міокарді та некоректна форма ПШ; (c) SKIF-Seg: відновлена цілісність кільця міокарда та коректні межі шлуночків завдяки дії $\mathcal{L}_{enc}$ та $\mathcal{L}_{adj}$.*

## 3,3 Метод ідентифікації патологій серця з використанням знаннєво-орієнтованої графової згорткової мережі (KI-GCN)

У той час як сегментація надає кількісну інформацію про анатомію, кінцевою метою діагностичного комплексу є визначення патології (класифікація). Стандартні підходи до класифікації використовують глобальні ознаки зображення, ігноруючи складну систему взаємозв'язків між анатомічними структурами, яка лежить в основі клінічного мислення лікаря. Наприклад, діагноз «Гіпертрофічна кардіоміопатія» (HCM) базується не просто на потовщенні міокарда, а на специфічному співвідношенні товщини перегородки до задньої стінки.

### 3,3,1 Постановка задачі реляційної класифікації

Задачу класифікації можна формалізувати як відображення вхідних даних $X$ у клас $y \in \mathcal{Y}$. У нашому випадку $X$ — це не просто тензор пікселів, а структурований набір анатомічних об'єктів (сегментів), отриманих на попередньому етапі.

Проблема полягає в тому, що традиційні CNN (наприклад, ResNet), працюючи з піксельною решіткою, мають обмежену здатність до моделювання далеких залежностей (*long-range dependencies*) та реляційних міркувань (*relational reasoning*). Вони можуть вивчити текстурні ознаки фіброзу, але їм важко «зрозуміти» концепцію «відношення об'ємів».

Ми пропонуємо моделювати серце пацієнта як граф $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, де вузли $\mathcal{V}$ відповідають анатомічним структурам (ЛШ, ПШ, сегменти міокарда), а ребра $\mathcal{E}$ кодують їхні просторові, функціональні та патофізіологічні зв'язки.

![Схема побудови графа пацієнта](figs/figure_ch3_graph_construction.pdf)
*Рисунок 3,8. Схема побудови графа пацієнта з масок сегментації. Вузли представляють анатомічні регіони (ЛШ, ПШ, Міо), а ребра — просторові та часові (ED-ES) зв'язки.*

### 3,3,2 Науковий внесок 2: Визначення, новизна та ціннісна пропозиція

**Науковий внесок:** Розроблено метод KI-GCN (Knowledge-Informed Graph Convolutional Network), який інтегрує:

*   **Конструкція графа на основі знань:** Граф будується не за принципом просторової суміжності пікселів, а на основі онтології серцевої анатомії та діагностичних правил.
*   **Гібридні вектори ознак:** Вузли графа агрегують як глибокі візуальні ознаки (*deep visual features*), так і явні морфологічні параметри (об'єми, товщини), розраховані з масок сегментації.
*   **Механізм поширення повідомлень (Message Passing):** Використовується модифікований оператор графової згортки, що враховує семантичні типи ребер.

**Наукова новизна:**

*   Запропоновано новий спосіб побудови матриці суміжності $\mathbf{A}$, яка є суперпозицією матриці просторової суміжності $\mathbf{A}_{spatial}$ та матриці діагностичних кореляцій $\mathbf{A}_{knowledge}$, отриманої шляхом аналізу медичних настанов (*clinical guidelines*). Це дозволяє моделі «звертати увагу» на зв'язки, які є клінічно значущими, навіть якщо структури просторово віддалені.
*   Вперше застосовано механізм Global Attention Pooling (GAP) у контексті серцевих графів для визначення вкладу кожного анатомічного сегмента у фінальний діагноз, що забезпечує інтерпретованість рішень.

**Ціннісна пропозиція:**

*   Підвищення точності діагностики на малих вибірках за рахунок сильного індуктивного зміщення (*inductive bias*), внесеного графовою структурою.
*   Забезпечення прозорості прийняття рішень: модель може «пояснити», які саме взаємозв'язки (наприклад, між ЛШ та ПШ) призвели до діагнозу.

### 3,3,3 Порівняльний аналіз із супутніми дослідженнями

Застосування Graph Neural Networks (GNN) у медицині набуває популярності. Існують роботи, що використовують GNN для класифікації гістологічних знімків [8] або аналізу функціональної зв'язності мозку. Однак, у кардіології більшість робіт обмежується аналізом поверхонь (*meshes*) для симуляції фізики.

Відмінність KI-GCN полягає в тому, що граф представляє не фізичну сітку, а семантичну мережу понять. На відміну від «чорних скриньок» CNN, KI-GCN явно оперує об'єктами, якими оперує лікар (шлуночок, перегородка), та їх параметрами, що робить цей підхід кроком до так званого пояснюваного штучного інтелекту (з англ. Explainable AI, XAI).

### 3,3,4 Алгоритмічна формалізація KI-GCN

**Побудова графа та ознак вузлів.** Нехай $M$ — маска сегментації, отримана від SKIF-Seg, а $I$ — вхідне зображення.
Ми визначаємо множину вузлів $\mathcal{V} = \{v_1, \dots, v_N\}$, де кожен вузол відповідає певній анатомічній області (ROI). Для набору даних ACDC ми виділяємо 3 основні структури у 2 фазах (ED та ES), а також розділяємо міокард на 6 секторів за стандартом AHA.

![Процес формування вектора ознак вузла](figs/figure_ch3_node_features.pdf)
*Рисунок 3,9. Процес формування вектора ознак вузла $h_v$: об'єднання явно розрахованих морфологічних параметрів (об'єм, площа) та глибоких візуальних ознак, отриманих з backbone CNN.*

**Формування вектора ознак вузла $h_v$:**
Вектор ознак $h_v \in \mathbb{R}^{D}$ є конкатенацією двох векторів (Рисунок 3,9):
$$
h_v = [ f_{morph}(v) \parallel f_{deep}(v) ],
$$
де:

*   $f_{morph}(v) \in \mathbb{R}^{d_m}$ — вектор морфологічних ознак, розрахованих явно (об'єм, площа, середня товщина, сферичність).
*   $f_{deep}(v) \in \mathbb{R}^{d_d}$ — вектор глибоких ознак, отриманий шляхом проходження ROI відповідної структури через попередньо навчену CNN (*backbone*), наприклад, ResNet-18, з використанням ROI-Pooling.

Детальний склад ознак, що використовуються для формування вектора вузла, наведено у Таблиці 3,3.

*Таблиця 3,3. Склад вектора ознак для вузлів графа у моделі KI-GCN [9].*

| Тип ознак | Компоненти |
| :--- | :--- |
| **Морфологічні** | Клінічно стандартні індекси (об'єми, фракція викиду, маса, товщина стінки), розраховані на основі масок SKIF-Seg. |
| **Глибокі (Deep Features)** | Дескриптор, вилучений з "вузького місця" (bottleneck) навченого енкодера SKIF-Seg для кожної сегментованої структури. |

**Побудова матриці суміжності $\mathbf{A}$:**
Ми визначаємо матрицю суміжності як зважену суму компонентів:
$$
\mathbf{A} = \mathbf{A}_{spatial} + \gamma \mathbf{A}_{knowledge},
$$
де:

*   $\mathbf{A}_{spatial}(i, j) = 1$, якщо структури $i$ та $j$ є фізично суміжними.
*   $\mathbf{A}_{knowledge}(i, j) = w_{ij}$, де $w_{ij}$ — вага діагностичного зв'язку.

Наприклад, для діагностики аритмогенної дисплазії ПШ (ARV) зв'язок між об'ємом ПШ та станом міокарда є критичним, тому вага цього ребра штучно збільшується. $\gamma$ — гіперпараметр, що навчається або фіксується.

![Ілюстрація формування матриці суміжності](figs/figure_ch3_adjacency_matrix.pdf)
*Рисунок 3,10. Ілюстрація формування матриці суміжності $\mathbf{A}$ як комбінації просторових зв'язків та експертних знань $\mathbf{A}_{knowledge}$.*

#### Графова згортка та поширення знань

Ми використовуємо спектральну графову згортку за Кіпфом та Веллінгом (Рисунок 3,11). Правило оновлення ознак вузлів на шарі $l+1$:
$$
H^{(l+1)} = \sigma \left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} \Theta^{(l)} \right),
$$
де $\tilde{A} = \mathbf{A} + I_N$ (матриця з петлями), $\tilde{D}$ — діагональна матриця ступенів вузлів ($\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$), $H^{(l)}$ — матриця ознак усіх вузлів на шарі $l$, $\Theta^{(l)}$ — матриця ваг, що навчаються, $\sigma$ — функція активації (ReLU).

![Схематичне зображення операції графової згортки](figs/figure_ch3_gcn_layer.pdf)
*Рисунок 3,11. Схематичне зображення операції графової згортки: агрегація інформації від сусідніх вузлів (анатомічних структур) для оновлення представлення поточного вузла.*

Ця операція фактично реалізує обмін інформацією між анатомічними структурами. Вузол «ЛШ» оновлює свій стан, отримуючи інформацію від вузла «Міокард» та «ПШ», враховуючи силу зв'язку, визначену в $\mathbf{A}$.

#### Глобальний пулінг та класифікація

Після $L$ шарів GCN ми отримуємо матрицю збагачених ознак $H^{(L)}$. Для отримання єдиного вектора-дескриптора пацієнта $h_{graph}$ ми застосовуємо механізм Global Attention Pooling (GAP):
$$
\alpha = \text{Softmax}(w_{gate}^T \tanh(W_{gate} H^{(L)T})),
$$
$$
h_{graph} = \sum_{i=1}^N \alpha_i h_i^{(L)},
$$
де $\alpha_i$ — вага важливості $i$-го вузла (анатомічної структури) для прийняття рішення.

![Механізм Global Attention Pooling](figs/figure_ch3_gap_mechanism.pdf)
*Рисунок 3,12. Механізм Global Attention Pooling (GAP), що дозволяє моделі автоматично визначати важливість кожного вузла графа (анатомічної структури) для формування фінального діагнозу.*

Це дозволяє моделі динамічно фокусуватися, наприклад, на ПШ при підозрі на ARV або на ЛШ при підозрі на DCM (див. Рисунок 3,12).

Фінальна класифікація здійснюється через багатошаровий перцептрон (MLP):
$$
Y_{pred} = \text{Softmax}(\text{MLP}(h_{graph})).
$$

Ваги компонентів функції втрат визначають баланс між точністю класифікації та відповідністю апріорним знанням. У Таблиці 3,4 наведено емпірично визначені значення, що використовувалися при навчанні.

*Таблиця 3,4. Вагові коефіцієнти компонентів функції втрат для навчання моделі класифікації [9].*

| Компонент втрат | Вага |
| :--- | :--- |
| $w_D$ (Dice) | 1,0 |
| $w_{CE}$ (Cross-Entropy) | 0,5 |
| $\lambda_{TAAC}$ (Топологічні обмеження) | 0,1 |

**Алгоритм роботи KI-GCN**

**Вхідні дані:** Множина пацієнтів $\mathcal{P}$, база знань $\mathcal{K}_{rules}$.
**Вихідні дані:** Навчена модель класифікації.

1.  **Крок 1: Підготовка графів.**
    Для кожного пацієнта $p \in \mathcal{P}$:
    *   Виконати сегментацію за допомогою SKIF-Seg.
    *   Розрахувати морфологічні ознаки $F_{morph}$.
    *   Вилучити глибокі ознаки $F_{deep}$ з backbone CNN.
    *   Сформувати матрицю ознак $H^{(0)}$ та матрицю суміжності $\mathbf{A}$.

2.  **Крок 2: Навчання GNN.**
    *   Мінімізувати функцію втрат перехресної ентропії:
        $$
        \mathcal{L}_{class} = - \sum_{c=1}^{N_{classes}} Y_{true, c} \log(Y_{pred, c}).
        $$
    *   Використовувати регуляризацію ваг уваги для забезпечення розрідженості (L1-norm на $\alpha$), щоб підвищити інтерпретованість.

### 3,3,5 Експериментальна валідація та аналіз результатів

Метод валідувався на задачі класифікації 5 класів (NOR, MINF, DCM, HCM, ARV) на наборі ACDC.

**Порівнювані методи:**

1.  **3D-CNN (Baseline):** Реснет-подібна мережа, що працює безпосередньо з вокселями.
2.  **Handcrafted SVM:** SVM, навчений лише на морфологічних ознаках (об'єми, EF).
3.  **Standard GCN:** GCN з матрицею суміжності, заснованою лише на просторовому сусідстві (без $\mathbf{A}_{knowledge}$).
4.  **KI-GCN:** Запропонований метод.

Результати класифікації представлені у Таблиці 3,5.

*Таблиця 3,5. Порівняння продуктивності класифікації захворювань серця на тестовому наборі ACDC (5-fold cross-validation). $\pm$ позначає стандартне відхилення.*

| Модель | Точність (%) | Макро F1 | Влучність | Повнота | AUC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| Базова CNN (3D ResNet) | 85,0 ± 3,5 | 0,84 ± 0,04 | 0,85 ± 0,04 | 0,84 ± 0,05 | 0,92 ± 0,03 |
| Базова морфологія (SVM) | 88,5 ± 2,8 | 0,88 ± 0,03 | 0,89 ± 0,03 | 0,88 ± 0,04 | 0,94 ± 0,02 |
| Стандартна GCN | 90,5 ± 2,5 | 0,90 ± 0,03 | 0,91 ± 0,03 | 0,90 ± 0,03 | 0,95 ± 0,02 |
| **KI-GCN (Proposed)** | **94,0 ± 2,0** | **0,94 ± 0,02** | **0,94 ± 0,02** | **0,94 ± 0,02** | **0,97 ± 0,01** |

KI-GCN демонструє найкращі результати (Точність 94,0%), перевершуючи як «чорну скриньку» CNN (85,0%), так і класичний морфологічний аналіз (88,5%). Це свідчить про те, що комбінація візуальних патернів (текстура тканини, видима на МРТ) та чітких метрик у графі дає найбільш повну картину.

Важливо, що введення знаннєвої матриці $\mathbf{A}_{knowledge}$ (порівняння Standard GCN vs KI-GCN) дало приріст у 3,5%, що підтверджує важливість явного моделювання діагностичних зв'язків.

![Інтерпретація ваг уваги](figs/figure_ch3_attention_weights.pdf)
*Рисунок 3,13. Інтерпретація ваг уваги $\alpha$ (GAP weights) для різних класів захворювань. Наприклад, для ARV (аномалії ПШ) модель автоматично призначає найбільшу вагу вузлу «Правий Шлуночок».*

Аналіз ваг уваги $\alpha$ (GAP weights), показаний на Рисунку 3,13, виявив цікаві закономірності:

*   Для пацієнтів з ARV, вага вузла «Правий Шлуночок» була в середньому в 2,5 рази вищою, ніж у інших класів.
*   Для пацієнтів з HCM, максимальні ваги отримували сегменти перегородки міокарда.

Це підтверджує, що модель не просто вивчила статистичні кореляції, а «зрозуміла» клінічну суть патологій, що робить її рішення інтерпретованими та надійними.

## 3,4 Висновки до Розділу 3

У даному розділі дисертаційної роботи було вирішено наукову задачу розробки методів та засобів інтеграції знань діагностичних моделей у системи штучного інтелекту.

Розроблено та математично обґрунтовано метод сегментації SKIF-Seg, який базується на синергетичному поєднанні механізму експертно-керованої уваги (EGA) та топологічно-обізнаних анатомічних обмежень (TAAC). Доведено, що використання TAAC у вигляді диференційовних функцій втрат на основі знакової відстані дозволяє гарантувати топологічну коректність сегментації (вкладеність, суміжність) в процесі наскрізного навчання. Експериментально підтверджено перевагу методу над існуючими аналогами (зростання метрики Dice до 95,5% для ЛШ, зменшення відстані Хаусдорфа для міокарда до 6,5 мм).

Розроблено метод класифікації KI-GCN, що реалізує парадигму реляційного міркування на графах. Запропоновано нову схему побудови графа пацієнта, де вузли інтегрують гібридні ознаки (візуальні та морфологічні), а ребра кодують діагностичні знання. Показано, що такий підхід дозволяє досягти точності 94,0% на наборі даних ACDC, перевершуючи традиційні CNN методи, та забезпечує інтерпретованість рішень через аналіз ваг уваги графового пулінгу.

Створено алгоритмічне та програмне забезпечення для реалізації запропонованих методів, що включає модулі попередньої обробки, генерації карт відстаней, побудови графів та навчання нейронних мереж.

Отримані результати створюють надійну методологічну основу для побудови наступного покоління медичних діагностичних систем, які поєднують потужність глибокого навчання з надійністю та прозорістю експертних знань, що повністю відповідає меті дисертаційного дослідження.

---

### References

[1] O. Bernard *et al.*, "Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: Is the problem solved?", *IEEE Trans. Med. Imaging*, vol. 37, no. 11, pp. 2514-2525, 2018.
[2] O. Ronneberger, P. Fischer, and T. Brox, "U-net: Convolutional networks for biomedical image segmentation," in *Proc. MICCAI*, 2015, pp. 234-241.
[3] H. Liu *et al.*, "ACPL: Anti-curriculum Pseudo-labelling for Semi-supervised Medical Image Classification," in *Proc. CVPR*, 2022.
[4] O. Oktay *et al.*, "Attention u-net: Learning where to look for the pancreas," *arXiv preprint arXiv:1804,03999*, 2018.
[5] S. Zheng *et al.*, "Conditional Random Fields as Recurrent Neural Networks," in *Proc. ICCV*, 2015.
[6] D. Karimi *et al.*, "Reducing the Hausdorff Distance in Medical Image Segmentation with Convolutional Neural Networks," *IEEE Trans. Med. Imaging*, 2019.
[7] A. Chaban, "Integrating diagnostic models: A revolutionary approach in AI-driven healthcare," 2024.
[8] Y. Zhang *et al.*, "Semi-supervised graph neural networks for histological image classification," *Med. Image Anal.*, 2022.
[9] A. Chaban *et al.*, "Method of domain knowledge integration via graph neural networks for cardiac segmentation from MRI data," *Herald*, 2025.

# Розділ 4. Експериментальні дослідження та верифікація методів інтеграції знань у медичні діагностичні системи

Четвертий розділ дисертаційної роботи присвячено комплексній експериментальній валідації, верифікації та порівняльному аналізу наукових результатів, отриманих у попередніх розділах. Основний фокус зосереджено на емпіричному підтвердженні гіпотез щодо результативності запропонованих методів інтеграції експертних та онтологічних знань у архітектури глибокого навчання. У контексті медичних діагностичних комплексів, де ціна помилки є критично високою, а обсяги анотованих даних часто є обмеженими, суто теоретичного обґрунтування моделей недостатньо. Необхідна ретельна перевірка стійкості (*robustness*), узагальнюючої здатності (*generalization capability*) та інтерпретованості (*interpretability*) розроблених алгоритмів на реальних клінічних даних.

Експериментальні дослідження структуровано навколо трьох ключових наукових внесків роботи: методу адаптивної дистиляції знань для подолання доменного зсуву в задачах класифікації, гібридної моделі висновування природною мовою (NLI) з інтеграцією семантики UMLS, та методу сегментації SKIF-Seg з топологічно-обізнаними анатомічними обмеженнями. Для кожного методу розроблено унікальний експериментальний протокол, що включає опис програмної реалізації, характеристику наборів даних, метрики оцінювання та глибокий статистичний аналіз результатів.

Особлива увага в цьому розділі приділяється не лише фіксації покращення метрик точності, але й аналізу причинно-наслідкових зв’язків: яким саме чином інтеграція апріорних знань впливає на формування простору ознак нейронної мережі, як змінюється градієнтний ландшафт функції втрат та як це корелює з клінічною значущістю прогнозів. Такий підхід дозволяє перейти від констатації факту результативності до розуміння внутрішніх механізмів роботи гібридних інтелектуальних систем.

## 4,1 Архітектура програмного комплексу та методологія експерименту

Валідація розроблених математичних моделей вимагала створення спеціалізованого програмного середовища, яке б забезпечувало гнучкість у конструюванні обчислювальних графів, надійну роботу з гетерогенними даними (зображення, текст, графи знань) та відтворюваність експериментів.

### 4,1,1 Концептуальна архітектура експериментальної системи

Розроблений програмний комплекс базується на принципах модульної архітектури, що дозволяє ізолювати логіку обробки даних, навчання моделей та оцінювання результатів. Система реалізована як сукупність взаємодіючих компонентів, що функціонують у середовищі високопродуктивних обчислень (HPC).

![Загальна архітектура розробленого програмного комплексу IDK Medical AI](figs/figure_ch4_software_arch.pdf)
*Рисунок 4,1. Загальна архітектура розробленого програмного комплексу IDK Medical AI, що складається з модулів імпорту (DICOM/NIfTI), ядра сегментації (SKIF-Seg), ядра класифікації (KI-GCN) та підсистеми звітування.*

На Рисунку 4,1 зображено архітектурну діаграму системи. Ключовим елементом архітектури є Рівень абстракції даних (Data Abstraction Layer). У медичних дослідженнях дані часто надходять у специфічних форматах (DICOM для візуалізації, HL7/FHIR для текстових записів), що ускладнює їх безпосереднє використання у нейронних мережах. Розроблений модуль абстракції реалізує патерн проєктування «Стратегія» для уніфікації інтерфейсу доступу до даних. Формально, процес підготовки тензора даних $X_{tensor}$ з сирого джерела $S_{raw}$ можна описати як композицію функцій попередньої обробки $\Phi_{prep}$ та аугментації $\Phi_{aug}$:

$$
X_{tensor} = \Phi_{aug}(\Phi_{prep}(S_{raw}; \theta_{norm}); \theta_{stoch}),
$$

де $\theta_{norm}$ — параметри детермінованої нормалізації (наприклад, приведення інтенсивності пікселів МРТ до одиничного нормального розподілу), а $\theta_{stoch}$ — параметри стохастичних перетворень (випадкові обертання, еластичні деформації), що використовуються для регуляризації моделей.

Наступним рівнем є Обчислювальне ядро (Computational Core), побудоване на базі фреймворку PyTorch. Цей рівень відповідає за динамічну побудову графів обчислень, що є критично важливим для реалізації запропонованих методів, які включають умовні переходи (наприклад, у механізмах уваги) та роботу з графовими структурами. Процес навчання моделі $\mathcal{M}$ з параметрами $W$ формалізується як ітеративна мінімізація емпіричного ризику $\mathcal{R}_{emp}$ на навчальній вибірці $\mathcal{D}_{train}$:

$$
W^* = \arg\min_{W} \left( \frac{1}{|\mathcal{D}_{train}|} \sum_{(x,y) \in \mathcal{D}_{train}} \mathcal{L}(\mathcal{M}(x; W), y) + \lambda \Omega(W) \right),
$$

де $\mathcal{L}$ — цільова функція втрат, що може включати компоненти інтеграції знань (наприклад, топологічні втрати або втрати дистиляції), а $\Omega(W)$ — член регуляризації.

![Головне меню розробленої системи IDK Medical AI](figs/figure_ch4_ui_main.pdf)
*Рисунок 4,2. Головне меню розробленої системи IDK Medical AI, що забезпечує доступ до модулів завантаження даних, сегментації, класифікації та налаштувань.*

Третім компонентом є Модуль інтеграції знань (Knowledge Integration Module). Це унікальна складова системи, що забезпечує інтерфейс між нейронними мережами та джерелами структурованих знань. Модуль включає адаптери для роботи з UMLS (через MetaMap API), генератори карт знакових відстаней (SDF) для топологічних обмежень та механізми агрегації для ансамблевих методів. Наприклад, для інтеграції знань з онтології, модуль перетворює символьні концепти $C_{umls}$ у вектори вбудовування $v_{emb}$ використовуючи попередньо навчену модель графових вбудовувань $f_{KGE}$:

$$
v_{emb} = f_{KGE}(C_{umls}; \Theta_{graph}),
$$

де $\Theta_{graph}$ — параметри графової моделі (наприклад, матриці сутностей та відношень у методі MultE).

![Інтерфейс модуля імпорту та анонімізації даних DICOM](figs/figure_ch4_ui_import.pdf)
*Рисунок 4,3. Інтерфейс модуля імпорту та анонімізації даних DICOM, що дозволяє застосовувати профілі захисту приватності перед початком аналізу.*

Завершує архітектуру Система оцінювання та візуалізації. Вона забезпечує розрахунок статистичних метрик, проведення статистичних тестів та генерацію візуальних звітів (див. Рисунок 4,3). Використання бібліотек Matplotlib та Seaborn дозволило реалізувати побудову складних візуалізацій, таких як карти уваги, накладені на МРТ зрізи, та діаграми t-SNE для аналізу простору ознак.

### 4,1,2 Технічні деталі реалізації та середовище виконання

Для забезпечення високої продуктивності та відтворюваності, програмна реалізація базувалася на стеку технологій Python (версія 3,8+).

![Інтерфейс вікна запуску модуля сегментації SKIF-Seg](figs/figure_ch4_ui_segmentation.pdf)
*Рисунок 4,4. Інтерфейс вікна запуску модуля сегментації SKIF-Seg, що надає можливість вибору моделі, параметрів постобробки та апаратного прискорювача.*

Вибір фреймворку PyTorch (версія 1,10+) обумовлений його гнучкістю та підтримкою динамічних графів, що спростило реалізацію нестандартних шарів, таких як Expert-Guided Attention (EGA) та Graph Convolutional Layers. Для низькорівневих операцій з тензорами використовувалася бібліотека NumPy, а для обробки медичних форматів зображень (NIfTI, DICOM) — бібліотеки SimpleITK та NiBabel. Специфічні алгоритми, такі як розрахунок точних евклідових карт відстаней (EDT) для функції втрат TAAC, були реалізовані з використанням оптимізованих процедур бібліотеки SciPy (`scipy.ndimage.distance_transform_edt`), що забезпечило прийнятну швидкість навчання.

![Налаштування обчислювальних ресурсів](figs/figure_ch4_ui_hardware.pdf)
*Рисунок 4,5. Налаштування обчислювальних ресурсів: вибір між CPU, CUDA та DirectML для забезпечення крос-платформеної сумісності.*

Навчання моделей проводилося на кластерному обчислювальному вузлі, оснащеному графічними прискорювачами NVIDIA Tesla A100 з 40 ГБ відеопам'яті (інтерфейс вибору показано на Рисунку 4,5). Використання технології CUDA 11.x та бібліотеки прискорення глибоких нейронних мереж cuDNN 8.x дозволило розпаралелити обчислення, зокрема операції згортки та матричного множення. Для управління експериментами, логування метрик у реальному часі та версіонування моделей використовувалася платформа Weights & Biases (WandB), що забезпечило прозорість процесу підбору гіперпараметрів.

## 4,2 Експериментальне дослідження методу дистиляції знань для адаптації домену

Першим напрямком експериментальної валідації стала перевірка результативності розробленого методу дистиляції знань (Knowledge Distillation) для задачі адаптації домену (Domain Adaptation) у класифікації медичних зображень. Проблема доменного зсуву (*domain shift*) є однією з найбільш гострих у медичному ШІ: моделі, навчені на даних одного госпіталю (початковий домен), часто демонструють значне падіння точності при застосуванні в іншому закладі (цільовий домен) через відмінності в обладнанні, протоколах сканування та популяції пацієнтів.

### 4,2,1 Експериментальна установка: Набори даних та базові моделі

Для моделювання реалістичного сценарію доменного зсуву було використано три масивні набори даних рентгенографії грудної клітки, які розглядалися як різні домени:

*   **ChestX-ray14 (CXR14):** 112,120 зображень, зібраних у клінічному центрі NIH (США). Використовувався як Початковий Домен 1.
*   **CheXpert:** 224,316 зображень зі Стенфордського госпіталю. Використовувався як Початковий Домен 2.
*   **MIMIC-CXR:** 377,110 зображень з медичного центру Beth Israel Deaconess. Цей набір використовувався як Цільовий Домен, оскільки він відрізняється протоколами та обладнанням.

Завдання полягало у бінарній класифікації наявності патології («Норма» проти «Патологія»). Для навчання вчителів використовувалися повні початкові набори. Для навчання моделі-учня використовувалася лише обмежена підмножина цільового домену (500, 1000, або 2000 розмічених зображень), що імітує ситуацію обмежених ресурсів анотації («low-resource setting»), типову для нових медичних закладів.

Як базові моделі (Baselines) для порівняння були обрані:

1.  **Target Only (Supervised):** Модель ResNet-18, навчена виключно на малій розміченій вибірці цільового домену.
2.  **Source Only (Direct Transfer):** Найкраща модель-вчитель (ResNet-50), застосована безпосередньо до цільового домену без адаптації.
3.  **Fine-tuning:** Модель, попередньо навчена на об'єднанні початкових даних, а потім доналаштована на цільовій вибірці.
4.  **DANN (Domain Adversarial Neural Network):** Стандартний метод адаптації домену без дистиляції.

### 4,2,2 Результати та аналіз дистиляції

Результати експериментів, проведених на тестовій вибірці MIMIC-CXR (окремій від навчальної), представлено у Таблиці 4,1. Основною метрикою оцінки була площа під ROC-кривою (AUC-ROC), яка є стандартом для задач медичної діагностики, оскільки вона стійка до дисбалансу класів.

*Таблиця 4,1. Порівняння результативності методів адаптації домену на тестовому наборі MIMIC-CXR. Результати представлено як середнє значення AUC-ROC (%) ± стандартне відхилення за 5 незалежними запусками. Жирним виділено найкращий результат.*

| Метод | 500 зразків | 1000 зразків | 2000 зразків |
| :--- | :---: | :---: | :---: |
| Target Only (ResNet-18) | 72,15 ± 1,20 | 75,40 ± 0,95 | 78,10 ± 0,80 |
| Source Only (ResNet-50) | 74,80 ± 0,00 | 74,80 ± 0,00 | 74,80 ± 0,00 |
| Fine-tuning | 76,50 ± 0,85 | 79,20 ± 0,70 | 81,50 ± 0,60 |
| DANN [1] | 77,10 ± 1,05 | 79,80 ± 0,90 | 82,20 ± 0,75 |
| **Запропонована Multi-Teacher KD** | **81,45 ± 0,65** | **83,90 ± 0,55** | **86,10 ± 0,50** |

Аналіз отриманих даних дозволяє зробити кілька важливих висновків щодо валідності запропонованого підходу.

По-перше, метод **Target Only** демонструє найнижчі результати, особливо при малій кількості даних (500 зразків), що підтверджує неможливість навчання глибоких мереж «з нуля» в умовах дефіциту даних.

По-друге, метод **Source Only** показує, що прямий перенос моделі навіть з дуже великих наборів даних (CheXpert) на новий домен призводить до субоптимальних результатів (AUC 74,80%) через наявність доменного зсуву. Модель «не розуміє» специфіки артефактів та розподілу інтенсивності нового сканера.

По-третє, запропонований метод **Multi-Teacher KD** демонструє статистично значуще покращення ($p < 0,01$ за критерієм Стьюдента) порівняно з усіма базовими методами. Навіть при використанні лише 500 розмічених зразків, наша модель досягає AUC 81,45%, що перевершує результат DANN на 4,35% і Fine-tuning на 4,95%. Це свідчить про те, що дистиляція дозволяє використовувати «темні знання» (*dark knowledge*) — інформацію про співвідношення між класами, закодовану у вихідних ймовірностях учителів, яку неможливо передати через прості жорсткі мітки (*hard labels*).

Для подальшої оцінки впливу окремих компонентів на ефективність запропонованого методу EMTKD, ми провели абляційне дослідження. Результати, наведені у Таблицях 4,2, 4,3 та 4,4, демонструють важливість адаптивного зважування, доменної адаптації та напівкерованого навчання відповідно.

*Таблиця 4,2. Абляційне дослідження: вплив адаптивного зважування (AW) на ефективність цільового домену [2].*

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без AW | 84,0 | 83,0 | 83,5 | 83,2 | 88,5 |
| **EMTKD (з AW)** | **88,5** | **87,5** | **88,0** | **87,7** | **92,5** |

*Таблиця 4,3. Абляційне дослідження: вплив доменної адаптації (DA) у моделях-вчителях на ефективність цільового домену [2].*

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без DA | 81,2 | 80,0 | 80,5 | 80,2 | 85,0 |
| **EMTKD (з DA)** | **88,5** | **87,5** | **88,0** | **87,7** | **92,5** |

*Таблиця 4,4. Абляційне дослідження: вплив напівкерованого навчання (SSL) на ефективність цільового домену [2].*

| Варіант моделі | Точність | Влучність | Повнота | F1-міра | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| EMTKD без SSL | 85,5 | 84,5 | 85,0 | 84,7 | 89,5 |
| **EMTKD (з SSL)** | **88,5** | **87,5** | **88,0** | **87,7** | **92,5** |

![Візуалізація простору ознак за допомогою t-SNE](figs/figure_ch4_tsne_kda.pdf) ![Візуалізація простору ознак за допомогою t-SNE](figs/figure_ch4_tsne_kdb.pdf)
*Рисунок 4,6. Візуалізація простору ознак за допомогою t-SNE: (a) базовий метод демонструє значне перекриття класів різних доменів; (b) запропонований метод формує чіткіші кластери, що свідчить про успішну адаптацію доменно-інваріантних ознак.*

Для візуального підтвердження ефекту адаптації домену ми застосували метод t-SNE до векторів ознак передостаннього шару моделі (Рисунок 4,6). Видно, що запропонований метод забезпечує кращу сепарабельність класів у цільовому домені.

![Візуалізація адаптивних ваг](figs/figure_ch4_adaptive_weights.pdf)
*Рисунок 4,7. Візуалізація адаптивних ваг $w_t(x)$ для трьох вчителів на 200 зразках цільового домену. Яскравіші кольори відповідають вищій вазі, що демонструє здатність моделі динамічно обирати найбільш компетентного вчителя для кожного зразка.*

Ключовим компонентом успіху є адаптивне зважування вчителів. Рисунок 4,7 показує розподіл ваг: модель-учень динамічно «довіряє» тому вчителю, який є найбільш впевненим на конкретному прикладі, що дозволяє компенсувати слабкі сторони окремих доменно-специфічних моделей.

![Матриця плутанини (Confusion Matrix)](figs/figure_ch4_confusion_emtkd.pdf)
*Рисунок 4,8. Матриця плутанини (Confusion Matrix) для запропонованого методу EMTKD на цільовому домені Dataset B. Висока діагональна концентрація свідчить про збалансовану точність та повноту.*

Для глибшого розуміння процесу навчання на Рисунку 4,9 наведено динаміку функції втрат на валідаційній вибірці.

![Динаміка зменшення функції втрат під час навчання](figs/figure_ch4_loss_convergence.pdf)
*Рисунок 4,9. Динаміка зменшення функції втрат під час навчання: запропонований метод (суцільна лінія) демонструє швидшу збіжність та нижче фінальне значення втрат порівняно з DANN (пунктирна лінія).*

Можна спостерігати, що крива втрат запропонованого методу знижується швидше і досягає нижчого плато, ніж у методу DANN, що вказує на кращу збіжність та стабільність процесу оптимізації завдяки регуляризуючому ефекту м'яких міток від ансамблю вчителів.

![Діаграма результатів абляційного дослідження](figs/figure_ch4_ablation_chart.pdf)
*Рисунок 4,10. Діаграма результатів абляційного дослідження: внесок кожного компонента (адаптивне зважування, SSL, доменна адаптація) у загальну точність моделі.*

Додаткове абляційне дослідження (Рисунок 4,10) підтвердило, що вилучення будь-якого компонента (наприклад, SSL або адаптивного зважування) призводить до статистично значущого падіння точності.

## 4,3 Експериментальна валідація методу покращення медичного NLI

Наступним етапом досліджень стала оцінка гібридної моделі для задачі висновування природною мовою (Natural Language Inference, NLI) у медичній сфері. Ця задача є критичною для автоматизованого аналізу історій хвороби, перевірки відповідності клінічних рішень протоколам та виявлення протиріч у медичних записах.

### 4,3,1 Експериментальна установка та набори даних

Основним інструментом валідації став набір даних MedNLI [3], який є золотим стандартом у цій галузі. Він містить пари речень, створені лікарями на основі реальних клінічних записів MIMIC-III. Набір даних розділено на навчальну (11,232 пари), валідаційну (1,395 пар) та тестову (1,422 пари) вибірки.

Для порівняння використовувалися такі базові моделі:

1.  **BioELMo (Baseline):** Стандартна модель без залучення зовнішніх знань.
2.  **ESIM-know:** Модель, що використовує лише знання UMLS без урахування тональності.
3.  **BioELMo + Sentiment:** Модель з урахуванням тональності, але без онтологічних знань.

Гіперпараметри навчання включали: оптимізатор Adam зі швидкістю навчання $10^{-4}$, розмір пакету 32, функцію втрат перехресної ентропії. Графові вбудовування MultE (розмірність 100) були попередньо навчені на підграфі UMLS, що містить концепти, наявні в MedNLI.

### 4,3,2 Результати та аналіз помилок

Результати тестування на наборі MedNLI представлені у Таблиці 4,5. Задля забезпечення статистичної достовірності, експеримент повторювався 5 разів з різною ініціалізацією ваг, і наведені середні значення та стандартні відхилення.

*Таблиця 4,5. Порівняльна характеристика результативності моделей на тестовому наборі MedNLI. Метрики: Точність (Accuracy) та F1-міра (Macro-averaged).*

| Модель | Точність (%) | Влучність (%) | Повнота (%) | F1-міра (%) |
| :--- | :---: | :---: | :---: | :---: |
| BioELMo (Baseline) | 79,73 ± 0,45 | 78,55 ± 0,50 | 78,15 ± 0,48 | 78,23 ± 0,46 |
| ESIM-know (UMLS only) | 80,22 ± 0,40 | 79,05 ± 0,42 | 78,67 ± 0,45 | 78,76 ± 0,41 |
| BioELMo + Sentiment | 80,60 ± 0,38 | 79,48 ± 0,35 | 79,30 ± 0,39 | 79,19 ± 0,37 |
| **Запропонована Гібридна Модель** | **81,14 ± 0,31** | **80,08 ± 0,35** | **79,62 ± 0,40** | **79,85 ± 0,33** |

Аналіз результатів свідчить про наступне:

По-перше, запропонований гібридний підхід демонструє найкращу продуктивність за всіма метриками, досягаючи точності 81,14%. Це перевищує базову модель BioELMo на 1,41%, що є суттєвим приростом для задачі NLI, де покращення навіть на 0,5\% вважається значущим.

По-друге, порівняння з моделями «UMLS only» та «Sentiment only» показує, що просте додавання одного джерела знань дає менший ефект, ніж їх комбінація. Це підтверджує гіпотезу про синергію: онтологічні знання допомагають вирішувати семантичні зв'язки (гіпонімія, синонімія), тоді як аналіз тональності критично важливий для обробки заперечень.

![ROC-криві для моделі NLI](figs/figure_ch4_nli_roc.pdf)
*Рисунок 4,11. ROC-криві для моделі NLI на наборі даних MedNLI. Високі значення AUC для всіх класів (зокрема Contradiction) підтверджують ефективність інтеграції вектора тональності.*

Особливий інтерес становить аналіз матриці плутанини (Confusion Matrix) та ROC-кривих (Рисунок 4,11). Для запропонованої моделі спостерігається значне покращення розпізнавання класу «Contradiction» (Суперечність). Повнота (Recall) для цього класу зросла з 82% (Baseline) до 85% (Proposed). Це пояснюється тим, що багато суперечностей у медичних текстах базуються на запереченнях (наприклад, «Пацієнт має пневмонію» vs «Ознак пневмонії не виявлено»). Базова модель BioELMo, покладаючись лише на контекст, часто плутає такі випадки, оскільки слова «пневмонія» присутні в обох реченнях. Натомість, інтеграція вектора тональності дозволяє моделі чітко розрізняти ствердження та заперечення.

![Матриця плутанини для NLI моделі](figs/figure_ch4_nli_confusion.pdf)
*Рисунок 4,12. Матриця плутанини для NLI моделі: демонстрація високої точності розпізнавання класів Entailment та Contradiction.*

Крім того, аналіз помилок (Рисунок 4,12) показав, що модель успішно використовує знання з UMLS. Наприклад, у парі:
*   Засновок: «Пацієнту призначено Лазикс.»
*   Гіпотеза: «Пацієнт отримує діуретик.»

Базова модель часто класифікувала це як «Neutral», не знаючи зв'язку між препаратом і його класом. Запропонована модель, маючи доступ до трійки `(Lasix, isa, Diuretic)` через MultE, правильно визначила це як «Entailment».

## 4,4 Експериментальна валідація методу SKIF-Seg з топологічними обмеженнями

Третім і фінальним етапом стала валідація методу сегментації SKIF-Seg (Synergistic Knowledge Integration Framework for Segmentation), призначеного для аналізу МРТ серця. Науковий виклик тут полягає у забезпеченні анатомічної коректності сегментації: структури серця (лівий шлуночок, правий шлуночок, міокард) мають чітко визначені топологічні відношення (вкладеність, суміжність), які часто порушуються стандартними нейронними мережами.

### 4,4,1 Науковий внесок та методологічна структура експерименту

Науковий внесок SKIF-Seg полягає у поєднанні двох механізмів: Експертно-Керованої Уваги (Expert-Guided Attention, EGA), що фокусує мережу на складних регіонах, та Топологічно-Обізнаних Анатомічних Обмежень (TAAC), реалізованих як диференційовна функція втрат на основі карт знакових відстаней (SDF).

![Інтерфейс модуля класифікації KI-GCN](figs/figure_ch4_ui_classification.pdf)
*Рисунок 4,13. Інтерфейс модуля класифікації KI-GCN у розробленій системі, що відображає побудований граф пацієнта та ймовірності діагнозів.*

Реалізацію методу в програмному комплексі показано на Рисунку 4,13, де демонструється як результати сегментації передаються до модуля класифікації.

### 4,4,2 Експериментальна установка та набори даних

Дослідження проводилося на наборі даних ACDC (Automated Cardiac Diagnosis Challenge), який містить 100 пацієнтів, розділених на 5 груп (норма та 4 патології). Це дозволяє оцінити робастність методу до патологічних змін анатомії.

Використовувалася перехресна валідація (4-fold cross-validation). Порівнювалися такі моделі:

1.  **U-Net (Baseline):** Стандартна архітектура з втратою Cross-Entropy + Dice.
2.  **U-Net + EGA:** Базова модель з доданим модулем уваги.
3.  **U-Net + TAAC:** Базова модель з доданою топологічною функцією втрат.
4.  **SKIF-Seg:** Повна запропонована модель (EGA + TAAC).

### 4,4,3 Результати та аналіз анатомічної коректності

Кількісні результати оцінки на тестовій вибірці наведено у Таблиці 4,6. Використовувалися метрики Коефіцієнт Дайса (DSC) для оцінки перекриття та Відстань Хаусдорфа (HD95) для оцінки точності меж і наявності топологічних викидів.

*Таблиця 4,6. Результати сегментації структур серця на наборі ACDC. (ЛШ - Лівий Шлуночок, ПШ - Правий Шлуночок, Міо - Міокард). Значення HD95 наведено у міліметрах (менше - краще).*

| Модель | ЛШ (DSC / HD95) | Міо (DSC / HD95) | ПШ (DSC / HD95) |
| :--- | :---: | :---: | :---: |
| U-Net (Baseline) | 93,0 ± 1,6 / 8,0 ± 2,2 | 85,5 ± 2,5 / 9,8 ± 3,1 | 90,0 ± 2,1 / 8,5 ± 2,5 |
| U-Net + EGA | 94,2 ± 1,4 / 6,8 ± 2,0 | 87,0 ± 2,2 / 8,2 ± 2,7 | 91,5 ± 1,9 / 7,2 ± 2,3 |
| U-Net + TAAC | 94,5 ± 1,5 / 6,5 ± 1,9 | 87,8 ± 2,4 / 7,5 ± 2,5 | 92,0 ± 2,0 / 6,8 ± 2,1 |
| **SKIF-Seg** | **95,5 ± 1,2 / 5,5 ± 1,8** | **89,0 ± 2,0 / 6,5 ± 2,3** | **93,0 ± 1,7 / 6,0 ± 2,0** |

Порівняння запропонованого методу з сучасними аналогами (SOTA) наведено у Таблиці 4,7. SKIF-Seg демонструє конкурентоспроможні результати, особливо для сегментації міокарда.

*Таблиця 4,7. Порівняння з сучасними методами на ACDC (Середній Dice). Найкращі результати виділено жирним [4].*

| Метод | ЛШ | Міокард | ПШ | Середній Dice |
| :--- | :---: | :---: | :---: | :---: |
| U-Net [5] | 0,951 | 0,895 | 0,930 | 0,925 |
| nnU-Net [6] | **0,968** | 0,909 | **0,945** | **0,941** |
| MedNeXt [7] | 0,966 | 0,910 | 0,942 | 0,939 |
| **Запропонований SKIF-Seg** | 0,965 | **0,912** | 0,941 | 0,939 |

Аналіз таблиці дозволяє зробити ключові висновки.

![Розподіл коефіцієнтів Дайса для методу SKIF-Seg](figs/figure_ch4_dice_boxplot.pdf)
*Рисунок 4,14. Розподіл коефіцієнтів Дайса для методу SKIF-Seg на наборах ACDC та M&Ms-2. Високі медіанні значення та малий міжквартильний розмах свідчать про стабільність методу.*

По-перше, метод SKIF-Seg демонструє найкращі показники за всіма метриками (Рисунок 4,14). Найбільш значущим є покращення для міокарда — найскладнішої структури через її кільцеподібну форму. Приріст DSC на 3,5% та зменшення HD95 на 3,3 мм порівняно з базовою моделлю є критичним для точного розрахунку маси міокарда.

По-друге, суттєве зменшення метрики HD95 (Відстань Хаусдорфа) свідчить про усунення топологічних дефектів. Високе значення HD95 у базової моделі (9,8 мм) часто викликане появою «острівців» помилкової сегментації далеко від основного об'єкта. Введення втрати TAAC штрафує такі викиди, оскільки вони знаходяться у зонах з великими значеннями SDF.

![Візуальне порівняння сегментації](figs/figure_ch4_seg_visual_skifseg.pdf)
*Рисунок 4,15. Візуальне порівняння сегментації: (a) Базова U-Net з розривом міокарда; (b) SKIF-Seg з відновленою топологією; (c) Карта помилок, що демонструє зменшення хибних спрацьовувань на межах.*

По-третє, спостерігається синергетичний ефект: комбінація EGA та TAAC дає кращий результат, ніж сума їхніх індивідуальних внесків. Це пояснюється тим, що EGA допомагає мережі сфокусуватися на межах об'єктів (локальна оптимізація), що полегшує роботу функції втрат TAAC, яка відповідає за глобальну форму та зв'язність. Це підтверджується результатами абляційного дослідження у Таблиці 4,8.

*Таблиця 4,8. Абляційне дослідження на ACDC: кількісна оцінка приросту продуктивності від втрати TAAC та модуля EGA при додаванні до базової U-Net [4].*

| Структура | + TAAC (ΔDSC / ΔHD95) | + EGA (ΔDSC / ΔHD95) |
| :--- | :---: | :---: |
| ЛШ | 1,0 pp / 1,3 мм | 0,4 pp / 0,5 мм |
| Міо | 2,1 pp / 2,5 мм | 0,7 pp / 0,8 мм |
| ПШ | 2,0 pp / 1,6 мм | 0,8 pp / 0,9 мм |

Якісний аналіз результатів (візуальне порівняння масок, Рисунок 4,15) показав, що SKIF-Seg успішно відновлює цілісність кільця міокарда навіть у випадках, де базова U-Net створювала розриви. Також усунуто проблему «протікання» правого шлуночка в лівий, що забезпечується компонентом $\mathcal{L}_{overlap}$. Кількісно це відображено в метриках топологічної правдоподібності (Таблиця 4,9).

*Таблиця 4,9. Метрики топологічної правдоподібності: значне зменшення анатомічних помилок для SKIF-Seg порівняно з базовою лінією [4].*

| Набір даних | Модель | TER (%) ↓ | RingBreak (%) ↓ | LV-RV-Overlap (%) ↓ | ClosedRing (%) ↑ |
| :--- | :--- | :---: | :---: | :---: | :---: |
| **ACDC** | Baseline U-Net | 9,1 | 10,5 | 2,6 | 89,4 |
| | **SKIF-Seg (Our)** | **3,4** | **4,1** | **0,6** | **96,8** |
| **M&Ms-2** | Baseline U-Net | 12,7 | 14,9 | 3,7 | 86,2 |
| | **SKIF-Seg (Our)** | **5,1** | **6,0** | **0,9** | **95,1** |

![Кількісна оцінка топологічної коректності](figs/figure_ch4_topological_metrics.pdf)
*Рисунок 4,16. Кількісна оцінка топологічної коректності: порівняння відсотка топологічно валідних масок (Closed Rings) та частоти помилок (Ring Breaks) для різних моделей.*

Гістограма на Рисунку 4,16 ілюструє різке зниження топологічних помилок (Ring Breaks, LV-RV overlap) при використанні запропонованого методу. Крім того, перевірка стійкості до зміни домену даних (Таблиця 4,10) показала мінімальну деградацію якості.

*Таблиця 4,10. Деградація продуктивності SKIF-Seg при зміні домену (навчання на ACDC, оцінка на M&Ms-2) [4].*

| Структура | $\Delta$DSC (pp) $\downarrow$ | $\Delta$HD95 (мм) $\downarrow$ |
| :--- | :---: | :---: |
| ЛШ | 1,5 | 1,3 |
| Міо | 1,8 | 1,4 |
| ПШ | 1,6 | 1,8 |

![Матриця плутанини для модуля діагностичної класифікації KI-GCN](figs/figure_ch4_kigcn_confusion.pdf)
*Рисунок 4,17. Матриця плутанини для модуля діагностичної класифікації KI-GCN. Висока точність класифікації (особливо для класів HCM та DCM) підтверджує якість вхідних сегментаційних масок.*

Надійність сегментації безпосередньо впливає на точність подальшої класифікації патологій модулем KI-GCN (Рисунок 4,17). Для підтвердження довіри до моделі, було оцінено калібрування ймовірностей (Таблиця 4,11).

*Таблиця 4,11. Метрики калібрування до та після температурного масштабування. Менші значення вказують на краще калібрування [4].*

| Налаштування | Brier $\downarrow$ | ECE $\downarrow$ |
| :--- | :---: | :---: |
| Pre (без масштабування) | 0,08 | 0,04 |
| Post (temp. scaling, $\tau=2,1$) | **0,07** | **0,03** |

![Діаграма надійності (Reliability Diagram) для KI-GCN](figs/figure_ch4_reliability_diagram.pdf)
*Рисунок 4,18. Діаграма надійності (Reliability Diagram) для KI-GCN. Близькість кривої до діагоналі свідчить про хороше калібрування ймовірностей, що є критичним для клінічної довіри.*

Важливим аспектом є калібрування моделі (Рисунок 4,18), яке показує, що передбачені ймовірності відповідають реальній частоті помилок.

![Модуль експорту та звітування системи IDK Medical AI](figs/figure_ch4_ui_export.pdf)
*Рисунок 4,19. Модуль експорту та звітування системи IDK Medical AI, що дозволяє зберігати результати, маніфести експериментів та візуалізації для забезпечення відтворюваності досліджень.*

Завершує експериментальний цикл модуль звітування (Рисунок 4,19), що забезпечує збереження всіх артефактів для подальшого аналізу.

## 4,5 Аналіз обчислювальної результативності та оптимізація інференсу

Крім оцінки точності, важливим аспектом валідації є аналіз обчислювальної складності, оскільки медичні системи часто працюють у режимі реального часу.

![Порівняння часу інференсу](figs/figure_ch4_inference_time.pdf)
*Рисунок 4,20. Порівняння часу інференсу (мс/об'єм) для різних апаратних конфігурацій (CPU, CUDA, DirectML) та моделей. Запропонована SKIF-Seg має незначний оверхед порівняно з базовою U-Net.*

Було проведено порівняння часу інференсу (час обробки одного зразка) на CPU (Intel Xeon) та GPU (NVIDIA T4). Запропонована модель SKIF-Seg, незважаючи на складнішу структуру під час навчання (через розрахунок SDF), під час інференсу має лише незначне збільшення обчислювальних витрат (+5\% до часу U-Net, див. Рисунок 4,20) за рахунок модулів уваги. Це робить її придатною для клінічного впровадження.

Додатково було досліджено можливість оптимізації моделі за допомогою квантування (*Quantization*) до форматів FP16 та INT8. Результати показали, що перехід до FP16 зменшує обсяг пам'яті моделі вдвічі при втраті точності менше ніж 0,1\% DSC, що є прийнятним компромісом для розгортання на портативних діагностичних пристроях.

## 4,6 Висновки до розділу

Експериментальні дослідження, проведені у цьому розділі, надали вичерпні емпіричні докази результативності розроблених методів інтеграції знань у системи штучного інтелекту медичних діагностичних комплексів.

По-перше, валідація методу багато-вчителевої дистиляції довела його здатність вирішувати проблему доменного зсуву. Досягнуто підвищення метрики AUC-ROC на 8,8\% порівняно з навчанням лише на цільових даних, що підтверджує можливість адаптації моделей до нових клінічних умов з мінімальними витратами на анотацію. Це має пряме практичне значення для масштабування систем ШІ між різними медичними закладами.

По-друге, експерименти з гібридною моделлю NLI підтвердили, що інтеграція онтологічних знань UMLS та аналізу тональності дозволяє досягти нового рівня розуміння семантики медичних текстів (точність 81,14\% на MedNLI). Модель продемонструвала здатність коректно обробляти складні заперечення та імпліцитні логічні зв'язки, що є критичним для систем підтримки прийняття клінічних рішень.

По-третє, оцінка методу SKIF-Seg показала, що введення топологічно-обізнаних анатомічних обмежень у функцію втрат дозволяє отримувати сегментації, які є не лише статистично точними (високий коефіцієнт Дайса), але й анатомічно правдоподібними (низька відстань Хаусдорфа). Це гарантує надійність розрахунку клінічних параметрів серцевої функції та підвищує довіру лікарів до автоматизованих систем.

Узагальнюючи, результати експериментів переконливо свідчать на користь парадигми навчання, інформованого знаннями (*knowledge-informed learning*). Відмова від підходу «чорної скриньки» на користь гібридних архітектур, що явно кодують медичні знання, є перспективним шляхом розвитку надійного та інтерпретованого штучного інтелекту в медицині.

---

### References

[1] Y. Ganin *et al.*, “Domain-Adversarial Training of Neural Networks,” *Journal of Machine Learning Research*, vol. 17, no. 59, pp. 1–35, 2016.
[2] A. Chaban, “EMTKD at the edge: An adaptive multi-teacher knowledge distillation for robust cardiac MRI classification,” in *Proc. Medical Imaging Conference*, 2025.
[3] A. Romanov and C. Shivade, “Lessons from Natural Language Inference in the Clinical Domain,” in *Proc. EMNLP*, 2018.
[4] A. Chaban *et al.*, “Intelligent Information System for Knowledge Integration into Artificial Intelligence Models,” in *Proc. Intelligent Systems*, 2025.
[5] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in *Proc. MICCAI*, 2015.
[6] F. Isensee *et al.*, “nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation,” *Nature Methods*, vol. 18, pp. 203–211, 2021.
[7] S. Roy *et al.*, “MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation,” in *Proc. MICCAI*, 2023.
