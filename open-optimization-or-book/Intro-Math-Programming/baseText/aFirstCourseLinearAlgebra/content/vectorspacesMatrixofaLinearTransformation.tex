\section{The Matrix of a Linear Transformation}

\begin{outcome}

\begin{enumerate}

\item[A.] Find the matrix of a linear transformation with respect to general bases in vector spaces. 

\end{enumerate}
\end{outcome}

You may recall from $\mathbb{R}^n$ that the matrix of a linear transformation depends on the bases chosen. This concept is explored in this section, where the linear transformation now maps from one arbitrary vector space to another. 

Let $T: V \mapsto W$ be an isomorphism where $V$ and $W$ are vector spaces. Recall from Lemma \ref{lem:basesisomorphism} that $T$ maps a basis in $V$ to a basis in $W$. When discussing this Lemma, we were not specific on what this basis looked like. In this section we will make such a distinction. 

Consider now an important definition.

\index{coordinate isomorphism}
\begin{definition}{Coordinate Isomorphism}{coordinateisomorphism}
Let $V$ be a vector space with $\func{dim}(V)=n$, let $B=\{ \vect{b}_1, \vect{b}_2, \ldots, \vect{b}_n \}$ be a fixed basis of $V$,
and let $\{ \vect{e}_1, \vect{e}_2, \ldots, \vect{e}_n \}$
denote the standard basis of $\mathbb{R}^n$.
We define a transformation $C_B:V\to\mathbb{R}^n$ by
\[
C_B(a_1\vect{b}_1 + a_2\vect{b}_2 + \cdots + a_n\vect{b}_n)
=
a_1\vect{e}_1 + a_2\vect{e}_2 + \cdots + a_n\vect{e}_n
=
\leftB\begin{array}{c} a_1 \\ a_2 \\ \vdots \\ a_n
\end{array}\rightB.\]
Then $C_B$ is a linear transformation
such that
$C_B(\vect{b}_i)=\vect{e}_i$, $1\leq i\leq n$.

$C_B$ is an isomorphism, called
the coordinate isomorphism corresponding to $B$.
\end{definition}

We continue with another related definition.

\index{coordinate vector}
\begin{definition}{Coordinate Vector}{coordinatevector}
Let $V$ be a finite dimensional vector space with $\func{dim}(V)=n$, and
let $B=\{\vect{b}_1, \vect{b}_2, \ldots, \vect{b}_n\}$ be an ordered basis of $V$ (meaning that the order that the
vectors are listed is taken into account).
The coordinate vector of $\vect{v}$ with respect to $B$ is defined
as $C_B(\vect{v})$.
\end{definition}

Consider the following example.

\begin{example}{Coordinate Vector}{coordinatevector}
Let $V = \mathbb{P}_2$ and $\vect{x} = -x^2 -2x + 4$. 
Find $C_B(\vect{x})$ for the following bases $B$:
\begin{enumerate}
\item $B = \left\{ 1, x, x^2 \right\}$
\item $B = \left\{ x^2, x, 1 \right\}$
\item $B = \left\{ x + x^2 , x , 4 \right\}$
\end{enumerate}
\end{example}

\begin{solution}
\begin{enumerate}
\item
First, note the order of the basis is important.
Now we need to find $a_1, a_2, a_3$ such that $\vect{x} = a_1 (1) + a_2 (x) + a_3(x^2)$, that is:
\[
-x^2 -2x + 4 = a_1 (1) + a_2 (x) + a_3(x^2)
\]
Clearly the solution is
\begin{eqnarray*}
a_1 &=& 4 \\
a_2 &=& -2 \\
a_3 &=& -1
\end{eqnarray*}
Therefore the coordinate vector is
\[
C_B(\vect{x}) = 
\leftB
\begin{array}{r}
4 \\
-2 \\
-1
\end{array} \rightB
\]

\item
Again remember that the order of $B$ is important. We proceed as above. 
We need to find $a_1, a_2, a_3$ such that $\vect{x} = a_1 (x^2) + a_2 (x) + a_3(1)$, that is:
\[
-x^2 -2x + 4 = a_1 (x^2) + a_2 (x) + a_3(1)
\]
Here the solution is
\begin{eqnarray*}
a_1 &=& -1 \\
a_2 &=& -2 \\
a_3 &=& 4
\end{eqnarray*}
Therefore the coordinate vector is
\[
C_B(\vect{x}) = 
\leftB
\begin{array}{r}
-1 \\
-2 \\
4
\end{array} \rightB
\]

\item 
Now we need to find $a_1, a_2, a_3$ such that $\vect{x} = a_1 (x + x^2) + a_2 (x) + a_3(4)$, that is:
\begin{eqnarray*}
-x^2 -2x + 4 &=& a_1 (x + x^2 ) + a_2 (x) + a_3(4)\\
&=& a_1 (x^2) + (a_1 + a_2) (x) + a_3(4)
\end{eqnarray*}

The solution is
\begin{eqnarray*}
a_1 &=& -1 \\
a_2 &=& -1 \\
a_3 &=& 1
\end{eqnarray*}
and the coordinate vector is
\[
C_B(\vect{x}) = 
\leftB
\begin{array}{r}
-1 \\
-1 \\
1
\end{array} \rightB
\]
\end{enumerate}
\end{solution}

Given that the coordinate transformation $C_B:V\to\mathbb{R}^n$ is an isomorphism, its inverse exists. 

\begin{theorem}{Inverse of the Coordinate Isomorphism}{coordinateinverse}
Let $V$ be a finite dimensional vector space with dimension $n$
and ordered basis $B=\{\vect{b}_1, \vect{b}_2, \ldots, \vect{b}_n\}$.
Then $C_B:V\to\mathbb{R}^n$ is an isomorphism whose inverse,
\[ C_B^{-1}:\mathbb{R}^n\to V\]
is given by
\[  C_B^{-1} =\leftB\begin{array}{c}
a_1 \\ a_2 \\ \vdots \\ a_n \end{array}\rightB =
a_1\vect{b}_1 + a_2\vect{b}_2 + \cdots + a_n\vect{b}_n
~\mbox{ for all }~
\leftB\begin{array}{c}
a_1 \\ a_2 \\ \vdots \\ a_n \end{array}\rightB \in\mathbb{R}^n.  \]
\end{theorem}

We now discuss the main result of this section, that is how
to represent a linear transformation with respect to different
bases.

Let $V$ and $W$ be finite dimensional vector spaces, and suppose
\begin{itemize}
\item $\dim(V)=n$ and $B_1=\{\vect{b}_1, \vect{b}_2, \ldots, \vect{b}_n\}$
is an ordered basis of $V$;
\item $\dim(W)=m$ and $B_2$ is an ordered basis of $W$.
\end{itemize}
Let $T:V\to W$ be a linear transformation.
If $V=\mathbb{R}^n$ and $W=\mathbb{R}^m$, then we can find a
matrix $A$ so that $T_A=T$. For arbitrary vector spaces $V$ and $W$, 
our goal is to represent $T$ as a matrix.,
i.e., 
find a matrix $A$ so that $T_A:\mathbb{R}^n\to\mathbb{R}^m$
and $T_A=C_{B_2}TC_{B_1}^{-1}$.

To find the matrix $A$:

\[ T_A=C_{B_2}TC_{B_1}^{-1}~\mbox{ implies that }~
T_AC_{B_1}=C_{B_2}T,\]

and thus for any $\vect{v}\in V$, 
\[ C_{B_2}[T(\vect{v})] = T_A[C_{B_1}(\vect{v})] 
=AC_{B_1}(\vect{v}).\]

Since $C_{B_1}(\vect{b}_j)=\vect{e}_j$
for each $\vect{b}_j\in B_1$,
$AC_{B_1}(\vect{b}_j)=A\vect{e}_j$, which is simply the
$j^{th}$ column of $A$.
Therefore, the $j^{th}$ column of $A$ is equal to $C_{B_2}[T(\vect{b}_j)]$.

The matrix of $T$ corresponding to the ordered
bases $B_1$ and $B_2$ is denoted $ M_{B_2B_1}(T)$ and is given by 
\[ M_{B_2B_1}(T)=
\leftB\begin{array}{cccc}
C_{B_2} [ T(\vect{b}_1)] & C_{B_2}[T(\vect{b}_2) ] &
\cdots & C_{B_2}[T(\vect{b}_n) ] \end{array}\rightB.\] 
This result is given in the following theorem. 

\begin{theorem}{}{}
Let $V$ and $W$ be vectors spaces of dimension
$n$ and $m$ respectively, with $B_1=\{\vect{b}_1, \vect{b}_2, \ldots, \vect{b}_n\}$ an
ordered basis of $V$ and $B_2$ an ordered basis of $W$. Suppose $T:V\to W$ is a linear transformation. Then the unique matrix $M_{B_2B_1}(T)$ of $T$ corresponding to $B_1$ and $B_2$ is given by 
\[ M_{B_2B_1}(T)=
\leftB\begin{array}{cccc}
C_{B_2}[T(\vect{b}_1)] & C_{B_2}[T(\vect{b}_2)] &
\cdots & C_{B_2}[T(\vect{b}_n)] \end{array}\rightB.\]

This matrix satisfies  $C_{B_2}[T(\vect{v})]=M_{B_2B_1}(T)C_{B_1}(\vect{v})$ for all $\vect{v}\in V$.
\end{theorem}

We demonstrate this content in the following examples. 

\begin{example}{Matrix of a Linear Transformation}{matrixoflineartransformation}
Let $T: \mathbb{P}_3 \mapsto \mathbb{R}^4$ be an isomorphism defined by
\[
T( ax^3 + bx^2 + cx + d) = \leftB \begin{array}{c}
a + b \\
b - c \\
c + d \\
d + a 
\end{array} \rightB
\]

Suppose $B_1 = \left\{ x^3, x^2, x, 1 \right\}$ is an ordered basis of $\mathbb{P}_3$ and 
\[
B_2 = \left\{ \leftB \begin{array}{r}
1 \\
0 \\
1 \\
0
\end{array} \rightB, \leftB \begin{array}{r}
0 \\
1 \\
0 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
0 \\
-1 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
0 \\
0 \\
1
\end{array} \rightB \right\} 
\]
be an ordered basis of $\mathbb{R}^4$.
Find the matrix $M_{B_2B_1}(T)$. 
\end{example}

\begin{solution}
To find $M_{B_2B_1}(T)$, we use the following definition.
\[
M_{B_2B_1}(T) = \leftB 
\begin{array}{cccc}
C_{B_2}[T(x^3)] & C_{B_2}[T(x^2)] & C_{B_2}[T(x)] & C_{B_2}[T(x^2)]
\end{array}
\rightB
\]
First we find the result of applying $T$ to the basis $B_1$.
\[
T(x^3)  = \leftB \begin{array}{c}
1 \\
0 \\
0 \\
1 
\end{array} \rightB, 
T(x^2)  = \leftB \begin{array}{c}
1 \\
1 \\
0  \\
0 
\end{array} \rightB, 
T(x) = \leftB \begin{array}{c}
0  \\
-1 \\
1  \\
0 
\end{array} \rightB, 
T(1) = \leftB \begin{array}{c}
0  \\
0  \\
1 \\
1 
\end{array} \rightB
\]

Next we apply the coordinate isomorphism $C_{B_2}$ to each of these vectors. We will show the first in detail. 
\[
C_{B_2} \left( \leftB \begin{array}{c}
1 \\
0 \\
0 \\
1 
\end{array} \rightB \right) = a_1 \leftB \begin{array}{r}
1 \\
0 \\
1 \\
0
\end{array} \rightB + a_2  \leftB \begin{array}{r}
0 \\
1 \\
0 \\
0
\end{array} \rightB + a_3 
\leftB \begin{array}{r}
0 \\
0 \\
-1 \\
0
\end{array} \rightB + a_4 
\leftB \begin{array}{r}
0 \\
0 \\
0 \\
1
\end{array} \rightB \]
This implies that
\begin{eqnarray*}
a_1 &=& 1 \\
a_2 &=& 0 \\
a_1 - a_3 &=& 0 \\
a_4 &=& 1 
\end{eqnarray*} 
which has a solution given by 
\begin{eqnarray*}
a_1 &=& 1 \\
a_2 &=& 0 \\
a_3 &=& 1 \\
a_4 &=& 1 
\end{eqnarray*} 

Therefore $C_{B_2} [T(x^3)] = \leftB \begin{array}{r} 
1 \\
0 \\
1 \\
1
\end{array} \rightB$. 

You can verify that the following are true.
\[
C_{B_2}[T(x^2)] = \leftB \begin{array}{r} 
1 \\
1 \\
1 \\
0
\end{array} \rightB,  C_{B_2}[T(x)] = \leftB \begin{array}{r} 
0 \\
-1 \\
-1 \\
0
\end{array} \rightB,  C_{B_2}[T(1)] = \leftB \begin{array}{r} 
0 \\
0 \\
-1 \\
1
\end{array} \rightB
\]

Using these vectors as the columns of $M_{B_2B_1}(T)$ we have
\[
M_{B_2B_1}(T) = \leftB \begin{array}{rrrr}
1 & 1 & 0 & 0 \\
0 & 1 & -1 & 0 \\
1 & 1 & -1 & -1 \\
1 & 0 & 0 & 1 
\end{array} \rightB
\]
\end{solution}

The next example demonstrates that this method can be used to solve different types of problems. We will examine the above example and see if we can work backwards to determine the action of $T$ from the matrix $M_{B_2B_1}(T)$.

\begin{example}{Finding the Action of a Linear Transformation}{actionlinear}
Let $T: \mathbb{P}_3 \mapsto \mathbb{R}^4$ be an isomorphism with
\[
M_{B_2B_1}(T) = \leftB \begin{array}{rrrr}
1 & 1 & 0 & 0 \\
0 & 1 & -1 & 0 \\
1 & 1 & -1 & -1 \\
1 & 0 & 0 & 1 
\end{array} \rightB,
\]
where $B_1 = \left\{ x^3, x^2, x, 1 \right\}$ is an ordered basis of $\mathbb{P}_3$ and 
\[
B_2 = \left\{ \leftB \begin{array}{r}
1 \\
0 \\
1 \\
0
\end{array} \rightB, \leftB \begin{array}{r}
0 \\
1 \\
0 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
0 \\
-1 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
0 \\
0 \\
1
\end{array} \rightB \right\} 
\]
is an ordered basis of $\mathbb{R}^4$. If $p(x) = ax^3 + bx^2 + cx + d$, find $T(p(x))$. 
\end{example}

\begin{solution}
Recall that $C_{B_2}[T(p(x))] = M_{B_2B_1}(T) C_{B_1}(p(x))$. 
Then we have 
\begin{eqnarray*}
C_{B_2}[T(p(x))] &=& M_{B_2B_1}(T) C_{B_1}(p(x)) \\
&=& 
\leftB \begin{array}{rrrr}
1 & 1 & 0 & 0 \\
0 & 1 & -1 & 0 \\
1 & 1 & -1 & -1 \\
1 & 0 & 0 & 1 
\end{array} \rightB \leftB \begin{array}{c}
a \\ 
b \\
c \\
d 
\end{array} \rightB \\
&=& 
\leftB \begin{array}{c}
a + b \\ 
b - c \\
a + b - c - d\\
a + d
\end{array} \rightB
\end{eqnarray*}

Therefore 
\begin{eqnarray*}
T(p(x)) &=& C^{-1}_D \leftB \begin{array}{c}
a + b \\ 
b - c \\
a + b - c - d\\
a + d
\end{array} \rightB \\
&=& (a+b) \leftB \begin{array}{r}
1 \\
0 \\
1 \\
0
\end{array} \rightB + (b-c) \leftB \begin{array}{r}
0 \\
1 \\
0 \\
0
\end{array} \rightB + 
(a+b-c-d) \leftB \begin{array}{r}
0 \\
0 \\
-1 \\
0
\end{array} \rightB + 
(a+d) \leftB \begin{array}{r}
0 \\
0 \\
0 \\
1
\end{array} \rightB \\
&=&
\leftB \begin{array}{c}
a + b \\
b - c \\
c + d \\
a +d 
\end{array} \rightB
\end{eqnarray*}

You can verify that this was the definition of $T(p(x))$ given in the previous example.
\end{solution}

We can also find the matrix of the composite of multiple transformations.

\begin{theorem}{Matrix of Composition}{matrixcomposition}
Let $V,W$ and $U$ be finite dimensional vector spaces, and suppose $T : V \mapsto W$, $S: W \mapsto U$ are linear transformations. 
Suppose $V, W$ and $U$ have ordered bases of $B_1$, $B_2$ and $B_3$ respectively.  Then the matrix of the composite transformation $S \circ T$ (or $ST$) is given by 
\[ M_{B_3B_1}(ST)=M_{B_3B_2}(S) M_{B_2B_1}(T).\]
\end{theorem}

The next important theorem gives a condition on when $T$ is an isomorphism.

\begin{theorem}{Isomorphism}{isomorphism}
Let $V$ and $W$ be vector spaces such that both have dimension $n$ and let $T: V \mapsto W$ be a linear transformation. Suppose $B_1$ is an ordered basis of $V$ and $B_2$ is an ordered basis of $W$. 

 Then the conditions that $M_{B_2B_1}(T)$ is invertible for \textbf{all} $B_1$ and $B_2$, and that $M_{B_2B_1}(T)$ is invertible for \textbf{some} $B_1$ and $B_2$ are equivalent. In fact, these occur if and only if $T$ is an isomorphism. 

If $T$ is an isomorphism, the matrix $M_{B_2B_1}(T)$ is invertible and its inverse is given by $\leftB M_{B_2B_1}(T) \rightB ^{-1} = M_{B_1B_2}(T^{-1})$.
\end{theorem}

Consider the following example.

\begin{example}{}{}
Suppose $T:\mathbb{P}_3\to\mathbb{M}_{22}$ is a linear transformation
defined by
\[ T(ax^3+bx^2+cx+d)=
\leftB\begin{array}{cc} a+d & b-c \\ b+c & a-d \end{array}\rightB\]
for all $ax^3+bx^2+cx+d\in\mathbb{P}_3$. Let
$B_1=\{ x^3, x^2, x, 1\}$ and
\[ B_2=\left\{
\leftB\begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array}\rightB,
\leftB\begin{array}{cc} 0 & 1 \\ 0 & 0 \end{array}\rightB,
\leftB\begin{array}{cc} 0 & 0 \\ 1 & 0 \end{array}\rightB,
\leftB\begin{array}{cc} 0 & 0 \\ 0 & 1 \end{array}\rightB\right\}\]
be ordered bases of $\mathbb{P}_3$ and $\mathbb{M}_{22}$, respectively.
\begin{enumerate}
\item Find $M_{B_2B_1}(T)$.
\item Verify that $T$ is an isomorphism by proving that $M_{B_2B_1}(T)$
is invertible.
\item Find $M_{B_1B_2}(T^{-1})$, and verify that 
$M_{B_1B_2}(T^{-1}) = \leftB M_{B_2B_1}(T)\rightB^{-1}$.
\item Use $M_{B_1B_2}(T^{-1})$ to find $T^{-1}$.
\end{enumerate}
\end{example}

\begin{solution}
\begin{enumerate}
\item 
\begin{eqnarray*}
M_{B_2B_1}(T) & = &
\leftB \begin{array}{cccc} C_{B_2}[T(1)] & C_{B_2}[T(x)] & C_{B_2}[T(x^2)]
& C_{B_2}[T(x^3)] \end{array}\rightB \\
& = & 
\leftB \begin{array}{cccc}
C_{B_2}\leftB\begin{array}{cc} 1 & 0 \\ 0 & 1 \end{array}\rightB 
& C_{B_2}\leftB\begin{array}{cc} 0 & 1 \\ 1 & 0 \end{array}\rightB
& C_{B_2}\leftB\begin{array}{cc} 0 & -1 \\ 1 & 0 \end{array}\rightB
& C_{B_2}\leftB\begin{array}{cc} 1 & 0 \\ 0 & -1 \end{array}\rightB
\end{array}\rightB \\
& = & \leftB\begin{array}{rrrr}
1 & 0 & 0 & 1 \\
0 & 1 & -1 & 0 \\
0 & 1 & 1 & 0 \\
1 & 0 & 0 & -1 \end{array}\rightB
\end{eqnarray*}

\item $\det(M_{B_2B_1}(T))=4$, so the matrix is invertible, and hence $T$
is an isomorphism.

\item 
\[ T^{-1}\leftB\begin{array}{cc} 1 & 0 \\ 0 & 1 \end{array}\rightB = 1, 
T^{-1}\leftB\begin{array}{cc} 0 & 1 \\ 1 & 0 \end{array}\rightB= x,
T^{-1}\leftB\begin{array}{cc} 0 & -1 \\ 1 & 0 \end{array}\rightB= x^2,
T^{-1}\leftB\begin{array}{cc} 1 & 0 \\ 0 & -1 \end{array}\rightB=x^3,\]
so
\[ T^{-1}\leftB\begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array}\rightB = \frac{1+x^3}{2},
T^{-1}\leftB\begin{array}{cc} 0 & 1 \\ 0 & 0 \end{array}\rightB= \frac{x-x^2}{2}, \]
\[ T^{-1}\leftB\begin{array}{cc} 0 & 0 \\ 1 & 0 \end{array}\rightB = \frac{x+x^2}{2},
T^{-1}\leftB\begin{array}{cc} 0 & 1 \\ 0 & 0 \end{array}\rightB= \frac{1-x^3}{2}. \]
Therefore,
\[ M_{B_1B_2}(T^{-1})=\frac{1}{2}\leftB\begin{array}{rrrr}
1 & 0 & 0 & 1 \\
0 & 1 & 1 & 0 \\
0 & -1 & 1 & 0 \\
1 & 0 & 0 & -1 \end{array}\rightB \]

You should verify that $M_{B_2B_1}(T) M_{B_1B_2}(T^{-1}) = I_4$. From this it follows that $[M_{B_2B_1}(T)]^{-1}= M_{B_1B_2}(T^{-1})$.

\item 
\begin{eqnarray*}
C_{B_1}\left(T^{-1}\leftB\begin{array}{cc}
p & q \\ r & s \end{array}\rightB\right) & = & 
M_{B_1B_2}(T^{-1})
C_{B_2}\left( \leftB\begin{array}{cc}
p & q \\ r & s \end{array}\rightB\right)\\
T^{-1}\leftB\begin{array}{cc}
p & q \\ r & s \end{array}\rightB & = & 
C_{B_1}^{-1}\left(M_{B_1B_2}(T^{-1})
C_{B_2}\left( \leftB\begin{array}{cc}
p & q \\ r & s \end{array}\rightB\right)\right)\\
& = &
C_{B_1}^{-1}\left(
\frac{1}{2}\leftB\begin{array}{rrrr}
1 & 0 & 0 & 1 \\
0 & 1 & 1 & 0 \\
0 & -1 & 1 & 0 \\
1 & 0 & 0 & -1 \end{array}\rightB
\leftB\begin{array}{c} p \\ q\\ r\\ s\end{array}\rightB\right) \\
& =&
C_{B_1}^{-1}\left(\frac{1}{2}\leftB\begin{array}{c}
p+s \\ q+r \\ r-q \\ p-s \end{array}\rightB\right) \\
& = & \frac{1}{2}(p+s)x^3 +\frac{1}{2}(q+r)x^2 +\frac{1}{2}(r-q)x 
+ \frac{1}{2}(p-s).
\end{eqnarray*}
\end{enumerate}
\end{solution}