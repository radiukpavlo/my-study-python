\section{The Kernel And Image Of A Linear Map}

\begin{outcome}
\begin{enumerate}
\item[A.]  Describe the kernel and image of a linear transformation, and find a basis for each. 
\end{enumerate}
\end{outcome}

In this section we will consider the case where the linear transformation is not necessarily an
isomorphism. First consider the following important definition.

\begin{definition}{Kernel and Image}{kernelimage}
Let $V$ and $W$ be subspaces of $\mathbb{R}^n$ and let $T:V\mapsto W$ be a linear transformation. Then the image of $T$
denoted as $\func{im}\left( T\right) $ is defined to be the set 
\index{linear map!image}
\index{linear map!kernel} 
\begin{equation*}
\func{im}\left( T\right) = \left\{T (\vect{v}):\vect{v}\in V\right\}
\end{equation*}
In words, it consists of all vectors in $W$ which equal $T(\vect{v})$ for some $
\vect{v}\in V$.

The kernel of $T$, written $\ker \left( T\right) $, consists of all $\vect{v}\in V$ such that $T(\vect{v})=\vect{0}$. That is, 
\begin{equation*}
\ker \left( T\right) =\left\{ \vect{v}\in V:T(\vect{v})=\vect{0}\right\}
\end{equation*}
\end{definition}

It follows that $\func{im}\left( T\right) $ and $\ker \left( T\right) $
are subspaces of $W$ and $V$ respectively.

\begin{proposition}{Kernel and Image as Subspaces}{kernelimagesubspaces}
Let $V, W$ be subspaces of $\mathbb{R}^n$ and let $T:V\rightarrow W$ be a linear transformation. Then $\ker \left(
T\right) $ is a subspace of $V$ and $\func{im}\left( T\right) $ is a
subspace of $W$.
\end{proposition}

\begin{proof}
First consider $\ker \left( T\right) .$ It is necessary to
show that if $\vect{v}_{1},\vect{v}_{2}$ are vectors in $\ker \left( T\right) $
and if $a,b$ are scalars, then $a\vect{v}_{1}+b\vect{v}_{2}$ is also in $\ker
\left( T\right) .$ But 
\begin{equation*}
T\left( a\vect{v}_{1}+b\vect{v}_{2}\right) =aT(\vect{v}_{1})+bT(\vect{v}_{2})=a\vect{0}+b\vect{0}=\vect{0}
\end{equation*}
Thus $\ker \left( T\right) $ is a subspace of $V$.

Next suppose $T(\vect{v}_{1}),T(\vect{v}_{2})$ are two vectors in $\func{im}\left(
T\right) .$ Then if $a,b$ are scalars, 
\begin{equation*}
aT(\vect{v}_{2})+bT(\vect{v}_{2})=T\left( a\vect{v}_{1}+b\vect{v}_{2}\right)
\end{equation*}
and this last vector is in $\func{im}\left( T\right) $ by definition. 
\end{proof}

We will now examine how to find the kernel and image of a linear transformation and describe the basis of each. 

\begin{example}{Kernel and Image of a Linear Transformation}{kernelimage}
Let $T: \mathbb{R}^4 \mapsto \mathbb{R}^2$ be defined by
\[
T \leftB \begin{array}{c}
a \\
b \\
c \\
d
\end{array} \rightB = 
\leftB \begin{array}{c}
a - b \\ 
c + d
\end{array} \rightB
\]
Then $T$ is a linear transformation. Find a basis for $\func{ker}(T)$ and $\func{im}(T)$. 
\end{example}

\begin{solution}
You can verify that $T$ is a linear transformation.

First we will find a basis for $\func{ker}(T)$. To do so, we want to find a way to describe all vectors $\vect{x} \in \mathbb{R}^4$ such that $T(\vect{x}) = \vect{0}$. Let $\vect{x} =  \leftB \begin{array}{c}
a \\
b \\
c \\
d
\end{array} \rightB$ be such a vector. Then
\[
T \leftB \begin{array}{c}
a \\
b \\
c \\
d
\end{array} \rightB = 
\leftB \begin{array}{c}
a - b \\ 
c + d
\end{array} \rightB = 
\leftB \begin{array}{c}
0 \\ 
0
\end{array} \rightB
\]

The values of $a, b, c, d$ that make this true are given by solutions to the system 
\begin{eqnarray*}
a - b &=& 0 \\
c + d &=& 0
\end{eqnarray*}
The solution to this system is $ a = s, b = s, c = t, d = -t$ where $s, t$ are scalars. We can describe $\func{ker}(T)$ as follows.
\[
\func{ker}(T) = \left\{ \leftB \begin{array}{r}
s \\ 
s \\
t \\
-t 
\end{array} \rightB \right\}
=
\func{span} \left\{ \leftB \begin{array}{r}
1 \\
1 \\
0 \\
0 
\end{array} \rightB, \leftB \begin{array}{r}
0 \\
0 \\
1 \\
-1
\end{array} \rightB \right\}
\]
Notice that this set is linearly independent and therefore forms a basis for $\func{ker}(T)$. 

We move on to finding a basis for $\func{im}(T)$. We can write the image of $T$ as 
\[
\func{im}(T) = \left\{ \leftB \begin{array}{c}
a - b \\
c + d
\end{array} \rightB
\right\}
\]
We can write this in the form
\[
\func{span} = \left\{ 
\leftB \begin{array}{r}
1 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
-1 \\
0
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
1
\end{array} \rightB, 
\leftB \begin{array}{r}
0 \\
1
\end{array} \rightB \right\}
\]
This set is clearly not linearly independent. By removing unnecessary vectors from the set we can create a linearly independent set with the same span. This gives a basis for $\func{im}(T)$ as
\[
\func{im}(T) = \func{span} \left\{
\leftB \begin{array}{r}
1 \\
0
\end{array} \rightB,
\leftB \begin{array}{r}
0 \\
1
\end{array} \rightB
\right\}
\]
\end{solution}

Recall that a linear transformation $T$ is called one to one if and only if $T(\vect{x}) = \vect{0}$ implies $\vect{x} = \vect{0}$. Using the concept of kernel, we can state this theorem in another way.

\begin{theorem}{One to One and Kernel}{onetoonekernel}
Let $T$ be a linear transformation where $\func{ker}(T)$ is the kernel of $T$. Then $T$ is one to one if and only if $\func{ker}(T)$ consists of \textbf{only} the zero vector. 
\end{theorem}

A major result is the relation between the dimension of the kernel and
dimension of the image of a linear transformation. In the previous example $\func{ker}(T)$ had dimension $2$, and $\func{im}(T)$ also had dimension of $2$. Is it a coincidence that the dimension of $\mathbb{M}_{22}$ is $4 = 2 + 2$? Consider the following theorem. 

\begin{theorem}{Dimension of Kernel and Image}{dimensionkernelimage}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are subspaces of $\mathbb{R}^n$. Suppose the dimension of $V$ is $m$. Then 
\[
m=\dim \left( \ker \left( T\right) \right) +\dim \left( \func{im}\left(
T\right) \right) 
\]
\index{rank added to nullity}
\index{nullity}
\index{rank}
\end{theorem}

\begin{proof}
From Proposition \ref{prop:kernelimagesubspaces}, $\func{im}\left( T\right) $ is a subspace of $W.$ We know that there exists a basis for $\func{im}\left( T\right)$, $\left\{ T(\vect{v}
_{1}),\cdots ,T(\vect{v}_{r})\right\} . $ Similarly, there is a basis for $\ker
\left( T\right) ,\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s}\right\} $. Then if $
\vect{v}\in V,$ there exist scalars $c_{i}$ such that 
\begin{equation*}
T(\vect{v})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})
\end{equation*}
Hence $T\left( \vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}\right) =0.$ It follows
that $\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}$ is in $\ker \left( T\right) $.
Hence there are scalars $a_{i}$ such that 
\begin{equation*}
\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}=\sum_{j=1}^{s}a_{j}\vect{u}_{j}
\end{equation*}
Hence $\vect{v}=\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}
_{j}. $ Since $\vect{v}$ is arbitrary, it follows that 
\begin{equation*}
V=\func{span}\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}\right\}
\end{equation*}
If the vectors $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}\right\} $ are linearly independent, then it will follow that
this set is a basis. Suppose then that 
\begin{equation*}
\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}_{j}=0
\end{equation*}
Apply $T$ to both sides to obtain 
\begin{equation*}
\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})+\sum_{j=1}^{s}a_{j}T(\vect{u})
_{j}=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})=0
\end{equation*}
Since $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})\right\} $ is linearly
independent, it follows that each $c_{i}=0.$ Hence $\sum_{j=1}^{s}a_{j}\vect{u
}_{j}=0$ and so, since the $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s}\right\} $
are linearly independent, it follows that each $a_{j}=0$ also. Therefore $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,\vect{v}
_{r}\right\} $ is a basis for $V$ and so 
\begin{equation*}
n=s+r=\dim \left( \ker \left( T\right) \right) +\dim \left( \func{im}\left(
T\right) \right) 
\end{equation*}
\end{proof}

The above theorem leads to the next corollary.

\begin{corollary}{}{}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are subspaces of $\mathbb{R}^n$. Suppose the dimension of $V$ is $m$. Then 
\[
\dim \left( \ker \left( T\right) \right) \leq m
\]
\[
\dim \left( \func{im}\left( T \right) \right) \leq m
\]
\end{corollary}

This follows directly from the fact that $n=\dim \left( \ker \left( T\right) \right) +\dim \left( \func{im}\left(
T\right) \right) $.

Consider the following example.

\begin{example}{}{}
Let $T:\mathbb{R}^{2}\rightarrow \mathbb{R}^{3}$ be defined by 
\begin{equation*}
T(\vect{x})=\leftB
\begin{array}{rr}
1 & 0 \\ 
1 & 0 \\ 
0 & 1
\end{array}
\rightB \vect{x}
\end{equation*}
Then $\func{im}\left( T\right) =V$ is a subspace of $\mathbb{R}^{3}$ and $T$
is an isomorphism of $\mathbb{R}^{2}$ and $V$. Find a $2\times 3$ matrix $A$
such that the restriction of multiplication by $A$ to $V=\func{im}\left(
T\right) $ equals $T^{-1}$. 
\end{example}

\begin{solution}
Since the two columns of the above matrix are linearly independent, we conclude that $\func{dim}(\func{im}(T)) = 2$ and therefore $\func{dim}(\func{ker}(T)) = 2 - \func{dim}(\func{im}(T)) = 2-2 = 0$ by Theorem \ref{thm:dimensionkernelimage}. Then by Theorem \ref{thm:onetoonekernel} it follows that $T$ is one to one. 

Thus $T$ is an isomorphism of $\mathbb{R
}^{2}$ and the two dimensional subspace of $\mathbb{R}^{3}$ which is the
span of the columns of the given matrix. Now in particular, 
\begin{equation*}
T(\vect{e}_{1})=\leftB 
\begin{array}{r}
1 \\ 
1 \\ 
0
\end{array}
\rightB ,\ T(\vect{e}_{2})=\leftB 
\begin{array}{r}
0 \\ 
0 \\ 
1
\end{array}
\rightB
\end{equation*}
Thus 
\begin{equation*}
T^{-1}\leftB 
\begin{array}{r}
1 \\ 
1 \\ 
0
\end{array}
\rightB =\vect{e}_{1},\ T^{-1}\leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB =\vect{e}_{2}
\end{equation*}
Extend $T^{-1}$ to all of $\mathbb{R}^{3}$ by defining 
\begin{equation*}
T^{-1}\leftB
\begin{array}{c}
0 \\ 
1 \\ 
0
\end{array}
\rightB =\vect{e}_{1}
\end{equation*}
Notice that the vectors
\begin{equation*}
\left\{ \leftB
\begin{array}{c}
1 \\ 
1 \\ 
0
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB ,\leftB 
\begin{array}{c}
0 \\ 
1 \\ 
0
\end{array}
\rightB \right\} 
\end{equation*}
are linearly independent so $T^{-1}$ can be extended linearly to yield a
linear transformation defined on $\mathbb{R}^{3}$. The matrix of $T^{-1}$
denoted as $A$ needs to satisfy 
\begin{equation*}
A\leftB
\begin{array}{rrr}
1 & 0 & 0 \\ 
1 & 0 & 1 \\ 
0 & 1 & 0
\end{array}
\rightB =\leftB 
\begin{array}{rrr}
1 & 0 & 1 \\ 
0 & 1 & 0
\end{array}
\rightB
\end{equation*}
and so 
\begin{equation*}
A=\leftB 
\begin{array}{rrr}
1 & 0 & 1 \\ 
0 & 1 & 0
\end{array}
\rightB \leftB 
\begin{array}{rrr}
1 & 0 & 0 \\ 
1 & 0 & 1 \\ 
0 & 1 & 0
\end{array}
\rightB^{-1}=\leftB 
\begin{array}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{array}
\rightB
\end{equation*}
Note that 
\begin{equation*}
\leftB
\begin{array}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{array}
\rightB \leftB 
\begin{array}{c}
1 \\ 
1 \\ 
0
\end{array}
\rightB =\leftB 
\begin{array}{c}
1 \\ 
0
\end{array}
\rightB
\end{equation*}
\begin{equation*}
\leftB 
\begin{array}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{array}
\rightB \leftB 
\begin{array}{c}
0 \\ 
0 \\ 
1
\end{array}
\rightB =\leftB 
\begin{array}{c}
0 \\ 
1
\end{array}
\rightB
\end{equation*}
so the restriction to $V$ of matrix multiplication by this matrix yields $
T^{-1}.$  
\end{solution}
