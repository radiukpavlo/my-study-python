\section{The Kernel And Image Of A Linear Map}

\begin{outcome}
\begin{enumerate}
\item[A.] Describe the kernel and image of a linear transformation.

\item[B.] Use the kernel and image to determine if a linear transformation is one to one or onto. 
\end{enumerate}
\end{outcome}

Here we consider the case where the linear map is not necessarily an
isomorphism. First here is a definition of what is meant by the image and
kernel of a linear transformation.

\begin{definition}{Kernel and Image}{}
Let $V$ and $W$ be vector spaces and let $T:V\rightarrow W$ be a linear transformation. Then the image of $T$
denoted as $\func{im}\left( T\right) $ is defined to be the set 
\begin{equation*}
\left\{ T(\vect{v}):\vect{v}\in V\right\}
\end{equation*}
In words, it consists of all vectors in $W$ which equal $T(\vect{v})$ for some $
\vect{v}\in V$. The kernel, $\ker \left( T\right) $, 
consists of all $\vect{v}\in V$ such that $T(\vect{v})=\vect{0}$. That is, 
\begin{equation*}
\ker \left( T\right) =\left\{ \vect{v}\in V:T(\vect{v})=\vect{0}\right\}
\end{equation*}
\end{definition}

Then in fact, both $\func{im}\left( T\right) $ and $\ker \left( T\right) $
are subspaces of $W$ and $V$ respectively.

\begin{proposition}{Kernel and Image as Subspaces}{kernelimagevectorspaces}
Let $V,W$ be vector spaces and let $T:V\rightarrow W$ be a linear transformation. Then $\ker \left(
T\right) \subseteq V$ and $\func{im}\left( T\right) \subseteq W$. In fact, they are both subspaces. 
\end{proposition}

\begin{proof}
First consider $\ker \left( T\right) .$ It is necessary to
show that if $\vect{v}_{1},\vect{v}_{2}$ are vectors in $\ker \left( T\right) $
and if $a,b$ are scalars, then $a\vect{v}_{1}+b\vect{v}_{2}$ is also in $\ker
\left( T\right) .$ But 
\begin{equation*}
T\left( a\vect{v}_{1}+b\vect{v}_{2}\right) =aT(\vect{v}_{1})+bT(\vect{v}_{2})=a\vect{0}+b\vect{0}=\vect{0}
\end{equation*}
Thus $\ker \left( T\right) $ is a subspace of $V$.

Next suppose $T(\vect{v}_{1}),T(\vect{v}_{2})$ are two vectors in $\func{im}\left(
T\right) .$ Then if $a,b$ are scalars, 
\begin{equation*}
aT(\vect{v}_{2})+bT(\vect{v}_{2})=T\left( a\vect{v}_{1}+b\vect{v}_{2}\right)
\end{equation*}
and this last vector is in $\func{im}\left( T\right) $ by definition. 
\end{proof}

Consider the following example.

\begin{example}{Kernel and Image of a Transformation}{kernelimage}
Let $T:\mathbb{P}_1\to\mathbb{R}$ be the linear transformation defined by
\[ T(p(x))=p(1)\mbox{ for all } p(x)\in \mathbb{P}_1.\]
Find the kernel and image of $T$.
\end{example}

\begin{solution}
We will first find the kernel of $T$. It consists of all polynomials in $\mathbb{P}_1$ that have $1$ for a root. 
\begin{eqnarray*}
\func{ker}(T) & = & \{ p(x)\in \mathbb{P}_1 ~|~ p(1)=0\} \\
& = & \{ ax+b ~|~ a,b\in\mathbb{R} \mbox{ and }a+b=0\} \\
& = & \{ ax-a ~|~ a\in\mathbb{R} \}
\end{eqnarray*}
Therefore a basis for $\func{ker}(T)$ is 
\[
\left\{ x-1 \right\}
\]
Notice that this is a subspace of $\mathbb{P}_1$. 

Now consider the image. It consists of all numbers which can be obtained by evaluating all polynomials in $\mathbb{P}_1$ at $1$. 
\begin{eqnarray*}
\func{im}(T) & = & \{ p(1) ~|~ p(x)\in \mathbb{P}_1 \} \\
 & = & \{ a+b ~|~ ax+b\in \mathbb{P}_1 \} \\
 & = & \{ a+b ~|~ a,b\in\mathbb{R} \}\\
 & = & \mathbb{R}
\end{eqnarray*}
Therefore a basis for $\func{im}(T)$ is 
\[
\left\{ 1 \right\}
\]
Notice that this is a subspace of $\mathbb{R}$, and in fact is the space $\mathbb{R}$ itself. 
\end{solution}

\begin{example}{Kernel and Image of a Linear Transformation}{findingkernelimage}
Let $T: \mathbb{M}_{22} \mapsto \mathbb{R}^2$ be defined by
\[
T \leftB \begin{array}{cc}
a & b \\
c & d 
\end{array}
\rightB
 = 
\leftB
\begin{array}{c}
a - b \\
c + d
\end{array}
\rightB
\]
Then $T$ is a linear transformation. Find a basis for $\func{ker} (T)$ and $\func{im}(T)$.
\end{example}

\begin{solution}
You can verify that $T$ represents a linear transformation. 

Now we want to find a way to describe all matrices $A$ such that $T(A) = \vect{0}$, that is the matrices in $\func{ker}(T)$. 
Suppose $A = \leftB \begin{array}{cc}
a & b \\
c & d 
\end{array}
\rightB$ is such a matrix. 
Then
\[
T \leftB \begin{array}{cc}
a & b \\
c & d 
\end{array}
\rightB
 = 
\leftB
\begin{array}{c}
a - b \\
c + d
\end{array}
\rightB
 = 
\leftB
\begin{array}{c}
0 \\
0
\end{array}
\rightB
\]
The values of $a, b, c, d$ that make this true are given by solutions to the system
\begin{eqnarray*}
a - b &=& 0 \\
c + d &=& 0 
\end{eqnarray*}
The solution is $a = s, b = s, c = t, d = -t$ where $s, t$ are scalars. We can describe $\func{ker}(T)$ as follows.
\[
\func{ker}(T) = 
\left\{ 
\leftB \begin{array}{cc}
s & s \\
t & -t 
\end{array}
\rightB
\right\}
=
\func{span}
\left\{
\leftB \begin{array}{cc}
1 & 1 \\
0 & 0 
\end{array} \rightB, 
\leftB \begin{array}{cc}
0 & 0 \\
1 & -1 
\end{array} \rightB
\right\}
\]
It is clear that this set is linearly independent and therefore forms a basis for $\func{ker}(T)$. 

We now wish to find a basis for $\func{im}(T)$. We can write the image of $T$ as 
\[
\func{im}(T) = \left\{ 
\leftB \begin{array}{c}
a - b  \\
c + d  
\end{array}
\rightB
\right\}
\]
Notice that this can be written as 
\[
\func{span}
\left\{
\leftB \begin{array}{c}
1 \\ 
0
\end{array}\rightB, 
\leftB \begin{array}{c}
-1 \\ 
0
\end{array}\rightB, 
\leftB \begin{array}{c}
0 \\ 
1
\end{array}\rightB, 
\leftB \begin{array}{c}
0 \\ 
1
\end{array}\rightB \right\}
\]

However this is clearly not linearly independent. By removing vectors from the set to create an independent set gives a basis of $\func{im}(T)$.
\[
\left\{
\leftB \begin{array}{c}
1 \\ 
0
\end{array}\rightB, 
\leftB \begin{array}{c}
0 \\ 
1
\end{array}\rightB
\right\}
\]

Notice that these vectors have the same span as the set above but are now linearly independent.
\end{solution}

A major result is the relation between the dimension of the kernel and
dimension of the image of a linear transformation. A special case was done
earlier in the context of matrices. Recall that for an $m\times n$ matrix $%
A, $ it was the case that the dimension of the kernel of $A$ added to the
rank of $A$ equals $n$. 

\begin{theorem}{Dimension of Kernel + Image}{}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are vector
spaces. Suppose the dimension of $V$ is $n$.
Then $n=\dim \left( \ker \left( T\right) \right) +\dim \left( \func{im}
\left( T\right) \right) $.
\end{theorem}

\begin{proof}
From Proposition \ref{prop:kernelimagevectorspaces}, $\func{im}\left( T\right) $
is a subspace of $W.$ By Theorem \ref{thm:basisvectorspace}, there exists a basis for $
\func{im}\left( T\right) ,\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})\right\}
. $ Similarly, there is a basis for $\ker \left( T\right) ,\left\{ \vect{u}
_{1},\cdots ,\vect{u}_{s}\right\} $. Then if $\vect{v}\in V,$ there exist
scalars $c_{i}$ such that 
\begin{equation*}
T(\vect{v})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})
\end{equation*}
Hence $T\left( \vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}\right) =0.$ It follows
that $\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}$ is in $\ker \left( T\right) $.
Hence there are scalars $a_{i}$ such that 
\begin{equation*}
\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}=\sum_{j=1}^{s}a_{j}\vect{u}_{j}
\end{equation*}
Hence $\vect{v}=\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}
_{j}. $ Since $\vect{v}$ is arbitrary, it follows that 
\begin{equation*}
V=\func{span}\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}\right\}
\end{equation*}
If the vectors $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}\right\} $ are linearly independent, then it will follow that
this set is a basis. Suppose then that 
\begin{equation*}
\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}_{j}=0
\end{equation*}
Apply $T$ to both sides to obtain 
\begin{equation*}
\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})+\sum_{j=1}^{s}a_{j}T(\vect{u}
_{j})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})= \vect{0}
\end{equation*}
Since $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})\right\} $ is linearly
independent, it follows that each $c_{i}=0.$ Hence $\sum_{j=1}^{s}a_{j}\vect{u
}_{j}=0$ and so, since the $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s}\right\} $
are linearly independent, it follows that each $a_{j}=0$ also. It follows
that $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,\vect{v}
_{r}\right\} $ is a basis for $V$ and so 
\begin{equation*}
n=s+r=\dim \left( \ker \left( T\right) \right) +\dim \left( \func{im}\left(
T\right) \right)
\end{equation*}
\end{proof}

Consider the following definition. 

\begin{definition}{Rank of Linear Transformation}{}
Let $T:V\rightarrow W$ be a linear transformation and suppose $V,W$ are finite dimensional vector spaces. Then
the rank of $T$ denoted as $\func{rank}\left( T\right) $ is defined as the
dimension of $\func{im}\left( T\right) .$ The nullity of $T$ is the
dimension of $\ker \left( T\right) .$ Thus the above theorem says that $
\func{rank}\left( T\right) +\dim \left( \ker \left( T\right) \right) =\dim
\left( V\right) .$
\end{definition}

Recall the following important result. 

\begin{theorem}{Subspace of Same Dimension}{subspacevectorspace}
Let $V$ be a vector space of dimension $n$ and let $W$ be a
subspace. Then $W=V$ if and only if the dimension of $W$ is also $n$.
\end{theorem}

From this theorem follows the next corollary.

\begin{corollary}{One to One and Onto Characterization}{oneoneontochar}
Let $T:V\rightarrow W$ be a linear map where the dimension of $V$ is $n$ and
the dimension of $W$ is $m$. Then $T$ is one to one if and only if $\ker
\left( T\right) =\left\{ \vect{0}\right\} $ and $T$ is onto if and only if $
\func{rank}\left( T\right) =m$.
\end{corollary}

\begin{proof}
The statement $\ker \left( T \right) =\left\{ \vect{0}\right\} $
is equivalent to saying if $T \left( \vect{v} \right)=\vect{0},$ it follows that $\vect{v}=\vect{0}$
. Thus by Lemma \ref{lem:onetooneabstract} $T$ is one to one. If $T$ is onto, then $
\func{im}\left( T\right) =W$ and so $\func{rank}\left( T\right) $ which is
defined as the dimension of $\func{im}\left( T\right) $ is $m$. If $\func{
rank}\left( T\right) =m,$ then by Theorem \ref{thm:subspacevectorspace}, since $\func{im}
\left( T\right) $ is a subspace of $W,$ it follows that $\func{im}\left(
T\right) =W$. 
\end{proof}

\begin{example}{One to One Transformation}{onetoonekernel}
Let $S:\mathbb{P}_2\to\mathbb{M}_{22}$ be a linear transformation
defined by
\[ S(ax^2+bx+c)
=
\leftB\begin{array}{cc}
a+b & a+c \\ b-c & b+c \end{array}\rightB
\mbox{ for all }
 ax^2+bx+c\in \mathbb{P}_2.\]
Prove that $S$ is one to one but not onto.
\end{example}

\begin{solution}
You may recall this example from earlier in Example \ref{exa:onetoonegeneral}. Here we will determine that $S$ is one to one, but not onto, using the method provided in Corollary \ref{cor:oneoneontochar}.

By definition, 
\[ \ker(S)=\{ax^2+bx+c\in \mathbb{P}_2 ~|~ a+b=0,
a+c=0, b-c=0, b+c=0\}.\]

Suppose $p(x)=ax^2+bx+c\in\ker(S)$.
This leads to a homogeneous system of four equations in three 
variables.  
Putting the augmented matrix in \rref: 

\[ \leftB\begin{array}{rrr|c}
1 & 1 & 0 & 0  \\
1 & 0 & 1 & 0  \\
0 & 1 & -1 & 0  \\
0 & 1 & 1 & 0  \end{array}\rightB
\rightarrow \cdots \rightarrow
\leftB\begin{array}{ccc|c}
1 & 0 & 0 & 0  \\
0 & 1 & 0 & 0  \\
0 & 0 & 1 & 0  \\
0 & 0 & 0 & 0  \end{array}\rightB. \]

Since the unique solution is $a=b=c=0$, $\ker(S)=\{\vect{0}\}$, and thus
$S$ is one-to-one by Corollary \ref{cor:oneoneontochar}.

Similarly, by Corollary \ref{cor:oneoneontochar}, if $S$ is onto it will have $\func{rank}(S) = \func{dim}(\mathbb{M}_{22}) = 4$. The image of $S$ is given by 
\[
\func{im}(S) = \left\{ \leftB\begin{array}{cc}
a+b & a+c \\ b-c & b+c \end{array}\rightB \right\} = \func{span} \left\{ \leftB\begin{array}{rr}
1 & 1 \\
0 & 0 \end{array} \rightB, \leftB\begin{array}{rr}
1 & 0 \\
1 & 1 \end{array} \rightB, \leftB\begin{array}{rr}
0 & 1 \\
-1 & 1 \end{array} \rightB \right\}
\]
These matrices are linearly independent which means this set forms a basis for $\func{im}(S)$. Therefore the dimension of $\func{im}(S)$, also called $\func{rank}(S)$, is equal to $3$. It follows that $S$ is not onto. 
\end{solution}