
\subsection{The Matrix Exponential}

The goal of this section is to use the concept of the matrix exponential to solve first order linear differential equations. We begin by proving the matrix exponential. 

Suppose $A$ is a diagonalizable matrix. Then the {\bf matrix exponential}\index{matrix exponential}, written $e^{A}$, can be easily defined. 
Recall that if $D$ is a diagonal matrix, then  
\begin{equation*}
P^{-1}AP=D
\end{equation*}
$D$ is of the form 
\begin{equation}
\leftB 
\begin{array}{ccc}
\lambda _{1} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \lambda _{n}
\end{array}
\rightB  \label{diagonalmatrix}
\end{equation}
and it follows that 
\begin{equation*}
D^{m}=\leftB 
\begin{array}{ccc}
\lambda _{1}^{m} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \lambda _{n}^{m}
\end{array}
\rightB
\end{equation*}

Since $A$ is diagonalizable, 
\begin{equation*}
A=PDP^{-1}
\end{equation*}
and
\begin{equation*}
A^{m}=PD^{m}P^{-1}
\end{equation*}

Recall why this is true. 
\begin{equation*}
A=PDP^{-1}
\end{equation*}
and so 
\begin{eqnarray*}
A^{m} &=&\overset{
\text{m times}}{\overbrace{PDP^{-1}PDP^{-1}PDP^{-1}\cdots PDP^{-1}}} \\
&=&PD^{m}P^{-1}
\end{eqnarray*}

We now will examine what is meant by the matrix exponental $e^{A}$. Begin by formally writing the following power series for $e^{A}$:
\begin{equation*}
e^{A} =  \sum_{k=0}^{\infty }\frac{A^{k}}{k!}=\sum_{k=0}^{\infty }\frac{PD^{k}P^{-1}}{k!}=P \left( \sum_{k=0}^{\infty }\frac{D^{k}}{k!} \right)P^{-1}
\end{equation*}
If $D$ is given above in \ref{diagonalmatrix}, the above sum is of the form 
\begin{equation*}
P \left( \sum_{k=0}^{\infty }\leftB 
\begin{array}{ccc}
\frac{1}{k!}\lambda _{1}^{k} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \frac{1}{k!}\lambda _{n}^{k}
\end{array}
\rightB \right) P^{-1}
\end{equation*}
This can be rearranged as follows:
\begin{equation*}
e^{A}=P\leftB 
\begin{array}{ccc}
\sum_{k=0}^{\infty }\frac{1}{k!}\lambda _{1}^{k} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \sum_{k=0}^{\infty }\frac{1}{k!}\lambda _{n}^{k}
\end{array}
\rightB P^{-1}
\end{equation*}
\begin{equation*}
=P\leftB 
\begin{array}{ccc}
e^{\lambda _{1}} &  & 0 \\ 
& \ddots &  \\ 
0 &  & e^{\lambda _{n}}
\end{array}
\rightB P^{-1}
\end{equation*}

This justifies the following theorem. 

\begin{theorem}{The Matrix Exponential}{matrixexponential}
Let $A$ be a diagonalizable matrix, with eigenvalues $\lambda_1, ..., \lambda_n$and corresponding matrix of eigenvectors $P$. Then the matrix exponential, $e^{A}$, is given by
\begin{equation*}
e^{A} = 
P\leftB 
\begin{array}{ccc}
e^{\lambda _{1}} &  & 0 \\ 
& \ddots &  \\ 
0 &  & e^{\lambda _{n}}
\end{array}
\rightB P^{-1}
\end{equation*}
\end{theorem}

\begin{example}{Compute $e^A$ for a Matrix $A$}{}
Let
\begin{equation*}
A=\leftB
\begin{array}{rrr}
2 & -1 & -1 \\
1 & 2 & 1 \\
-1 & 1 & 2
\end{array}
\rightB
\end{equation*}
Find $e^{A}$.
\end{example}

\begin{solution}
The eigenvalues work out to be $1,2,3$ and eigenvectors associated with these
eigenvalues are 
\begin{equation*}
\leftB 
\begin{array}{r}
0 \\ 
-1 \\ 
1
\end{array}
\rightB \leftrightarrow 1,
\leftB 
\begin{array}{r}
-1 \\ 
-1 \\ 
1
\end{array}
\rightB \leftrightarrow 2,\leftB 
\begin{array}{r}
-1 \\ 
0 \\ 
1
\end{array}
\rightB \leftrightarrow 3
\end{equation*}
Then let 
\begin{equation*}
D=\leftB 
\begin{array}{rrr}
1 & 0 & 0 \\ 
0 & 2 & 0 \\ 
0 & 0 & 3
\end{array}
\rightB, P=\leftB 
\begin{array}{rrr}
0 & -1 & -1 \\ 
-1 & -1 & 0 \\ 
1 & 1 & 1
\end{array}
\rightB
\end{equation*}
and so 
\begin{equation*}
P^{-1}=\leftB 
\begin{array}{rrr}
1 & 0 & 1 \\ 
-1 & -1 & -1 \\ 
0 & 1 & 1
\end{array}
\rightB
\end{equation*}

Then the matrix exponential is 
\begin{equation*}
e^{At} = \leftB 
\begin{array}{rrr}
0 & -1 & -1 \\ 
-1 & -1 & 0 \\ 
1 & 1 & 1
\end{array}
\rightB \leftB 
\begin{array}{ccc}
e^{1} & 0 & 0 \\ 
0 & e^{2} & 0 \\ 
0 & 0 & e^{3}
\end{array}
\rightB \leftB 
\begin{array}{rrr}
1 & 0 & 1 \\ 
-1 & -1 & -1 \\ 
0 & 1 & 1
\end{array}
\rightB
\end{equation*}
\begin{equation*}
\leftB 
\begin{array}{ccc}
e^{2} & e^{2}-e^{3} & e^{2}-e^{3} \\ 
e^{2}-e & e^{2} & e^{2}-e \\ 
-e^{2}+e & -e^{2}+e^{3} & -e^{2}+e+e^{3}
\end{array}
\rightB 
\end{equation*}
\end{solution}

The matrix exponential is a useful tool to solve autonomous
systems of first order linear differential equations. These are equations
which are of the form 
\begin{equation*}
X^{\prime }=AX, X(0) = C
\end{equation*}
where $A $ is a diagonalizable $n\times n$ matrix and $C$ is a constant vector. $X$ is a vector of functions in one variable, $t$:
\begin{equation*}
X = X(t) = \leftB \begin{array}{c}
x_1(t) \\
x_2(t) \\
\vdots \\
x_n(t) 
\end{array}
\rightB
\end{equation*}
Then $X^{\prime }$ refers to the first derivative of $X$ and is given by 
\begin{equation*}
X^{\prime} = X^{\prime}(t) = \leftB \begin{array}{c}
x_1^{\prime}(t) \\
x_2^{\prime}(t) \\
\vdots \\
x_n^{\prime}(t) 
\end{array}
\rightB, \; x_i^{\prime}(t) = \text{the derivative of}\; x_i(t)
\end{equation*}

Then it turns out that the solution to the
above system of equations is $X\left( t\right) =e^{At}C$. To see this, suppose $A$ is
diagonalizable so that 
\begin{equation*}
A=P\leftB 
\begin{array}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{array}
\rightB P^{-1}
\end{equation*}
Then 
\begin{equation*}
e^{At}=P\leftB 
\begin{array}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{array}
\rightB P^{-1}
\end{equation*} 
\begin{equation*}
e^{At}C=P\leftB 
\begin{array}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{array}
\rightB P^{-1}C
\end{equation*}

Differentiating $e^{At}C$ yields
\begin{equation*}
X^{\prime} = \left( e^{At}C\right) ^{\prime }=P\leftB 
\begin{array}{ccc}
\lambda _{1}e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}e^{\lambda _{n}t}
\end{array}
\rightB P^{-1}C
\end{equation*}
\begin{equation*}
=P\leftB 
\begin{array}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{array}
\rightB \leftB 
\begin{array}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{array}
\rightB P^{-1}C
\end{equation*}
\begin{eqnarray*}
&=&P\leftB 
\begin{array}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{array}
\rightB P^{-1}P\leftB 
\begin{array}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{array}
\rightB P^{-1}C \\
&=&A\left( e^{At}C\right) = AX
\end{eqnarray*}
Therefore $X = X(t) = e^{At}C$ is a solution to $X^{\prime }=AX$. 

To prove that $X(0) =  C$ if $X(t) = e^{At}C$:
\begin{equation*}
X(0) = e^{A0}C=P\leftB 
\begin{array}{ccc}
1 &  &  \\ 
& \ddots &  \\ 
&  & 1
\end{array}
\rightB P^{-1}C=C
\end{equation*}

\begin{example}{Solving an Initial Value Problem}{}
Solve the initial value problem
\begin{equation*}
\leftB
\begin{array}{c}
x \\
y
\end{array}
\rightB ^{\prime }=\leftB 
\begin{array}{rr}
0 & -2 \\
1 & 3
\end{array}
\rightB \leftB
\begin{array}{c}
x \\
y
\end{array}
\rightB ,\ \leftB
\begin{array}{c}
x(0)\\
y(0)
\end{array}
\rightB  =\leftB
\begin{array}{c}
1 \\
1
\end{array}
\rightB
\end{equation*}
\end{example}

\begin{solution}
The matrix is diagonalizable and can be written as  
\begin{eqnarray*}
A &=& PDP^{-1} \\
\leftB  
\begin{array}{rr}
0 & -2 \\ 
1 & 3
\end{array}
\rightB &=&\leftB  
\begin{array}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{array}
\rightB \leftB 
\begin{array}{rr}
1 & 0 \\ 
0 & 2
\end{array}
\rightB \leftB 
\begin{array}{rr}
2 & 2 \\ 
-1 & -2
\end{array}
\rightB
\end{eqnarray*}
Therefore, the matrix exponential is of the form 
\begin{equation*}
e^{At} = \leftB  
\begin{array}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{array}
\rightB \leftB 
\begin{array}{cc}
e^{t} & 0 \\ 
0 & e^{2t}
\end{array}
\rightB \leftB 
\begin{array}{rr}
2 & 2 \\ 
-1 & -2
\end{array}
\rightB
\end{equation*}
The solution to the initial value problem is
\begin{eqnarray*}
X(t) &=& e^{At}C \\
\leftB 
\begin{array}{c}
x\left( t\right) \\ 
y\left( t\right)
\end{array}
\rightB &=& \leftB  
\begin{array}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{array}
\rightB \leftB 
\begin{array}{cc}
e^{t} & 0 \\ 
0 & e^{2t}
\end{array}
\rightB \leftB 
\begin{array}{rr}
2 & 2 \\ 
-1 & -2
\end{array}
\rightB \leftB 
\begin{array}{c}
1 \\ 
1
\end{array}
\rightB \\
&=&\leftB 
\begin{array}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{array}
\rightB
\end{eqnarray*}
We can check that this works: 
\begin{eqnarray*}
\leftB 
\begin{array}{c}
x\left( 0\right) \\ 
y\left( 0\right)
\end{array}
\rightB &=&
\leftB 
\begin{array}{c}
4e^{0}-3e^{2(0)} \\ 
3e^{2(0)}-2e^{0}
\end{array}
\rightB \\
&=&
\leftB 
\begin{array}{c}
1 \\ 
1
\end{array}
\rightB
\end{eqnarray*}

Lastly, 
\begin{equation*}
X^{\prime} = 
\leftB 
\begin{array}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{array}
\rightB ^{\prime }=\leftB 
\begin{array}{c}
4e^{t}-6e^{2t} \\ 
6e^{2t}-2e^{t}
\end{array}
\rightB
\end{equation*}
and 
\begin{equation*}
AX = \leftB  
\begin{array}{rr}
0 & -2 \\ 
1 & 3
\end{array}
\rightB \leftB 
\begin{array}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{array}
\rightB =\leftB 
\begin{array}{c}
4e^{t}-6e^{2t} \\ 
6e^{2t}-2e^{t}
\end{array}
\rightB
\end{equation*}
which is the same thing. Thus this is the solution to the initial value
problem.
\end{solution}


