
# "Метод автоматичного формування ієрархічної структури класів для розпізнавання об'єктів"

**author: "Науково-технічний звіт"**
**date: "23.07.2025"**
**lang: uk-UA**

---

У технічному звіті запропоновано формальний, інтуїтивно зрозумілий метод, який автоматично формує дерево рівнів/класів, спираючись на (і) відстані між векторними поданнями класів, (іі) величину невідповідності між ними та (ііі) прості порогові правила. Алгоритм узгоджує емпіричні спостереження авторів щодо трирівневої схеми «`H/V → T/B/O → G/M/Z`» й узагальнює їх до автоматично масштабованої процедури.

---

## 1. Запропонований метод

Метод складається з восьми послідовних кроків, що охоплюють процеси від вилучення ознак до експорту готової ієрархічної структури. На вхід подаються дані, зазначені в таблиці 1.

**Таблиця 1.** Вхідні дані для алгоритму.

| Позначення | Розмірність | Пояснення |
| :--- | :--- | :--- |
| $D=\{(x_i,y_i)\}_{i=1}^{N}$ | $N \times (\text{зображення} + \text{мітка})$ | Навчальний набір кадрів БПЛА з їхніми початковими мітками. |
| $L=\{l_1, \dots, l_m\}$ | $m$ | **Базові класи** (тобто найдрібніші, що вже не діляться). |
| $m$ | скаляр | Кількість базових класів. |
| $B$ | функція $\mathbb{R}^{H\times W\times3} \to \mathbb{R}^{d}$ | Back-bone, який перетворює ROI у вектор ознак розмірності $d$. |
| $\lambda \in [0,1]$ | скаляр | Коефіцієнт, що задає частку просторової відстані $\|\mu_p-\mu_q\|2$ відносно емпіричної невідповідності $(1-\Omega{pq}-\Omega_{qp})$ у комбінованій мірі $M_{pq}$. |
| $\delta_{\min}$ | скаляр | Мінімальна відстань між кластерами, за якої їх ще розділяємо. |
| $\varepsilon_{\max}$ | скаляр | Максимально допустима частка помилкових сплутувань усередині кластера. |
| $\Theta=(\text{FPS}_{\min}, T_{\max})$ | вектор $2\times1$ | Мінімальна швидкість (кадрів/с) та максимальна латентність (мс). |

---

### 1.1. Крок 1: Вилучення ознак для усіх ROI

Перший етап є підготовчим. Його мета — перетворити кожну область інтересу (ROI) на зображенні у числовий вектор (ембединг), з яким можна виконувати математичні операції.

1. Для кожного зображення $x_i$ виконуємо первинне детектування (будь-який SOTA-детектор) та отримуємо множину ROI $R_i=\{r_{i1}, \dots, r_{ik}\}$.
2. Для кожного ROI обчислюємо вектор ознак:
    $$f_{ij}=B(r_{ij}) \in \mathbb{R}^{d}.$$

> **Примітка 1.** Для забезпечення відтворюваності використовується однаковий базовий детектор ROI на всіх рівнях — `YOLOv11-m` з конфігурацією `confidence=0.25`, `IoU=0.5`. Усі подальші моделі $D_k$ працюють з уже обрізаними ROI і не виконують повторного пошуку об'єктів.
> **Примітка 2.** Дані діляться на train/val/test у пропорції 70 / 15 / 15 %, що жорстко фіксується через random seed = 2025.

---

### 1.2. Крок 2: Побудова «профілю» класу

На цьому етапі для кожного базового класу ми обчислюємо дві ключові характеристики: його усереднене представлення у просторі ознак (центроїд) та те, як часто його плутають з іншими класами (матриця невідповідності). Ці два показники стануть основою для вимірювання «близькості» між класами.

1. Для кожного атомарного класу $l \in L$ збираємо множину ознак $F_l=\{f_{ij} \mid y_{ij}=l\}$.
2. Обчислюємо **центроїд**:
    $$\mu_l=\frac{1}{|F_l|}\sum_{f \in F_l}f. \quad(1)$$
3. Одноразово навчаємо одноетапний класифікатор без ієрархії $C^{\text{flat}}$ (наприклад, простий `MLP`) на всіх $f_{ij}$ та формуємо **матрицю невідповідності**:
    $$\Omega\in[0,1]^{m\times m}, \quad \Omega_{pq}=\frac{\text{FP}(p\to q)}{\sum_{q'}\text{FP}(p\to q')}, \quad(2)$$
    де $\text{FP}(p\to q)$ — кількість неправильних присвоєнь $p \mapsto q$.

Тут під одноетапним класифікатором без ієрархії $C^{\text{flat}}$ розуміємо модель, що одразу прогнозує один з усіх $m$ базових класів без ієрархії.

---

### 1.3. Крок 3: Визначення міри близькості між класами

Тут ми поєднуємо дві метрики з попереднього кроку в єдиний показник $M_{pq}$. Ця міра близькості враховує як геометричну відстань між центроїдами класів, так і емпіричні дані про те, наскільки часто класифікатор їх плутає. Параметр $\lambda$ дозволяє регулювати важливість кожного з цих компонентів. Комбінація відбувається за формулою (3):

$$M_{pq} = \lambda \cdot \|\mu_p-\mu_q\|_2 + (1-\lambda)\cdot(1-\Omega_{pq}-\Omega_{qp}), \qquad p\neq q. \quad(3)$$

> *Чим більшим є $M_{pq}$ — тим легше класи розділити.*

---

### 1.4. Крок 4: Ієрархічне агломеративне групування

Це ядро алгоритму, де відбувається безпосередня побудова ієрархії. Використовуючи обчислену міру близькості $M_{pq}$, ми застосовуємо метод кластеризації, який послідовно об'єднує найближчі класи. Потім, рухаючись по отриманій дендрограмі, ми приймаємо рішення про поділ або об'єднання груп на основі заданих порогів, перевіряючи умову (4).

1. Будуємо повнозважений граф з вагами $M_{pq}$ та застосовуємо `agglomerative clustering (average linkage)`, отримуючи дендрограму $T$.
2. Переходимо зверху донизу: для кожної внутрішньої вершини $S \subseteq L$ перевіряємо умову:
    $$\min_{p\neq q \in S} M_{pq} < \delta_{\min} \land \frac{\sum_{p,q \in S, p \neq q} \Omega_{pq}}{|S|(|S|-1)} > \varepsilon_{\max}. \quad(4)$$

* Якщо **умова виконується** → **не розділяємо** (класи лишаються у цьому ж листі).
* Якщо **умова не виконується** → **ділимо** вершину на її дві дочірні кластери й повторюємо перевірку.

У результаті маємо $K$ рівнів $\{L_1, \dots, L_K\}$ з дедалі дрібнішими класами; алгоритм природно повторює логіку `H/V → T/B/O → G/M/Z` з рукопису, але без ручного втручання.

---

### 1.5. Крок 5: Призначення моделей на кожен рівень ієрархії

Після того, як структура ієрархії визначена, необхідно для кожного її рівня підібрати оптимальні моделі детектора та класифікатора. Вибір відбувається автоматично на основі характеристик рівня (кількість класів, розмір об'єктів) та апаратних обмежень.

> **Мета:** для кожного рівня $k$ вибрати пару **детектор $D_k$** і **класифікатор $C_k$** так, щоб:
>
> 1. виконувалися ресурсні обмеження $\Theta=(\text{FPS}_{\min}, T_{\max})$;
> 2. модель залишалася придатною до малого/великого числа класів та розміру об’єктів.

#### 1.5.1. Вхідні параметри (усі легко вимірювані)

**Таблиця 2.** Вхідні параметри для вибору моделей на рівні $k$.

| Змінна | Розмірність / Тип | Як отримати | Що означає |
| :--- | :--- | :--- | :--- |
| $\|L_k\|$ | скаляр (ціле) | Обчислити кількість унікальних підкласів, що залишилися на рівні $k$. | Скільки категорій треба розрізняти на поточному рівні. |
| $\bar{s}_k$ | скаляр (пікселі) | Взяти медіану значень $\sqrt{w_{ij}h_{ij}}$ для всіх ROI рівня $k$. | Середній лінійний розмір об’єктів, які обробляє рівень. |
| $FPS_{\min}$ | скаляр (кадри/с) | Задано технічним завданням. | Мінімально допустима швидкість системи в робочому режимі. |
| $T_{\max}$ | скаляр (мс) | Задано технічним завданням. | Гранична сумарна латентність повного каскаду. |
| $C_{\text{GPU}}$ | скаляр (TFLOPS) | Паспортна потужність доступного GPU (або фактична, виміряна утилітою `nvidia-smi`). | Обчислювальний ресурс, на який спирається вибір «важкої» чи «легкої» моделі. |

##### 1.5.2. Дерево рішень (детермінований алгоритм)

Логіка вибору моделей базується на наборі `if-elif-else` правил, що враховують параметри з таблиці 2.

```python
# ---- детермінований вибір моделей на рівні k ----
if |L_k| <= 2 and bar_s_k >= 48:
    D_k = "YOLOv11-l";    F_k = "CSPDarknet-53"
    C_k = "MLP(256)"
elif 3 <= |L_k| <= 6 and bar_s_k >= 32:
    D_k = "YOLOv11-m";    F_k = "CSPDarknet-53+SPP-FPN"
    C_k = "FT-Transformer(d=512,h=8,blocks=2)"
else:  # |L_k| > 6  or  bar_s_k < 32
    D_k = "RT-DETR-Tiny"; F_k = "CSPDarknet-53+FPN+CARAFE"
    C_k = "FT-Transformer(d=768,h=12,blocks=4)"

# ---- ресурсне зниження складності ----
if C_GPU < 5.0:           # TFLOPS
    D_k = "YOLO-Nano";    F_k = "Lite-FPN"
    C_k = "MobileNet-MLP(128)"
```

> **Примітка 1.** Значення 5.0 TFLOPS відповідає орієнтовній межі між «десктопними» та «вбудованими» GPU‑платформами (Jetson AGX Orin ≈ 4 TFLOPS FP16).

#### 1.5.3. Правила корекції

Для забезпечення надійності системи застосовуються додаткові правила корекції.

1. **Перевірка латентності:** якщо сумарна латентність рівня $T_k > T_{\max}/K$, знижуємо варіант на один рівень у дереві.
2. **Малі об’єкти** ($\bar{s}_k < 16$ px): додаємо попередню SR-підвищувальну мережу (наприклад, `ESRGAN` ×2) перед $D_k$.
3. **FPS-тест:** якщо фактичний FPS $<\text{FPS}_{\min}$, замінюємо $C_k$ на компактний `MLP` і повторюємо тест.
4. **Баланс витрат енергії:** якщо сумарне споживання енергії (W) перевищує 80 % паспортного TDP платформи, замінюємо RT‑DETR‑Tiny -> YOLOv11‑m та повторюємо FPS‑тест.

#### 1.5.4. Відтворюваність

Алгоритм забезпечує високу відтворюваність результатів.

* **Порогові значення** (48 px, 32 px, 16 px, TFLOPS = 5) обрано на базі емпіричних меж; у реплікації їх можна варіювати, але сам алгоритм (порівняння «`>` / `≤`») залишається сталим.
* **Вхідні змінні** $|L_k|$, $\bar{s}_k$, $C_{\text{GPU}}$ вимірюються однозначно; отже для тих самих даних і «заліза» вибір моделей повториться.
* Таблиця/псевдокод вище може бути реалізована в кілька рядків Python (`if-elif-else`), тому pipeline легко інтегрується у `CI`.

**Вихід:** для кожного рівня $k$ повертаємо пару ($D_k$, $C_k$), гарантувавши, що вся ієрархія задовольняє $\Theta$ і не потребує ручного тюнінгу.

#### 1.5.5. Дерево рішень (таблична форма)

Правила вибору моделей, описані в псевдокоді, можна представити у більш структурованій табличній формі (таблиця 3).

**Таблиця 3.** Дерево рішень для вибору моделей.

| Вхідні умови | Детектор $D_k$ | Вилучення $F_k$ | Класифікатор $C_k$ |
| :--- | :--- | :--- | :--- |
| $\|L_k\| \le 2$ та $\bar{s}_k > 48$ px | **`YOLOv11-l`** (≈130 FPS на RTX 3090) | Стандартний `CSPDarknet-53` | **`Linear MLP`** (1 прих. шар, 256 нейронів) |
| $3 \le \|L_k\| \le 6$ та $\bar{s}_k \ge 32$ px | **`YOLOv11-m`** | `CSPDarknet-53` + `SPP-FPN` | **`FT-Transformer`** (d=512, h=8, 2 блоки) |
| $\|L_k\| > 6$ або $\bar{s}_k < 32$ px | **`RT-DETR-Tiny`** (ембединг 256) | `CSPDarknet-53` + `FPN` + `CARAFE` | **`FT-Transformer`** (d=768, h=12, 4 блоки) |
| При дефіциті TFLOPS ($C_{\mathrm{GPU}} < 5$) | **`YOLO-Nano`** | Lightweight `FPN` | **`MobileNet-MLP`** |

---

### 1.6. Крок 6: Послідовне (ззовні → всередину) навчання

Навчання моделей відбувається послідовно, від найвищого (найзагальнішого) рівня ієрархії до найнижчого (найспецифічнішого). Моделі глибших рівнів навчаються лише на тих даних, які були правильно класифіковані на попередньому рівні, що дозволяє їм спеціалізуватися на розрізненні дедалі більш подібних класів.

1. Навчаємо ($D_1$, $F_1$, $C_1$) на всьому датасеті.
2. Для кожного наступного рівня $k$: використовуємо тільки ті ROI, які попередній рівень відніс до надкласу, та навчаємо ($D_k$, $F_k$, $C_k$).
3. Для побудови **конкатенованого вектора ознак** шукаємо підмножину шарів $\mathcal{S}$ максимізуючи вираз (5):
    $$\Phi(\mathcal{S})=\min_{p\neq q \in L_k}\|\mu_{p,\mathcal{S}}-\mu_{q,\mathcal{S}}\|_2, \quad(5)$$
    аналогічно вибору у таблиці 1 і рис. 5 рукопису.

> **Алгоритм вибору $\mathcal{S}$.** Використовуємо жадібну процедуру:
>
> 1. Стартуємо з найглибшого шару back‑bone.
> 2. На кожній ітерації додаємо той шар, що дає найбільший приріст $\Phi(\mathcal{S})$ (формула 5) на валідації.
> 3. Зупиняємося, коли приріст < 0.5 %, або кількість шарів > 3.

---

### 1.7. Крок 7: Калібрування порогів та перевірка ресурсних обмежень

Фінальний етап перед експортом — це тонке налаштування та верифікація. Для кожного класифікатора визначається оптимальний поріг впевненості, а вся система перевіряється на відповідність вимогам до швидкості та затримок. Якщо обмеження не виконуються, алгоритм може повернутися до попередніх кроків для спрощення ієрархії.

1. Для кожного $C_k$ калібруємо поріг довіри $p_k^\star$ методом Youden‑J на ROC‑кривій, щоб мінімізувати error‑propagation униз по каскаду. Тут $p_k^\star$ слугує оптимальним порогом довіри класифікатора $C_k$.
2. Обчислюємо сумарну латентність і FPS; якщо не виконує $\Theta$ — збільшуємо $\delta_{\min}$ (отримаємо менше рівнів) та/або замінюємо моделі згідно з правилами з розділу 1.5.

> **Застереження.** Після зміни $\delta_{\min}$ у кроці 7 алгоритм **повторно** перераховує матрицю $M$ й запускає Крок 4, інакше отримана ієрархія буде несумісна з новим порогом.

---

### 1.8. Крок 8: Експорт структури

Результатом роботи алгоритму є готова до розгортання структура: конфігураційний файл, що описує ієрархію та призначені моделі, а також самі навчені моделі.

Формуємо `JSON`/`YAML`‑файл:

```yaml
levels:
  - id: 1
    classes: ["H","V"]
    detector: YOLOv11-l
    classifier: FT-Transformer
    threshold: 0.82
  - id: 2
    parent_class: "V"
    classes: ["T","B","O"]
    detector: YOLOv11-m
    classifier: FT-Transformer
    threshold: 0.80
  - id: 3
    parent_class: "O"
    classes: ["G","M","Z"]
    detector: YOLOv11-m
    classifier: MLP
    threshold: 0.78
```

* збережені ваги моделей.

---

**Вихідні дані:**

* Дерево ієрархії $H=(L_1, \dots, L_K)$ з моделями $\{(D_k, F_k, C_k)\}_{k=1}^{K}$.
* Конфігураційний файл для розгортання на БПЛА чи наземній станції.
* Аналітичний звіт (таблиці метрик, граф FPS-vs-F1, дендрограма).

---

## 2. Глосарій

**Таблиця 4.** Опис усіх позначень.

| Позначення | Розмірність | Значення |
| :--- | :--- | :--- |
| $N$ | скаляр | Кількість зображень у датасеті. |
| $x_i$ | $H\times W\times3$ | $i$-те зображення RGB. |
| $y_i$ | скаляр з діапазону $[1,m]$ | Базова мітка з множини $L$. |
| $m$ | скаляр | Число базових (найдрібніших) класів. |
| $f_{ij}$ | $\mathbb{R}^{d}$ | Вектор ознак $j$-го ROI на $x_i$. |
| $d$ | скаляр | Розмірність простору ознак після $B$. |
| $\mu_l$ | $\mathbb{R}^{d}$ | Центроїд ознак класу $l$. |
| $\Omega$ | $m\times m$ | Матриця нормованих помилок між парами класів. |
| $M$ | $m\times m$ трикутна | Матриця комбінованої близькості (формула 3). |
| $K$ | скаляр | Кінцева кількість ієрархічних рівнів. |
| $L_k$ | множина | Підмножина класів, що розрізняється на рівні $k$. |
| $\|L_k\|$ | скаляр | Поточна кількість підкласів на рівні $k$. |
| $k$ | індекс $1 \dots K$ | Номер рівня в ієрархії. |

## 3. Коротке обґрунтування автоматизованого підходу

**Таблиця 5.** Порівняння ручного та автоматичного підходів.

| Критерій | Ручна схема (2.4–2.5) | Автоматичний алгоритм |
| :--- | :--- | :--- |
| Вибір рівнів/класів | емпірично | формула (4) |
| Підбір моделей | фіксований | дерево рішень (таблиця 3) |
| Пороги довіри | не описано | калібрування (розділ 1.7) |
| Підтримка FPS | декларативно | перевірка (розділ 1.7) |
| Масштабування на нові класи | ручне | повторити кроки 1.1–1.4 |

Алгоритм робить побудову структури **трасованою, відтворюваною** й адаптивною до нових наборів класів чи апаратних обмежень, зберігаючи концепцію, закладену авторами.