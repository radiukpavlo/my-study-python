# Специфікація програмного забезпечення

**subtitle:** "Проєкт: Автоматичне формування ієрархічної структури класів для розпізнавання об'єктів"
**version:** "1.0-alpha"
**date:** "2025-07-23"
**lang:** uk-UA

---

**Мова реалізації:** `Python 3.11`
**Цільова платформа:** `Linux x86-64/ARM64`, `Windows 10/11 x86-64`
**Вимоги до GPU:** `CUDA >= 12.1`, `cuDNN >= 9`

---

## 1. Загальний огляд

Програмне забезпечення (ПЗ) реалізує повний конвеєр (`pipeline`) із 8 етапів, описаний у науково-технічному звіті (НТЗ). Конвеєр приймає відеопотік або статичний набір зображень із БПЛА, деталізує об’єкти до багаторівневої ієрархії та експортує готову структуру (моделі + конфігураційний файл) у форматах `ONNX`, `TorchScript` та `YAML`.

Весь код відповідає стандартам `PEP 8`, використовує статичні типи згідно з `PEP 484`, містить модульні тести для кожної логічної одиниці та налаштовану безперервну інтеграцію (`CI`) на `GitHub Actions`.

---

## 2. Терміни й скорочення

* **ROI** — Region of Interest, прямокутник навколо об’єкта.
* **Back-bone $B$** — CNN-мережа `CSPDarknet-53`, попередньо навчена на датасеті `COCO`.
* **Agglo-кластеризація** — `AgglomerativeClustering` із параметром `linkage='ward'` з бібліотеки `scikit-learn`.
* **`Hydra`** — система для керування конфігураціями, що дозволяє комбінувати `YAML`-файли.
* **`MLflow`** — сервіс для відстеження параметрів та результатів експериментів.

---

## 3. Нефункціональні вимоги

**Таблиця 1.** Нефункціональні вимоги до програмного забезпечення.

| Категорія | Вимога |
|:---|:---|
| **Якість коду** | Дотримання `PEP 8`/`PEP 257`; обов’язкові підказки типів (`type hints`) згідно з `PEP 484`. |
| **Продуктивність** | ≥ 30 FPS на `NVIDIA RTX 3060`; ≥ 15 FPS на `NVIDIA Jetson AGX Orin`. |
| **Пам’ять** | Пікове споживання < 6 GB GPU RAM у режимі висновку (`inference`). |
| **Відтворюваність** | Фіксоване початкове значення для генератора випадкових чисел (`random seed = 2025`); кожен запуск в `MLflow` містить `git-hash` та параметри `Hydra`. |
| **Безперервна інтеграція** | Автоматичне тестування, лінтинг та збірка `ONNX`-моделей у `GitHub Actions`. |
| **Ліцензії** | Усі залежності мають бути сумісні з ліцензіями `Apache-2.0` або `MIT`. |

---

## 4. Функціональні вимоги

**Таблиця 2.** Функціональні вимоги до програмного забезпечення.

| ID | Опис |
|:---|:---|
| **FR-1** | Завантажити датасет у форматі `COCO-JSON` або `YOLOv5 TXT`. |
| **FR-2** | Виконати первинне детектування ROI за допомогою детектора `YOLOv11-m`. |
| **FR-3** | Вилучити ознаки $f_{ij}=B(r_{ij})$ та зберегти їх у файл формату `HDF5`. |
| **FR-4** | Обчислити центроїди $\mu_l$ та матрицю плутанини $\Omega$. |
| **FR-5** | Побудувати матрицю близькості $M$ (формула (3) з НТЗ) та дендрограму $T$. |
| **FR-6** | Згенерувати ієрархічні рівні $L_k$ згідно з умовою (4) з НТЗ. |
| **FR-7** | Для кожного рівня $k$ вибрати моделі $D_k$, $F_k$, $C_k$ за допомогою дерева рішень. |
| **FR-8** | Навчити моделі для рівнів `1...K`, логуючи результати в `MLflow`. |
| **FR-9** | Калібрувати пороги впевненості $p_k^*$ та виконати тест продуктивності (FPS/латентність). |
| **FR-10** | Експортувати навчені моделі в `ONNX` та `TorchScript`; створити фінальний `YAML`-конфіг. |

---

## 5. Архітектура

### 5.1. Структура каталогів

```text
auto_hierarchy/
├─ auto_hierarchy/
│   ├─ data/              # Завантаження та трансформації даних
│   ├─ features/          # Вилучення ознак
│   ├─ clustering/        # Кроки 3–4: побудова матриці близькості та кластеризація
│   ├─ modeling/          # Вибір та навчання моделей D_k, C_k
│   ├─ evaluation/        # Калібрування порогів, тести продуктивності
│   ├─ export/            # Експорт у формати ONNX та YAML
│   ├─ utils/             # Допоміжні функції
│   └─ main.py            # Головний скрипт для запуску
├─ configs/               # Конфігураційні файли Hydra (YAML)
├─ tests/                 # Модульні та інтеграційні тести (pytest)
├─ requirements.txt       # Список залежностей
└─ pyproject.toml         # Конфігурація проєкту
```

### 5.2. Основні зовнішні бібліотеки

**Таблиця 3.** Перелік основних зовнішніх залежностей.

| Бібліотека | Версія | Призначення |
|:---|:---|:---|
| **PyTorch** | `2.3` | Основний фреймворк для глибокого навчання. |
| **PyTorch Lightning** | `2.3` | Високорівнева обгортка для спрощення тренувального циклу. |
| **scikit-learn** | `1.7` | Реалізація `AgglomerativeClustering`. |
| **Ultralytics YOLO** | `v8.2` | Детектори `YOLOv11-m` (форк на базі `v8`). |
| **rt-detr** | `0.1-dev` | Попередня реалізація детектора `RT-DETR-Tiny`. |
| **Hydra-core** | `1.4` | Керування конфігураціями. |
| **MLflow** | `2.11` | Відстеження експериментів. |

---

## 6. Детальна декомпозиція модулів

### 6.1. Модуль `data/`

| Клас / Функція | Обов’язки |
|:---|:---|
| `DatasetLoader` | Читає датасети у форматах `COCO`/`YOLO`, виконує розбиття на `train`/`val`/`test`. |
| `ROICropper` | Використовує детектор `YOLOv11-m` для виявлення та обрізки ROI. |
| `HDF5Writer` | Серіалізує об'єкти $r_{ij}$, $y_{ij}$ у формат `HDF5` для ефективного доступу. |

### 6.2. Модуль `features/`

* `FeatureExtractor`: обгортка над back-bone моделлю $B$; реалізує кешування ознак на диску.
* Використовує `torch.compile` для оптимізації швидкості вилучення ознак.

### 6.3. Модуль `clustering/`

* `CentroidCalculator`: обчислює центроїди $\mu_l$ (формула (1) з НТЗ).
* `ConfusionMatrix`: тренує $C_{\text{flat}}$, обчислює матрицю плутанини $\Omega$.
* `DistanceMatrixBuilder`: нормує метрики та формує фінальну матрицю близькості $M$ (формула (3) з НТЗ).
* `AggloBuilder`: створює дендрограму за допомогою `sklearn.cluster.AgglomerativeClustering` та виконує умову розрізання (формула (4) з НТЗ).

### 6.4. Модуль `modeling/`

| Компонент | Вміст |
|:---|:---|
| `ModelSelector` | Реалізує дерево рішень (див. розділ 1.5.2 НТЗ) в одному методі `select(level_stats)`. |
| `LevelTrainer` | Абстракція над навчанням пари $D_k$, $C_k$$ за допомогою `PyTorch Lightning`; зберігає чекпоінти. |
| `SuperResolutionWrapper` | Обгортка для `ESRGAN x2`, що застосовується у випадку $\bar{s}_k < 16$. |

### 6.5. Модуль `evaluation/`

* `LatencyTester`: вимірює затримку $T_k$, FPS та утилізацію `GPU`/`CPU`.
* `ThresholdCalibrator`: знаходить оптимальний поріг $p_k^*$ за допомогою ROC-кривої (критерій Юдена J).
* `EnergyProfiler`: зчитує енергоспоживання GPU за допомогою `nvidia-smi --query-gpu=power.draw`.

### 6.6. Модуль `export/`

* `ONNXExporter`, `TorchScriptExporter`: експортують та валідують моделі.
* `YamlWriter`: збирає фінальний конфігураційний файл, що описує ієрархію, пороги та шляхи до ваг моделей.

---

## 7. Алгоритмічні деталі

### 7.1. Побудова матриці $M$

1. **Геометрична складова:** відстані між центроїдами $\|\mu_p - \mu_q\|_2$ нормалізуються до діапазону `[0, 1]`.
2. **Конфузійна складова:** матриця плутанини симетризується $\Omega_{pq} + \Omega_{qp}$ та також нормалізується.
3. **Комбінація:** компоненти поєднуються з вагою $\lambda$ та зберігаються у `NumPy`-матрицю типу `float32`.

### 7.2. Agglomerative Clustering

```python
from sklearn.cluster import AgglomerativeClustering

agg = AgglomerativeClustering(
    linkage="ward",
    affinity="euclidean",
    distance_threshold=delta_min,
    n_clusters=None,
    compute_full_tree=True
)
labels = agg.fit_predict(M_sym)
```

### 7.3. Умова розрізання

Реалізовано рекурсивний обхід дерева кластерів: якщо кластер $S$ задовольняє умову (4) з НТЗ, він фіксується як лист ієрархії, інакше — рекурсивно ділиться на дочірні кластери.

### 7.4. Вибір моделей

Алгоритм дерева рішень (розділ 1.5.2 НТЗ) є детермінованим. Будь-які зміни у виборі моделі детектора $D_k$ призводять до автоматичного оновлення графу латентності, що зберігає відповідність "клас → шлях моделі".

---

## 8. Інтерфейси та API

### 8.1. CLI-утиліта `auto-hier`

```sh
$ auto-hier \
  --data_path /path/to/data \
  --config-name base.yaml \
  model_selector.lambda=0.65
```

* **Команди:** `run`, `resume`, `export`, `eval`.
* Аргументи обробляються за допомогою `Hydra`; кожен параметр може бути перезаписаний через командний рядок.

### 8.2. Python SDK

```python
from auto_hierarchy import Pipeline, PipelineConfig

# Завантаження конфігурації з файлу
cfg = PipelineConfig.from_yaml("configs/base.yaml")

# Створення та запуск конвеєра
pipeline = Pipeline(cfg)
pipeline.fit()
pipeline.export(output_dir="artifacts/")
```

---

## 9. Документація та стиль коду

* **Док-рядки:** `Google-style`, перевіряються за допомогою `pydocstyle`.
* **Лінтінг та форматування:** `ruff` та `black` (120 символів на рядок).
* **Типізація:** `mypy --strict`.
* **Документація:** `Sphinx` для генерації HTML-документації з розгортанням на `GitHub Pages`.

---

## 10. Тестування

**Таблиця 4.** Стратегія тестування.

| Рівень | Інструмент | Покриття |
|:---|:---|:---|
| **Unit** | `pytest` + `hypothesis` | ≥ 90 % |
| **Integration** | `PyTorch Lightning` (`Trainer(fast_dev_run=True)`) | Кожен етап конвеєра |
| **E2E** | `pytest` + `torch.cuda.amp` на 50 зображеннях | Валідація вихідного `YAML` та FPS |

Приклад CI workflow (`GitHub Actions`):

```yaml
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11"]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - run: pip install -r requirements.txt
      - run: pytest -q
```

---

## 11. План робіт для одного розробника

**Таблиця 5.** План робіт.

| Тиждень | Задачі | Артефакти |
|:---|:---|:---|
| 1 | Проєктування репозиторію, `DatasetLoader`, `ROICropper`. | `PR #1` |
| 2 | `FeatureExtractor`, кешування в `HDF5`. | `PR #2` |
| 3 | `CentroidCalculator`, `ConfusionMatrix`, тест-документація. | `PR #3` |
| 4 | `DistanceMatrixBuilder`, `AggloBuilder`. | `PR #4` |
| 5 | `ModelSelector`, підготовка `YAML`-конфігів. | `PR #5` |
| 6 | `LevelTrainer` (`Lightning`), інтеграція `MLflow`. | `PR #6` |
| 7 | `LatencyTester`, `ThresholdCalibrator`. | `PR #7` |
| 8 | `ONNXExporter`, `YamlWriter`, end-to-end скрипт. | `PR #8` |
| 9 | Пакування, документація `Sphinx`, `Dockerfile`. | `реліз 0.9` |
| 10 | Високорівнева оптимізація, профілювання, фіналізація. | `реліз 1.0` |

---

## 12. Ризики та їх пом'якшення

**Таблиця 6.** Аналіз ризиків.

| Ризик | Вплив | Дії з пом'якшення |
|:---|:---|:---|
| Недоступність ваг для `RT-DETR-Tiny` | Середній | Використовувати `YOLOv11-m` як запасний варіант. |
| Перевитрата GPU RAM | Високий | Застосувати тренування зі змішаною точністю (`torch.cuda.amp`). |
| Нестабільний FPS на `Jetson` | Середній | Виконати квантизацію моделей до `INT8` за допомогою `TensorRT`. |

---

## 13. Ліцензія та відповідність

Увесь вихідний код проєкту розповсюджується під ліцензією `Apache 2.0`. Сторонні моделі перевірено на сумісність ліцензій (зокрема, код `Ultralytics YOLO` не містить посилань на `GPL`). Документація включає файл `Third-party licenses notice`.

---

## 14. Додатки

* **Додаток A:** Приклад схеми даних у файлі `HDF5`.
* **Додаток B:** Повний список гіперпараметрів та їх діапазонів для автоматичного підбору.
* **Додаток C:** Приклад повної `YAML`-конфігурації `Hydra`.
