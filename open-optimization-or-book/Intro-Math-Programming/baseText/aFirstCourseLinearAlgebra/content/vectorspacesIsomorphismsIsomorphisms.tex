\subsection{Isomorphisms}

The focus of this section is on linear transformations which are both one to one and onto. When this is the case, we call the transformation an isomorphism.

\begin{definition}{Isomorphism}{isomorphism}
Let $V$ and $W$ be two vector spaces and let $T: V \mapsto W$ be a linear transformation. 
Then $T$ is called an \textbf{isomorphism} 
\index{isomorphism}if the following two conditions are satisfied.

\begin{itemize}
\item $T$ is one to one. 

\item $T$ is onto.
\end{itemize}
\end{definition}

\begin{definition}{Isomorphic}{isomorphic}
Let $V$ and $W$ be two vector spaces and let $T: V \mapsto W$ be a linear transformation. 
Then if $T$ is an isomorphism, we say that $V$ and $W$ are \textbf{isomorphic.}
\index{isomorphic}
\end{definition}

Consider the following example of an isomorphism.

\begin{example}{Isomorphism}{isomorphism}
Let $T:\mathbb{M}_{22}\to\mathbb{R}^4$ be defined by
\[
T\leftB\begin{array}{cc} a & b \\ c & d \end{array}\rightB
=\leftB\begin{array}{c} a\\ b\\ c \\ d \end{array}\rightB
\mbox{ for all }
\leftB\begin{array}{cc} a & b \\ c & d \end{array}\rightB
\in\mathbb{M}_{22}. \]
Show that $T$ is an isomorphism.
\end{example}

\begin{solution}
Notice that if we can prove $T$ is an isomorphism, it will mean that $\mathbb{M}_{22}$ and $\mathbb{R}^4$ are isomorphic.
It remains to prove that 
\begin{enumerate}
\item $T$ is a linear transformation;
\item $T$ is one-to-one;
\item $T$ is onto.
\end{enumerate}

\textbf{$T$ is linear:}
Let $k,p$ be scalars.
\begin{eqnarray*}
T \left( k \leftB\begin{array}{cc} a_1 & b_1 \\ c_1 & d_1 \end{array}\rightB +  p \leftB\begin{array}{cc} a_2 & b_2 \\ c_2 & d_2 \end{array}\rightB \right) 
&=& T \left(  \leftB\begin{array}{cc} k a_1 & k b_1 \\ k c_1 & k d_1 \end{array}\rightB +  \leftB\begin{array}{cc} p a_2 & p b_2 \\ p c_2 & p d_2 \end{array}\rightB \right) \\
&=& T \left(  \leftB\begin{array}{cc} k a_1 + p a_2 & k b_1 + p b_2 \\ k c_1 + p c_2& k d_1 + p d_2 \end{array}\rightB  \right) \\
&=& \leftB \begin{array}{c} k a_1 + p a_2 \\ k b_1 + p b_2 \\ k c_1 + p c_2 \\ k d_1 + p d_2 \end{array}\rightB  \\
&=& \leftB \begin{array}{c} k a_1 \\ k b_1 \\ k c_1 \\ k d_1 \end{array} \rightB + \leftB \begin{array}{c} p a_2 \\ p b_2 \\ p c_2 \\ p d_2 \end{array} \rightB \\
&=& k \leftB \begin{array}{c} a_1 \\  b_1 \\  c_1 \\  d_1 \end{array} \rightB + p \leftB \begin{array}{c}  a_2 \\  b_2 \\  c_2 \\  d_2 \end{array} \rightB \\
&=& k T \left(\leftB\begin{array}{cc} a_1 & b_1 \\ c_1 & d_1 \end{array}\rightB \right) +  p T \left(\leftB\begin{array}{cc} a_2 & b_2 \\ c_2 & d_2 \end{array}\rightB \right)
\end{eqnarray*}

Therefore $T$ is linear. 

\textbf{$T$ is one-to-one:}
By Lemma \ref{lem:onetooneabstract} we need to show that if $T(A) = 0$ then $A = 0$ for some matrix $A \in \mathbb{M}_{22}$. 
\[
T\leftB\begin{array}{cc} a & b \\ c & d \end{array}\rightB
= \leftB\begin{array}{c} a\\ b\\ c \\ d \end{array}\rightB 
= \leftB\begin{array}{c} 0 \\ 0 \\ 0 \\ 0 \end{array}\rightB 
\]

This clearly only occurs when $a=b=c=d=0$ which means that 
\[
A = \leftB\begin{array}{cc} a & b \\ c & d \end{array}\rightB = \leftB\begin{array}{cc} 0 & 0 \\ 0 & 0 \end{array}\rightB = 0
\]

Hence $T$ is one-to-one.

\textbf{$T$ is onto:}
Let
\[ \vect{x}=\leftB\begin{array}{c} x_1\\x_2\\x_3\\x_4 \end{array}\rightB\in\mathbb{R}^4,\]
and
define matrix $A\in\mathbb{M}_{22}$ as follows:
\[ A=\leftB\begin{array}{cc} x_1 & x_2 \\ x_3 & x_4 \end{array}\rightB.\]

Then $T(A)=\vect{x}$, and therefore $T$ is onto.

Since $T$ is a linear transformation which is one-to-one and onto, $T$ is an isomorphism. Hence $\mathbb{M}_{22}$ and $\mathbb{R}^4$ are isomorphic.
\end{solution}

An important property of isomorphisms is that the inverse of an isomorphism
is itself an isomorphism and the composition of isomorphisms is an
isomorphism. We first recall the definition of composition.

\begin{definition}{Composition of Transformations}{compositetransformation}
Let $V, W, Z$ be vector spaces and suppose $T: V \mapsto W$ and $S: W \mapsto Z$ are linear transformations. Then the composite of $S$ and $T$ is
\[
S \circ T: V \mapsto Z
\]
and is defined by 
\[
(S \circ T) (\vect{v}) = S(T(\vect{v})) \mbox{ for all } \vect{v} \in V
\]
\end{definition}

Consider now the following proposition.

\begin{proposition}{Composite and Inverse Isomorphism}{compositeinverse}
Let $T:V\rightarrow W$ be an isomorphism. Then $T^{-1}:W\rightarrow V$ is
also an isomorphism. Also if $T:V\rightarrow W$ is an isomorphism and if $
S:W\rightarrow Z$ is an isomorphism for the vector spaces $V,W,Z,$ then $
S\circ T$ defined by $\left( S\circ T\right) \left( v\right) = S\left(
T\left( v\right) \right) $ is also an isomorphism.
\end{proposition}

\begin{proof}
Consider the first claim. Since $T$ is onto, a typical
vector in $W$ is of the form $T(\vect{v})$ where $\vect{v} \in V$. Consider then for $a,b$
scalars, 
\begin{equation*}
T^{-1}\left( aT(\vect{v}_{1})+bT(\vect{v}_{2})\right)
\end{equation*}
where $\vect{v}_{1}, \vect{v}_2 \in V$. Consider if this is equal to 
\begin{equation*}
aT^{-1}\left( T(\vect{v}_{1})\right) +bT^{-1}\left( T(\vect{v}_{2})\right) =a\vect{v}_{1}+b\vect{v}_{2}?
\end{equation*}
Since $T$ is one to one, this will be so if 
\begin{equation*}
T\left( a\vect{v}_{1}+b\vect{v}_{2}\right) =T\left( T^{-1}\left( aT(\vect{v}_{1})+bT(\vect{v}_{2})\right)
\right) =aT(\vect{v}_{1})+bT(\vect{v}_{2})
\end{equation*}
However, the above statement is just the condition that $T$ is a linear map.
Thus $T^{-1}$ is indeed a linear map. If $\vect{v} \in V$ is given, then $
\vect{v}=T^{-1}\left( T(\vect{v})\right) $ and so $T^{-1}$ is onto. If $T^{-1}(\vect{v})=\vect{0},$ then 
\begin{equation*}
\vect{v}=T\left( T^{-1}(\vect{v})\right) =T(\vect{0})=\vect{0}
\end{equation*}
and so  $T^{-1}$ is one to one.

Next suppose $T$ and $S$ are as described. Why is $S\circ T$ a linear map?
Let for $a,b$ scalars,
\begin{eqnarray*}
S\circ T\left( a\vect{v}_{1}+b\vect{v}_{2}\right) &\equiv &S\left( T\left(
a\vect{v}_{1}+b\vect{v}_{2}\right) \right) =S\left( aT(\vect{v}_{1})+bT(\vect{v}_{2})\right) \\
&=&aS\left( T(\vect{v}_{1})\right) +bS\left( T(\vect{v}_{2})\right) \equiv a\left( S\circ
T\right) \left( \vect{v}_{1}\right) +b\left( S\circ T\right) \left( \vect{v}_{2}\right)
\end{eqnarray*}
Hence $S\circ T$ is a linear map. If $\left( S\circ T\right) \left( \vect{v}\right)
=0,$ then $S\left( T\left( \vect{v} \right) \right) =\vect{0}$ and it follows that $T(\vect{v})=\vect{0}$ and hence by this lemma again, $\vect{v}=\vect{0}$. Thus $S\circ
T $ is one to one. It remains to verify that it is onto. Let $\vect{z}\in Z$. Then
since $S$ is onto, there exists $\vect{w}\in W$ such that $S(\vect{w})=\vect{z}.$ Also, since $T$
is onto, there exists $\vect{v}\in V$ such that $T(\vect{v})=\vect{w}.$ It follows that $S\left(
T\left( \vect{v}\right) \right) =\vect{z}$ and so $S\circ T$ is also onto.
\end{proof}

Suppose we say that two vector spaces $V$ and $W$ are related if there exists an isomorphism of one to the other, written as $V\sim W$. 
Then the above proposition suggests that $\sim $ is an equivalence relation. That is: $\sim $
satisfies the following conditions:

\begin{itemize}
\item $V\sim V$

\item If $V\sim W,$ it follows that $W\sim V$

\item If $V\sim W$ and $W\sim Z,$ then $V\sim Z$
\end{itemize}

We leave the proof of these to the reader. 

The following fundamental lemma describes the relation between bases and
isomorphisms.

\begin{lemma}{Bases and Isomorphisms}{basesisomorphism}
Let $T:V\rightarrow W$ be a
\index{isomorphism!invertible matrices}
\index{invertible matrices!isomorphism} linear map where $V,W$ are vector spaces.  Then a linear transformation $T$ which is one to one has the property that
if $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{k}\right\} $ is linearly
independent, then so is $\left\{ T(\vect{u}_{1}),\cdots ,T(\vect{u}_{k})\right\} $.
 More generally, $T$ is an
isomorphism if and only if whenever $\left\{ 
\vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $ is a basis for $V,$ it follows
that $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n})\right\} $ is a basis for $W$.
\end{lemma}

\begin{proof}
First suppose that $T$ is a linear map and is one to one
and $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{k}\right\} $ is linearly
independent. It is required to show that $\left\{ T(\vect{u}_{1}),\cdots ,T(\vect{u}_{k})\right\} $ is also linearly independent. Suppose then that 
\begin{equation*}
\sum_{i=1}^{k}c_{i}T(\vect{u}_{i})=\vect{0}
\end{equation*}
Then, since $T$ is linear, 
\begin{equation*}
T\left( \sum_{i=1}^{n}c_{i}\vect{u}_{i}\right) =\vect{0}
\end{equation*}
Since $T$ is one to one, it follows that 
\begin{equation*}
\sum_{i=1}^{n}c_{i}\vect{u}_{i}=0
\end{equation*}
Now the fact that $\left\{ \vect{u}_{1},\cdots ,\vect{u}_{n}\right\} $ is
linearly independent implies that each $c_{i}=0$. Hence $\left\{ T(\vect{u}
_{1}),\cdots ,T(\vect{u}_{n})\right\} $ is linearly independent.

Now suppose that $T$ is an isomorphism and $\left\{ \vect{v}_{1},\cdots ,\vect{
v}_{n}\right\} $ is a basis for $V$. It was just shown that $\left\{ T(\vect{v}
_{1}),\cdots ,T(\vect{v}_{n})\right\} $ is linearly independent. It remains to
verify that the span of $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n})\right\} $
is all of $W$. This is where $T$ is onto is used. If $\vect{w}\in W,$ there
exists $\vect{v}\in V$ such that $T(\vect{v})=\vect{w}$. Since $\left\{ \vect{v}
_{1},\cdots ,\vect{v}_{n}\right\} $ is a basis, it follows that there exists
scalars $\left\{ c_{i}\right\} _{i=1}^{n}$ such that 
\begin{equation*}
\sum_{i=1}^{n}c_{i}\vect{v}_{i}=\vect{v}.
\end{equation*}
Hence, 
\begin{equation*}
\vect{w}=T(\vect{v})=T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right)
=\sum_{i=1}^{n}c_{i}T\vect{v}_{i}
\end{equation*}
which shows that the span of these vectors $\left\{ T(\vect{v}_{1}),\cdots ,T
(\vect{v}_{n})\right\} $ is all of $W$ showing that this set of vectors is a
basis for $W$.

Next suppose that $T$ is a linear map which takes a basis to a basis. Then
for $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $ a basis for $V,$ it
follows $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n})\right\} $ is a basis for $
W.$ Then if $w\in W,$ there exist scalars $c_{i}$ such that $
w=\sum_{i=1}^{n}c_{i}T(\vect{v}_{i})=T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) $
showing that $T$ is onto. If $T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) =0$
then $\sum_{i=1}^{n}c_{i}T(\vect{v}_{i})=\vect{0}$ and since the vectors $\left\{ T(\vect{v}
_{1}),\cdots ,T(\vect{v}_{n})\right\} $ are linearly independent, it follows
that each $c_{i}=0.$ Since $\sum_{i=1}^{n}c_{i}\vect{v}_{i}$ is a typical vector in 
$V$, this has shown that if $T(\vect{v})=0$ then $\vect{v}=\vect{0}$ and so $T$ is also one to one.
Thus $T$ is an isomorphism.
\end{proof}

The following theorem illustrates a very useful idea for defining an
isomorphism. Basically, if you know what it does to a basis, then you can
construct the isomorphism.

\begin{theorem}{Isomorphic Vector Spaces}{isomorphicvectorspaces}
Suppose $V$ and $W$ are two vector spaces. Then the two vector spaces are isomorphic if and only
if they have the same dimension. In the case that the two vector spaces have
the same dimension, then for
\index{isomorphism!equivalence} a linear transformation $T:V\rightarrow W$, the
following are equivalent.

\begin{enumerate}
\item $T$ is one to one.

\item $T$ is onto.

\item $T$ is an isomorphism.
\end{enumerate}
\end{theorem}

\begin{proof}Suppose first these two vector spaces have the same
dimension. Let a basis for $V$ be $\left\{ 
\vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $ and let a basis for $W$ be $
\left\{ \vect{w}_{1},\cdots ,\vect{w}_{n}\right\} $. Now define $T$ as
follows. 
\begin{equation*}
T(\vect{v}_{i})=\vect{w}_{i}
\end{equation*}
for $\sum_{i=1}^{n}c_{i}\vect{v}_{i}$ an arbitrary vector of $V,$%
\begin{equation*}
T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) = \sum_{i=1}^{n}c_{i}T
(\vect{v}_{i})=\sum_{i=1}^{n}c_{i}\vect{w}_{i}.
\end{equation*}
It is necessary to verify that this is well defined. Suppose then that 
\begin{equation*}
\sum_{i=1}^{n}c_{i}\vect{v}_{i}=\sum_{i=1}^{n}\hat{c}_{i}\vect{v}_{i}
\end{equation*}
Then 
\begin{equation*}
\sum_{i=1}^{n}\left( c_{i}-\hat{c}_{i}\right) \vect{v}_{i}=0
\end{equation*}
and since $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $ is a basis, $
c_{i}=\hat{c}_{i}$ for each $i$. Hence 
\begin{equation*}
\sum_{i=1}^{n}c_{i}\vect{w}_{i}=\sum_{i=1}^{n}\hat{c}_{i}\vect{w}_{i}
\end{equation*}
and so the mapping is well defined. Also if $a,b$ are scalars, 
\begin{eqnarray*}
T\left( a\sum_{i=1}^{n}c_{i}\vect{v}_{i}+b\sum_{i=1}^{n}\hat{c}_{i}\vect{v}
_{i}\right) &=&T\left( \sum_{i=1}^{n}\left( ac_{i}+b\hat{c}_{i}\right) \vect{v
}_{i}\right) =\sum_{i=1}^{n}\left( ac_{i}+b\hat{c}_{i}\right) \vect{w}_{i} \\
&=&a\sum_{i=1}^{n}c_{i}\vect{w}_{i}+b\sum_{i=1}^{n}\hat{c}_{i}\vect{w}_{i} \\
&=&aT\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) +bT\left( \sum_{i=1}^{n}
\hat{c}_{i}\vect{v}_{i}\right)
\end{eqnarray*}
Thus $T$ is a linear map.

Now if 
\begin{equation*}
T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) =\sum_{i=1}^{n}c_{i}\vect{w}
_{i}=\vect{0},
\end{equation*}
then since the $\left\{ \vect{w}_{1},\cdots ,\vect{w}_{n}\right\} $ are
independent, each $c_{i}=0$ and so $\sum_{i=1}^{n}c_{i}\vect{v}_{i}=\vect{0}$
also. Hence $T$ is one to one. If $\sum_{i=1}^{n}c_{i}\vect{w}_{i}$ is a
vector in $W,$ then it equals 
\begin{equation*}
\sum_{i=1}^{n}c_{i}T\vect{v}_{i}=T\left( \sum_{i=1}^{n}c_{i}\vect{v}_{i}\right)
\end{equation*}
showing that $T$ is also onto. Hence $T$ is an isomorphism and so $V$ and $W$
are isomorphic.

Next suppose these two vector spaces are isomorphic. Let $T$ be the name of
the isomorphism. Then for $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $
a basis for $V$, it follows that a basis for $W$
is $\left\{ T\vect{v}_{1},\cdots ,T\vect{v}_{n}\right\} $ showing that the two
vector spaces have the same dimension.

Now suppose the two vector spaces have the same dimension.

First consider the claim that $1.)\Rightarrow 2.).$ If $T$ is one to one,
then if $\left\{ \vect{v}_{1},\cdots ,\vect{v}
_{n}\right\} $ is a basis for $V,$ then $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v
}_{n})\right\} $ is linearly independent. If it is not a basis, then it must
fail to span $W$. But then there would exist $\vect{w}\notin \func{span}
\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n})\right\} $ and it follows that $
\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n}),\vect{w}\right\} $ would be
linearly independent which is impossible because there exists a basis for $W$
of $n$ vectors. Hence 
\[
\func{span}\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}
_{n})\right\} =W
\]
and so $\left\{ T(\vect{v}_{1}),\cdots ,T(\vect{v}_{n})\right\} $
is a basis. Hence, if $\vect{w}\in W,$ there exist scalars $c_{i}$ such that 
\begin{equation*}
\vect{w}=\sum_{i=1}^{n}c_{i}T(\vect{v}_{i})=T\left( \sum_{i=1}^{n}c_{i}\vect{v}
_{i}\right)
\end{equation*}
showing that $T$ is onto. This shows that $1.)\Rightarrow 2.).$

Next consider the claim that $2.)\Rightarrow 3.).$ Since $2.)$ holds, it
follows that $T$ is onto. It remains to verify that $T$ is one to one. Since 
$T$ is onto, there exists a basis of the form $\left\{ T(\vect{v}_{i}),\cdots ,T
(\vect{v}_{n})\right\} .$ If $\left\{ \vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $
is linearly independent, then this set of vectors must also be a basis for $
V $ because if not, there would exist $\vect{u}\notin \func{span}\left\{ \vect{
v}_{1},\cdots ,\vect{v}_{n}\right\} $ so $\left\{ \vect{v}_{1},\cdots ,\vect{v}
_{n},\vect{u}\right\} $ would be a linearly independent set which is
impossible because by assumption, there exists a basis which has $n$
vectors. So why is$\left\{ \vect{v}_{1},\cdots ,\vect{v}_{n}\right\} $
linearly independent? Suppose 
\begin{equation*}
\sum_{i=1}^{n}c_{i}\vect{v}_{i}=\vect{0}
\end{equation*}
Then
\begin{equation*}
\sum_{i=1}^{n}c_{i}T\vect{v}_{i}=\vect{0}
\end{equation*}
Hence each $c_{i}=0$ and so, as just discussed, $\left\{ \vect{v}_{1},\cdots ,
\vect{v}_{n}\right\} $ is a basis for $V$. Now it follows that a typical
vector in $V$ is of the form $\sum_{i=1}^{n}c_{i}\vect{v}_{i}$. If $T\left(
\sum_{i=1}^{n}c_{i}\vect{v}_{i}\right) =\vect{0},$ it follows that 
\begin{equation*}
\sum_{i=1}^{n}c_{i}T(\vect{v}_{i})=\vect{0}
\end{equation*}
and so, since $\left\{ T(\vect{v}_{i}),\cdots ,T(\vect{v}_{n})\right\} $ is
independent, it follows each $c_{i}=0$ and hence $\sum_{i=1}^{n}c_{i}\vect{v}
_{i}=\vect{0}$. Thus $T$ is one to one as well as onto and so it is an
isomorphism.

If $T$ is an isomorphism, it is both one to one and onto by definition so $
3.)$ implies both $1.)$ and $2.)$.
\end{proof}

Note the interesting way of defining a linear transformation in the first
part of the argument by describing what it does to a basis and then
``extending it linearly''.

Consider the following example. 

\begin{example}{}{}
Let $V=\mathbb{R}^{3}$ and let $W$ denote the polynomials of degree at most
2. Show that these two vector spaces are isomorphic.
\end{example}

\begin{solution}
First, observe that a basis for $W$ is $\left\{ 1,x,x^{2}\right\} $ and a basis for $V$
is $\left\{ \vect{e}_{1},\vect{e}_{2},\vect{e}_{3}\right\} .$ Since these two
have the same dimension, the two are
isomorphic. An example of an isomorphism is this:\ 
\begin{equation*}
T(\vect{e}_{1})=1,T(\vect{e}_{2})=x,T(\vect{e}_{3})=x^{2}
\end{equation*}
and extend $T$ linearly as in the above proof. Thus 
\begin{equation*}
T\left( a,b,c\right) =a+bx+cx^{2}
\end{equation*}
\end{solution}
