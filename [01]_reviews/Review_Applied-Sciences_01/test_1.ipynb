{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF from C:\\Courses\\my-study-python\\[01]_reviews\\Review_Applied-Sciences_01\\applsci-3508831-peer-review-v1.pdf...\n",
      "PDF has 15 pages\n",
      "Successfully converted PDF to XML. Output saved to C:\\Courses\\my-study-python\\[01]_reviews\\Review_Applied-Sciences_01\\applsci-3508831-peer-review-v1.xml\n",
      "Conversion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom as minidom\n",
    "\n",
    "# Install required packages if not available\n",
    "try:\n",
    "    import PyPDF2\n",
    "except ImportError:\n",
    "    print(\"Installing PyPDF2...\")\n",
    "    !pip install PyPDF2\n",
    "    import PyPDF2\n",
    "\n",
    "def convert_pdf_to_xml(pdf_path, output_xml_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF research article to XML format using PyPDF2.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file\n",
    "        output_xml_path (str): Path to save the output XML file\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if conversion was successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading PDF from {pdf_path}...\")\n",
    "        \n",
    "        # Open the PDF file\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Get number of pages\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            print(f\"PDF has {num_pages} pages\")\n",
    "            \n",
    "            # Create the root XML element\n",
    "            root = ET.Element(\"article\")\n",
    "            \n",
    "            # Add metadata\n",
    "            metadata = ET.SubElement(root, \"metadata\")\n",
    "            \n",
    "            # Add document info if available\n",
    "            if hasattr(pdf_reader, 'metadata') and pdf_reader.metadata:\n",
    "                for key, value in pdf_reader.metadata.items():\n",
    "                    if value:\n",
    "                        meta_item = ET.SubElement(metadata, \"meta\", {\"name\": key})\n",
    "                        meta_item.text = str(value)\n",
    "            \n",
    "            # Process content\n",
    "            content = ET.SubElement(root, \"content\")\n",
    "            \n",
    "            # Try to extract the title from the first page\n",
    "            first_page_text = pdf_reader.pages[0].extract_text()\n",
    "            title_match = re.search(r'^([^\\n.]+)', first_page_text)\n",
    "            if title_match:\n",
    "                title = ET.SubElement(content, \"title\")\n",
    "                title.text = title_match.group(1).strip()\n",
    "            \n",
    "            # Try to identify abstract (often after title and before section headings)\n",
    "            abstract_match = re.search(r'(?i)abstract[:\\s]*([\\s\\S]+?)(?:\\n\\s*\\n|\\n\\s*\\d\\.|\\n\\s*introduction)', first_page_text)\n",
    "            if abstract_match:\n",
    "                abstract = ET.SubElement(content, \"abstract\")\n",
    "                abstract.text = abstract_match.group(1).strip()\n",
    "            \n",
    "            # Process all pages\n",
    "            paragraphs_section = ET.SubElement(content, \"paragraphs\")\n",
    "            \n",
    "            # Simple section detection pattern (assuming sections start with numbers or common section names)\n",
    "            section_pattern = r'(?:\\n\\s*\\d\\.|\\n\\s*(?:Introduction|Methods|Results|Discussion|Conclusion))[^\\n]*\\n'\n",
    "            \n",
    "            for page_num in range(num_pages):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                page_text = page.extract_text()\n",
    "                \n",
    "                # Try to identify sections\n",
    "                sections = re.split(section_pattern, page_text)\n",
    "                section_titles = re.findall(section_pattern, page_text)\n",
    "                \n",
    "                if len(section_titles) > 0:\n",
    "                    # Create section elements if section titles were found\n",
    "                    for i, section_title in enumerate(section_titles):\n",
    "                        if i < len(sections):\n",
    "                            section_text = sections[i+1] if i+1 < len(sections) else \"\"\n",
    "                            \n",
    "                            # Create section element\n",
    "                            section_elem = ET.SubElement(content, \"section\")\n",
    "                            \n",
    "                            # Add section heading\n",
    "                            heading = ET.SubElement(section_elem, \"heading\")\n",
    "                            heading.text = section_title.strip()\n",
    "                            \n",
    "                            # Split into paragraphs (assuming paragraphs are separated by blank lines)\n",
    "                            paragraphs = re.split(r'\\n\\s*\\n', section_text)\n",
    "                            for para_text in paragraphs:\n",
    "                                if para_text.strip():\n",
    "                                    paragraph = ET.SubElement(section_elem, \"paragraph\")\n",
    "                                    paragraph.text = para_text.strip()\n",
    "                else:\n",
    "                    # If no sections were found, add page text as paragraphs\n",
    "                    paragraphs = re.split(r'\\n\\s*\\n', page_text)\n",
    "                    for para_text in paragraphs:\n",
    "                        if para_text.strip():\n",
    "                            paragraph = ET.SubElement(paragraphs_section, \"paragraph\")\n",
    "                            paragraph.text = para_text.strip()\n",
    "            \n",
    "            # Try to extract references (often start with \"References\" heading)\n",
    "            references_text = \"\"\n",
    "            for page_num in range(num_pages):\n",
    "                page_text = pdf_reader.pages[page_num].extract_text()\n",
    "                if re.search(r'(?i)references|\\breferences\\b', page_text):\n",
    "                    # Found references section\n",
    "                    ref_match = re.search(r'(?i)references[:\\s]*([\\s\\S]+)', page_text)\n",
    "                    if ref_match:\n",
    "                        references_text = ref_match.group(1)\n",
    "                        break\n",
    "            \n",
    "            if references_text:\n",
    "                refs_section = ET.SubElement(root, \"references\")\n",
    "                # Split references (assuming each reference starts with a number)\n",
    "                ref_items = re.split(r'\\n\\s*\\d+\\.|\\[\\d+\\]', references_text)\n",
    "                for i, ref_text in enumerate(ref_items):\n",
    "                    if ref_text.strip():\n",
    "                        ref_elem = ET.SubElement(refs_section, \"reference\", {\"id\": f\"ref_{i+1}\"})\n",
    "                        ref_elem.text = ref_text.strip()\n",
    "        \n",
    "            # Pretty print the XML and save to file\n",
    "            xml_str = ET.tostring(root, encoding='utf-8')\n",
    "            xml_pretty = minidom.parseString(xml_str).toprettyxml(indent=\"  \")\n",
    "            \n",
    "            with open(output_xml_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(xml_pretty)\n",
    "            \n",
    "            print(f\"Successfully converted PDF to XML. Output saved to {output_xml_path}\")\n",
    "            return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting PDF to XML: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# For Jupyter Notebook compatibility - get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define input and output paths\n",
    "pdf_filename = 'applsci-3508831-peer-review-v1.pdf'\n",
    "pdf_path = os.path.join(current_dir, pdf_filename)\n",
    "\n",
    "# Create output filename based on input filename\n",
    "output_filename = os.path.splitext(pdf_filename)[0] + '.xml'\n",
    "output_path = os.path.join(current_dir, output_filename)\n",
    "\n",
    "# Convert PDF to XML\n",
    "success = convert_pdf_to_xml(pdf_path, output_path)\n",
    "\n",
    "if success:\n",
    "    print(\"Conversion completed successfully!\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
